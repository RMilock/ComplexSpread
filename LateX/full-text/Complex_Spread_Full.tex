\documentclass[a4paper,10pt,twoside]{book} %%{book}

\usepackage[top=5cm,bottom=5cm,inner=5cm,outer=3cm]{geometry}
\usepackage{graphicx, caption, subcaption} %per poter inserire le figure
\usepackage{csquotes} %handle " and ""
\MakeOuterQuote{"}  %handle opening/closing quotation
\usepackage{amssymb,amsmath,amsthm,amsfonts,bm, yhmath}
\usepackage{bookmark}% http://ctan.org/pkg/bookmark
\usepackage{appendix}
\usepackage{xspace}
\usepackage{tabularx}
\usepackage{indentfirst}
%\usepackage{subfigure}
%\usepackage[small]{caption}
\usepackage{eucal}
\usepackage{eso-pic}
\usepackage{url}
\usepackage{booktabs}
\usepackage{afterpage}
\usepackage{parskip}
\usepackage{listings}
\usepackage{fancyhdr}
\usepackage{textcomp}
\usepackage{cite}
\usepackage{multirow}
%\usepackage[utf8]{inputenc}   %per riuscire a scrivere gli accenti, but w/ this an error with csquote is raised. Hence, use \usep[english]{babel} only.
\usepackage[english]{babel}   %per riuscire a scrivere gli accenti
\usepackage{setspace}
\usepackage{etoc}
\usepackage{etoolbox}
\usepackage{setspace}
\usepackage{verbatim}
\usepackage{color}
\usepackage{titlesec}
\usepackage{fancyhdr}
\usepackage{tocbibind}
\usepackage{wrapfig}
\usepackage{booktabs}
\usepackage{braket}
\usepackage{multirow}
\usepackage{float}
\usepackage{units}
\usepackage{siunitx}
\usepackage{bigints}

\usepackage{pgfplots} % to make plot inside LateX
\pgfplotsset{compat = 1.16}

\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{mathrsfs}
\usepackage{bbold}
\usepackage{mathtools}
\usepackage[style=ddmmyyyy]{datetime2}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\pagestyle{fancy} 

\graphicspath{{../images/}}

\titleformat{\chapter}[display]
  {\normalfont\bfseries}{}{0pt}{\Huge}

\definecolor{brown}{rgb}{0.28, 0.02, 0.03}
\hypersetup{
colorlinks,
citecolor=blue,
filecolor=blue,
linkcolor=blue,
urlcolor=blue
}

%\makeatletter
%\renewcommand\tableofcontents{%
%    \section*{\Huge{\contentsname}}%
%    \@starttoc{toc}%
%}
%\makeatother

%\NewDocumentCommand{\evalat}{sO{\big}mm}{%
%  \IfBooleanTF{#1}
%   {\mleft. #3 \mright|_{#4}}
%   {#3#2|_{#4}}%
%}

\begin{document}
\frontmatter


\newgeometry{top=2cm,bottom=2cm,left=2cm,right=2cm}
%%old for {book}: \frontmatter
%below: textsc = font "small caps"
\begin{titlepage}
\vspace{5mm}
\begin{figure}[hbtp]
\centering
\includegraphics[scale=.13]{../images/unipd_logo.png}
\end{figure}
\vspace{5mm}
\begin{center}
{{\huge{\textbf{\LARGE UNIVERSIT\`A DEGLI STUDI DI PADOVA}}}\\}
\vspace{20mm}
{\Large{\bf Dipartimento di Fisica e Astronomia "Galileo Galilei"}} \\
\vspace{5mm}
{\Large{\textsc{\bf Master Degree in Physics (LM-17)}}}\\  
\vspace{20mm}
{\Large{\textsc{\bf Final Dissertation}}}\\
\vspace{30mm}
{\Large{\textsc{\bf Modelling COVID-19 In a Network}}}\\
\vspace{45mm}
\end{center}

\begin{spacing}{2}
\begin{tabular}{lccccccccccl}
	{\Large{\bf Candidate}} &&&&&&&&&& {\Large{\bf Thesis supervisor}}\\
	{\Large{\bf Riccardo Milocco}} &&&&&&&&&& {\Large{\bf Prof./Dr. Marco Baiesi}}\\
\end{tabular}
\end{spacing}
\vspace{15 mm}

\begin{center}
{\Large{\bf Academic Year 2020/2021}}
\end{center}
\end{titlepage}

\restoregeometry

\clearpage{\pagestyle{empty}\cleardoublepage}

\pagestyle{empty}

\vspace*{\fill}
\tableofcontents
\vspace*{\fill}

	

%-----------------------------------------------------------------------

%\newgeometry{top=4cm,left=4cm}
\newgeometry{left = 4cm, bottom = 2cm, right = 2cm, top=4cm}
\chapter*{Abstract}
The usual simplified description of epidemic dynamics predicts an exponential growth. This is due to the mean field character of the dynamical equations. However, a recent paper (Thurner S, Klimek P and Hanel R 2020 Proc. Nat. Acad. Sci. 117, 22684) \cite{Thurner::NetBasedExpl} showed
that in a network with fixed connectivity, the nodes become infected at a rate that increases linearly rather than exponentially.
Experimental data for COVID-19 seem to validate this approach. In this thesis we plan to study this model by tuning its parameters.
In particular, we monitor the effect induced by a significant presence of hubs in the network.

\chapter*{Motivations}
Last Update: \today
"The COVID-19 pandemics has led to a dramatic loss of human life worldwide and presents an unprecedented challenge to public health, food systems and the world of work"\cite{Chriscaden::2021_ImpactCOVID19}. In this scenario, monitoring and forecasting the diffusion of the virus is an essential tool for policymakers to handle the health-care resources and restrictions among individuals. To this purpose, many academics, e.g. \href{https://web.unipd.it/covid19/en/}{UniPD against COVID-19}\footnote{https://web.unipd.it/covid19/en/}, have been trying to tackle the COVID-19 spreading as well as its side-effects, which have to be considered on the "path to normality". This drastic shift with respect to the "path to herd immunity" comes from a recent study \cite{GU::2021_SitePathToNormality} which shed light on the fact that "herd immunity", due to delay on vaccinations, could probably not be reached for the end of 2021. On the other hand, due to few practical points \cite{Nature:18.3.2021_NoHerdImmunity}, it is also probabile that the long-term prospects include COVID-19 becoming an endemic disease, much like influenza. 
Therefore, the recovery of the pre-COVID-19 situation could be slow even in the presence of effective vaccines.

Hence, an interesting path to cover is to describe the evolution of the COVID-19 pandemic, e.g. with the SIR model \cite{pizzuti::2020_ItalyCOVIDnetwork}, on different network topologies in order to simulate the different containment policies, i.e. "lock-downs".

%%old for {book}: 
\mainmatter

\newcommand{\changefont}{%
    \fontsize{12}{12}
	%\selectfont
}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\changefont \slshape \nouppercase{\rightmark}} %section
\fancyhead[RE,LO]{\changefont \slshape \nouppercase{\leftmark}} %chapter
\fancyfoot[C]{\thepage}

\chapter[Introduction]{Introduction}
%\include{cap_Introduction}

\section{Complexity}
Since its beginning, Physics has been driven by a "Unification Principle"\footnote{from Newton with the "gravity"-relationship between an apple and the Moon; passing to Einstein, whom the effects of gravity are equal to the ones of an accelerated rocket for; ending to the \textit{Grand Unified Theory} as an unification of of general relativity with the particle physics},which aims at describing the reality as a "reduction" and simplification of its constituents and interactions. Nevertheless, this optimistic gaze, is (amazingly) challenged by the complexity that emerges in the world we are living in. This complexity could have variable origins but also different spatial scales: from ants' nest to storms, from the markets to human/animal migrations, from the epidemics to ecosystems. Therefore, Nature is capable of obeying simple laws but, on the other hand, to straightforwardly generate complex phenomena. A paradigmatic example is the flocking of birds: the core of the flock assumes different shapes due to a collective interaction among the birds; while an alone bird would proceed in a defined direction.
These facts were enough to establish the new branch of \textit{Physics Of the Complex Systems} which ultimate goal is to describe the emergence of the "complex" phenomena from the simple law of physics, e.g. "gravity model" \cite{GravityModelsandEmpiricalTrade}.
Having understood that \textit{"More is different"} \cite{Anderson:1972_MoreIsDifferent} and its ubiquity, it is natural to demand a formal definition of "Complexity". Nevertheless, quoting the Nobel Price Murray Gell-Mann \cite{Gell-Man:1987_S&C}, "a variety of different measures would be required to capture all our intuitive ideas about what is meant by complexity and by its opposite, simplicity" . In fact, from computational complexity to other information measures, all such quantities are context-dependent and subjective, since they depend on many aspects, such as the detail level (coarse graining) of the entity to describe. Thus, a rough but clear definition could be drawn for the Complex System Society site \cite{CSS:2021_compsystdef}:

\begin{definition}[\textit{"Complexity"}]
Complex systems are systems where the collective behavior of their parts entails emergence of properties that can hardly, if not at all, be inferred from properties of the parts.
\end{definition}

In other words, the non-linear interactions among the parts of which a complex system is composed let emerge a behavior which could not be understood simply by applying the fundamental laws to its constituents.

The first representation of this weaved system is by considering entities and connections among them. Thus, a powerful tool to describe it is the Network Science.
In particular, the purpose of this thesis is to study the epidemic spreading of the COVID-19 over different network topologies that mimic the underlying social network of contacts. The phenomenon is, thus, regarded as a complex system through the analysis of the SIR model, which grasps the emergent features rather than the microscopic behavior of the disease.

\subsection{Models Ecosystem}
Infectious epidemics are responsible for a significant health and economic burden on society. New diseases appear frequently and old diseases persist. Therefore, many mathematical models have been used recently to guide policy makers to mitigate the impact of new infectious diseases (e.g. Polio, H1N1 influenza and Ebola) or established ones (such as HIV, cholera and seasonal influenza).
On the other hand, with the phrase \textit{All models are wrong; some models are useful} \cite{Box::2005_StatDesign}, George Box wanted to highlight that no model, no matter how complicated\footnote{Instead, the complexity of a model could challenge its possibility to be predictive in many scenarios. A related topic is the "over-fitted model" in statistical learning or "Occam's razor" in Philosophy}, is perfect. Thus, a way to evaluate a "successful" model has to be recovered.

Inside the "ecosystems" of models, there are the simple models which allow to analytically explain how the primary mechanisms influence important characteristics (e.g. epidemic threshold, epidemic size\footnote{how large it will be}, how long it will last). To be more accurate, it is also possible to develop models that incorporate much more details about both the disease and individual-level interactions \cite{Kiss::MathOfEpiOnNet}.

\begin{figure}[htbp]
	\centering
	\includegraphics[width = .4\linewidth]{perfect_model.png}
	\caption{A caricature of the relation between model realism, complexity and the
	insight the model provides \cite{Kiss::MathOfEpiOnNet}.}
	\label{fig:perfect_model}
\end{figure}	

As suggested by the \autoref{fig:perfect_model}\footnote{\textit{"Est modus in rebus"} \label{cit:GM}} (\cite{Kiss::Ch1MathOfEpiOnNet}), models provide maximum insight where the right balance of realism (circle filled with dots, e.g. regarding epidemiology Graph-Neural-Network to predict $R_t$ \cite{Davahli::USA_predicting_COVID19}) and simplicity (circle with vertical lines e.g. on epidemics the deterministic SIR model) is met\footnote{The equilibrium point may depend on the specific posed question} (central circle with oblique lines).

In this middle region, there could be found several works that use network analysis as the underlying structure for a phenomenon(\cite{Thurner::NetBasedExpl} \cite{VespignaniSatorras2001Epidemic} \cite{pizzuti::2020_ItalyCOVIDnetwork}); while other, more involved, that incorporate human mobility data in several hybrid models \cite{ZEROUAL::DL_COVID19, Stubinger::Incidence_Diff_Countries} in order to predict its diffusion. For the sake of simplicity, the present thesis is going to deepen the paper of \cite{Thurner::NetBasedExpl}. In particular, Thurner et al. \cite{Thurner::NetBasedExpl}, by focusing on the COVID-19 spreading in Austria and in the USA, are able to find a scenario, i.e. a combination of the SIR spreading parameters\footnote{the infection rate $\beta$, recover rate $\mu$, the long-range attachment probability $p$}, such that the outbreak is (quasi-)linear for a value of the average number of contact $D$. This behavior of the SIR model is qualitatively comparable with the curves reported by the JHUniversity reported below. 
Hence, inspired by \cite{Thurner::NetBasedExpl}, the aim of this project is to analyze how the SIR model behaves by changing its "inner" epidemic parameters but also the topology of the underlying social network, i.e. the susceptible people.

\section{A Technical Introduction}
\label{sec:ATechIntro}
At $8 \, \textnormal{May} \, 2020$, none of the affected COVID-19 states have reached "herd immunity" but still they reached the "epidemic peak" due to the containment restrictions on social contacts. One paradigmatic example is the case of Austria, for which the total infected cases at the 08/05/2020 were $0.18\%$ of the total population, remarkably low with respect to the SARS-COV-2 "herd-immunity" level that are supposed to be at $0.8\%$ (\cite{Zingano:2021_HI_hom_pop}) of the entire (susceptible) population. 

To qualitatively show the behaviors of Austria, USA and Italy, we produced a graph of the total cases \autoref{fig:USA-AUT-ITAtotalcasesOWID} according to the reported cases of \cite{JHUGitHub:2020_TotalCases} from the first detection of COVID-19 (25/02/2020) to the starting days of May (08/05/2020). The purpose of this figure is to show the effect of the policies over the COVID-19 curves.
Indeed, the beginning and ending dates where exhibited by the colored big marks on the curves of the total cases. Since for the USA all the states could behave differently, we chose to display the starting date of the first (California) and the last (Missouri and South Dakota) states; while we report only one ending date as the quoted states ended the stay-at-home restriction at the same time.
Therefore, even if USA has got many more contagions of Austra and Italy, it has the lowest curve due to not restricted lockdowns which did not flatten the fraction of total cases. 
In the legend, there are reported two important quantities:
\begin{itemize}
	\item $max/min$ is defined as the "growth factor" f (see \autoref{ch:Methodology}) is the ratio among $max$ (the total cases at the end of the figure) and $min$ (the total cases at the beginning of the figure);
	\item $max / totp$ where "$max$" is the total cases at the end, while "$totp$" is the total population for each state according to \cite{PopulationEstimate}.
\end{itemize}
In particular, the ranges of infected individuals displayed by the each state are the following: 2-15774 (AUT), 453-217185 (ITA), 16-1295396 (USA) \cite{Anderson:1972_MoreIsDifferent}. In turn, this means that Austria could track down the COVID-19 since its early stages; while Italy began already with a considerable amount of cases. Furthermore, the infected at the beginning of the lockdown (for the USA the stay-at-home-order of the California) are also reported in the legend: 1018 (AUT), 12462 (ITA), 13663 (USA). This means that even if Austria temporally started the lockdown restrictions after Italy, considering also its starting cases it has anticipated much the italian policies. Therefore at 08/05/2020, the total infected were smaller than the italian ones.
\begin{figure}[tbp]
	\centering
	\includegraphics[width = \textwidth]{Introduction/COVID-RealStates_2020-03-25.png}
	\caption{The number of total cases normalized to their maximum value in the period 25/02/20 - 08/05/20. The dates of the first lockdown are: 16/03 - 14/04/20 (AUT); 11/03 - 04/05/20 (ITA); California: 19/03 - 04/05; Missouri: 6/04 - 04/05. USA states with no-stay-at-home restrictions: Arkansas,	Iowa,Nebraska,North Dakota,	South Dakota}
	\label{fig:USA-AUT-ITAtotalcasesOWID}
\end{figure}
The most striking observation is that the total cases (\autoref{fig:USA-AUT-ITAtotalcasesOWID})for USA, after early-stages when the stay-at-home order was not at work, exhibits a (quasi-)linear growth for an extended time interval in contrast with the "S-shaped" logistic curve predicted by the standard compartmental models. The extension of the linear regime depends on the onset of the measures; while for early stages, as it was the case for many countries \cite{Thurner::NetBasedExpl} ($8 \, \textnormal{May} \, 2020$), an exponential growth dominates the spreading of the disease as in \autoref{fig:USA-AUT-ITAtotalcasesOWID}.
By taking care of the modification of the underlying social network structure, in this present thesis, we want to (qualitatively) recover the spreading trends for the states that have or have not applied the Non-Pharmaceutical-Intervations (NPIs). \newline
Specifically, an infection may occur for two reasons:
\begin{enumerate}
    \item interaction between an infected and a susceptible person;
    \item contact is "intense" (e.g. long, close,...) enough to lead to a disease transmission.
\end{enumerate}
Hence, the rationale behind the social distancing is that it takes to a reduction of both of these factors.
On the other hand, the analytically solvable SIR model assumes that, defined $N, D$ as the total number of individuals in the population and the average number of contacts respectively, there is the same probability that an individual encounters an infected person ("well-mixed population") and all the nodes have the same number of neighbors ($N-1$ or $D$). This approach allows to recover analytical results for an epidemic spreading but it annihilates the underlying network structure. Therefore, as claimed in \cite{VespignaniSatorras2001Epidemic}, there is the need of studying how the network affects the spreading of a disease, but still no focus is put on the spreading below the epidemic threshold \cite{Thurner::NetBasedExpl} as it is the case if nodes were separated through NPIs. 
In this thesis, the main goal is to grasp the relevant features of a complex social network in presence of NPIs and compare them with respect to a "well-mixed" population model.
In detail, by changing the epidemic parameters, we let the SIR Model evolve in different network topologies such as standard models of the graph-theory ("Watts-Strogatz","Scale-Free", "Caveman Model") but also a new involved topology, i.e. a Poissonian Small-World Network. As a benchmark of a "well-mixed" population, we used an "annealed" mean-field (see \autoref{sec:Annealed_MF_Network}) which is a natural realization of a mean-field network with a fixed average number of contacts per node.
To account for the epidemic onset at early times, we used the \textit{basic reproduction number}, namely  $R_0 := \beta \cdot D/\mu$. This quantity is defined as the the average number of new infections caused by an individual in a completely susceptible population\footnote{The susceptible individuals are chosen according to "epidemic targets", e.g. only children for the measles} \cite{Kiss::MathOfEpiOnNet}. Moreover, it is well consolidated that for $R_0 > 1$ an epidemic is possible (not guaranteed); while for $R_0 < 1$ the disease will die out. 
Thus, these informations drive naturally to suppose that $R_0$ could also be a signal of the strength of an epidemic outbreak. Instead, this is not the case, since, as reported in the section \autoref{sec:res_RegLat}, for equal $R_0$ values there could be different behavior of the disease. Thus, to account for the "epidemic severity", i.e. the final outbreak size, a new parameter has to be introduced that has to:
\begin{itemize}
	\item grasp the different behavior of epidemics;
	\item depend only on the initial condition, i.e. network metrics (e.g. "long-range" parameter $p$) and disease parameters ($\beta \textnormal{ and } \mu$).
\end{itemize}
In particular, $R_0$ should depend on the underlying topology, but it worths anticipating that the considered epidemics model are not designed for this scope: both the homogeneous and the heterogeneous models are averaging the network properties \autoref{ch:sir-models}. Hence, we propose a new quantity called \textit{epidemic severity} which is formally defined as 
\begin{equation}
	\Delta R_0 (\delta):= \frac{R_0 - R_{c-net}}{\delta}
\end{equation}
where $\delta:=\langle l \rangle $ is the average path length. We will describe it more deeply in \autoref{sec:def_epidemic_severity}

Finally, as in \cite{Thurner::NetBasedExpl}, an "epidemic" order parameter\footnote{Precisely, it is the standard deviation of the daily new infected (see \autoref{sec:OrderParam4LinContagion}).} is computed for each spread to classify a light outbreak, i.e. an outbreak which infect less than the $30\%$ of the entire population, from a stronger one, with an outbreak size of $\sim 80\%$ of individuals. In this way, a kind of first-order phase transition could be obtained by plotting the order parameter against the average degree of contacts as done in \autoref{fig:Ordp_OPSW_COVID19_p0.3_panel}.

Acquired the purposes and intentions of the thesis, it seems natural to deepen the area of the Network Science.


\section{Network Science}

Two aspects contribute to the popularity of Network Science: its universality nature of networks and the availability of large datasets\footnote{In reality, also the computational power to analyze them should be remarked.} which map huge networks of the furthest kind, e.g. "food-webs" or the Science of Science.
Its roots could be found in the Graph Theory, a mathematical branch devoted to the analysis of the networks (or graphs), and Statistical Mechanics, committed to the formalization of the dynamical processes on networks, such as self-organization and information theory.
For our purpose, the Graph Theory allows to formalize a "networky" - complex system such as the social network of the individuals over which a disease spreads; while Statistical Mechanics to develop a model focusing on its emergent characteristic, such as a SIR model.

\subsection{Graph Theory}
\label{sec:GraphTheory}
\begin{figure}[htbp]
	\centering
	\includegraphics[scale = 0.7, trim = {3cm 2cm 4cm 5cm}, clip]{Basic_SN}
	\caption{Contacts interaction Network. As far as the COVID-19 interaction is concerned, a (risky) contact is defined as the human-droplets that reach one individual. Therefore, a symmetric edge could represent a chat among two persons; where directed edges would be a "one-way" interaction such as in a room with pre-existent droplets. The number above each edge are the weights, which could be the minutes spent in the previous quoted room. Lastly, we will focus on undirected and weigth-less graphs.}
	\label{fig:basicSN}
\end{figure}

A graph is a tuple (V,E) where the "V" stands for "vertexes" (1,2,3,4) while "E" for "edges" (the links between the vertexes).
With the same notation, an edge connecting the node\footnote{In the context of a social network, a vertex represents a person/individual} $i$ to $j$ is, often, identified by $(i,j)$.
Formally, the labels of the vertexes are the image of any bijective embedding from the nodes to a chosen set, e.g. integer numbers. The relationship among vertexes are accounted by the edges, which could be unsymmetrical, as for $(1,4)$, and with different strength of the connection, such as $(1,4) \text{ and } (1,3)$ which. If all the edges are symmetric, i.e. if (A,B) implies (B,A), the graph is said undirected, e.g. the friendship network; otherwise it is said directed, e.g. the phone contacts network. 
With the given definitions, it is now clear that roughly everything could be divided in vertexes connected by am arbitrary relation.
The simplest example, is the \textit{simple graph}, which is an unweighted, undirected graph containing no graph loops, i.e. $(i,i)$ edges, or multiple edges such as multiples-$(i,j)$. It could be represented as the \autoref{fig:basicSN} forcing all the edges to be weightless and undirected.
\begin{figure}[ht]
	\includegraphics[width = \linewidth]{SimpleGraph_950.png}
	\caption{Edges peculiarities. The labels are $1,2,3,4$ assigned anti-clockwise starting from the bottom}
	\label{fig:simple}
\end{figure}
\newpage

\subsection{Adjacency Matrix}
Typically for real networks, the number of involved nodes is big, e.g. the Google web-graph available at \href{https://snap.stanford.edu/data/#socnets}{Standford University Network Dataset} is of the order of the $800k$ nodes and $5milion$ edges. Thus, despite the clearness of \autoref{fig:basicSN}, the most suitable way of representing a graph is by grouping all its properties in a matrix called the adjacency matrix $A$. 
Starting from the basics, the (symmetric) adjacency matrix for the simple graph above is:
\[
A_{ij} :=
\begin{cases}
1 & \text{if exist an unweighted edge among i and j} \\
0 & \text{otherwise}
\end{cases}
\quad
\Leftrightarrow
\quad
A = 
\begin{bmatrix}
0 & 0 & 1 & 0 \\
0 & 0 & 1 & 1 \\
1 & 1 & 0 & 1 \\
0 & 1 & 1 & 0 \\
\end{bmatrix}
\]

Hereby, $A \in M_4(\mathbb{N})$ holds the nature of a simple graph:
\begin{itemize}[noitemsep]
	\item the rows represent the direct connections between the $i-th$ row and the $j-th$ column; while, the columns the edge $(j,i)$. Thus, there are only 4 nodes;
	\item unweighted: the value of the elements of $A$ is binar;
	\item without loops: the diagonal is $0$;
	\item without multi-edges: the value of the entries of $A$ are strictly $0$ or $1$, account for the presence of, at maximum, one edge.
\end{itemize}

A more involved, adjacency matrix is the one of the rightest graph which present multiples loops\footnote{As far as multi-edges are concerned, the $2$ would be off-diagonal}.
Formally,
\[
A = 
\begin{bmatrix}
0 & 0 & 1 & 0 \\
0 & 0 & 1 & 1 \\
1 & 1 & 0 & 1 \\
0 & 1 & 1 & \textbf{2} \\
\end{bmatrix}
\]

Thus, in \autoref{fig:basicSN} is report a (simple) weighted and directed graph with 4 nodes connected by a "central"\footnote{The "centrality" measure of the node is another important quantity which is context-dependent. In this case, the "centrality" refers to a degree centrality for which the most central node is the one with the highest number of contacts} node $1$.
In particular,
\[
A = 
\begin{bmatrix}
0 & 1 & \textbf{5} & 1 \\
1 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 \\ 
\end{bmatrix}
\]
where it is encoded the direct edges since $A$ is not symmetric. Wheter there would be a self-loop, such at $ 1 \longleftrightarrow 1 $, there would be a 1 at the first entry (position $(1,1)$) of the matrix $A$.

\subsection{Degree}

\begin{figure}[ht]
    \begin{subfigure}{\textwidth}
        \includegraphics[scale = 0.4]{../images/Networks/DegreeClustCoeffPathLeng}
        \centering
        \caption{Network measures \cite{Olaf:2011_NonRandomBrain}}
        \label{fig:degree_clustcoefficient_pathlength}
    \end{subfigure}
\end{figure}
As quoted before, a (real) network could be very tangled. Thus, the degree distribution, i.e. the normalized number of vertexes with a certain degree, allows to check whether all the nodes have, or not, the same number of contacts even at a plain eye inspection. 

Formally, the degree of a vertex, in a (undirected) graph, is the number of edges connected to it. We denote the degree of node $i$ by $k_i$ and, by mean of $A$, $$k_i := \sum_{i=1}^{N} A_{ij},$$ where $N$ is the number of total nodes.
For directed graphs, as in \autoref{fig:basicSN}, a distinction between the entering and exiting edges to a node has to be defined. In particular, by a generalization of the previous $k_i$, 
\begin{equation}
	k_i^{in} := \sum_{j=1}^N A_{ij}, \quad k_j^{out} := \sum_{i=1}^N A_{ij}.
	\label{eq:kin_kout}	
\end{equation}
where $k_i^{in(out)}$ is the number of in-going (out-going) number of edges. 

Therefore, by applying the \autoref{eq:kin_kout}\footnote{A practical check is to count the tails for the out-degree and arrows for the inner-degree. Ultimately, each sum has to equate the number of edges (a undirected edge has to be count doubled)} to \autoref{fig:basicSN}, it is possible to recover the degree distribution of the vertexes as in the \autoref{fig:degreed_basicSN}. Thus, a possibile way to build a graph would be to draw the nodes degrees from a fixed distribution and, then, connecting the nodes according to their degree. In fact, this approach, generating a \textit{Configurational Model Network}, is going to be exploited in the further chapters by using a Poissonian degree distribution and connecting the vertexes only to nearest neighbors via an ad-hoc algorithm \autoref{sec:PSW_network}.

\newpage
\begin{figure}[h]
	\begin{subfigure}{.5\linewidth}
		\begin{tikzpicture}
		\begin{axis}[ybar interval, 
			width = \linewidth,
			xtick align=inside,
			ymin = 0,%, ymax=55,ymin=0, minor y tick num = 3]
			ylabel = {Number of Nodes},
			xlabel = {In-degrees},]
		\addplot coordinates { (0, 0) (1, 3) (2, 0) (3, 0) (4, 0) (5, 1) (6, 0) };
		\end{axis}
		\end{tikzpicture}
	\end{subfigure}%
	\hfill
	\begin{subfigure}{.5\linewidth}
		\begin{tikzpicture}
		\begin{axis}[ybar interval, 
			width = \linewidth,
			xtick align=inside,
			ymin = 0,%, ymax=55,ymin=0, minor y tick num = 3]
			ylabel = {Number of Nodes},
			xlabel = {Out-degrees},]
		\addplot coordinates { (0, 0) (1, 1) (2, 0) (3, 0) (4, 0) (5, 0) (6, 0) (7,1) (8,0) };
		\end{axis}
		\end{tikzpicture}
	\end{subfigure}
	\caption{Degree Distribution of the \autoref{fig:basicSN}}
	\label{fig:degreed_basicSN}
	\end{figure}

\chapter{The Network Models}
\label{ch:network-models}
As it could be perceived, modeling a complex (social) phenomenon\footnote{The "social" nature has been only evoked for concreteness. Nevertheless, this in-depth presentation of models is interdisciplinary as Network Science itself.}, as the epidemic spreading, in a network has two main tasks. The first is the identification of the nodes, which is a fairly simple task. The hard one is to pinpoint the emergent correlations in order to connect the vertexes and reproduce the phenomenon. The latter one is the real challenge in network theory.

%Thus, the goal is to artificially reproduce the main topological features of the real networks. 
Many networks are characterized by strong constraints on the node degree which forces a satisfying regularity to be present, e.g. the radial architecture of a spider net or the map of the main streets of Manhattan.
Inspired by this, as a first tackle, the pathogen is left to act on a regular society, which individual contact are differing at most by one: famous examples are the "regular" Watts-Strogatz and the Caveman model.

Most of the real networks, however, do not show a comforting orderliness. 
%add an image of spider net, Manhattan and Internet Network
Rather, their inner structure seems to be characterized by a certain degree of randomness, e.g. the internet network \cite{barabasi::2016networkbook}. Random network theory embraces this feature by constructing network models that are truly random, e.g. Erdös-Rényi. By contrast, they are not able to capture the presence of hubs, alias the "Scale-Free" property. Thus, new models as to be proposed to generate those highly connected degree nodes, such as the Barabási-Albert models.
A review of these is reported in the following sections; alongside with the newly proposed "Poissonian Small World" network (see \cite{Thurner::NetBasedExpl} or \autoref{sec:PSW_network}).

\section{Regular Networks}
\label{sec:RLN-Caveman_Description}
\subsection{Lattice Graph}
\begin{figure}[ht]
    \begin{subfigure}{\textwidth}
        \includegraphics[scale = 0.4]{../images/Networks/RegGraphs}
        \centering
        \caption{In (a) - fully-connected graph; In (b) - $D = 4$ regular graph \cite{Zelazo:2011_RSensNet_images}}
        \label{fig:RegGraph}
    \end{subfigure}
\end{figure}

The "Regular Networks" are characterized by a fixed number of neighbors per node $D = \langle k \rangle$. Thus, they are expected as the constituent graphs for the class of systems which constraints $D$ to a certain value, e.g. solids in the physics of matter.
Ultimately, by trying to study a new phenomenon, it is fundamental to test its behavior on a controlled environment as the one provided by the regular networks.

In \autoref{sec:WS_Model}, there will be presented the "Watts-Strogatz" model which depending by an inner parameter $p$ can interpolate between a regular graph for $p = 0$ (\autoref{fig:RegGraph}) and a random network ($p=1$).

\subsection{Connected Caveman Graph}
\begin{figure}[ht]
    \begin{subfigure}{\textwidth}
        \includegraphics[trim={2cm 3cm 2cm 4cm}, clip, scale = 0.6]{../images/Networks/CavemanMod_Rew}
        \centering
        \caption{Disconnected and Connected with rewiring Caveman Model \cite{Taube:2005_IndianSoftwIndustry}}
        \label{fig:CavemanMod}
    \end{subfigure}
\end{figure}

By analogy with the Non-Pharmaceutical-Interventions (NPIs) which accounts only for the household interactions, we considered the "Caveman Model".

The rationale is to consider as if one node, of the previously modeled networks, would be a family composed by a fixed number of people. This idea drives to the "coarse-graining" approach seen in the previous sections.
In detail, the Caveman model enables to fix both the number of "caves"/families and the number of individual for each family. 

In the present thesis, it is going to be developed an intermediate version among the Caveman models shown in \autoref{fig:CavemanMod}. Indeed, connect the nearest caves of the left figure by creating a new edge on randomly choosing nodes within each cave. Then, introduce a "rewiring parameter" to enable "long-range" connections, resulting in "tunneling cuts" among distant nodes as in the right rewired graph. The ending graph is comparable to a Watts-Strogatz model, whose nodes are substituted with an entire cave.

A naive expectation is that the epidemic spread slower and more stochastically, since the nodes are poorly connected with the "outside" rather than in the family.

\section{Random Networks}
Not all the networks are characterized by hubs as WWW or the airports graphs.
In fact, there could be constraints, such as cost-benefit problem, which limit the maximum degree of the bigger node. In those cases, random networks may be the best (thus, not conclusive) fit, e.g. national highways network, power grid of generators and switches, $\cdots$

\subsection{The Erdös-Rényi Model}
\label{sec:ER_model}
%insert a reference image for ER model

\begin{figure}[ht]
    \begin{subfigure}{\textwidth}
        \includegraphics[trim={14cm 0 0 1cm}, clip, scale = 0.6]{../images/Networks/ERmodel}
        \centering
        \caption{Erdös-Rényi Model for $p = 0.2$ \cite{Baronchelli:2017_EpidSpreadCompNets}}
        \label{fig:ERmodel}
    \end{subfigure}
\end{figure}

The Erdös-Rényi (ER - \autoref{fig:ERmodel}) model was the first attempt to formally describe a random network. 
In particular, these two mathematicians were the fathers of the random graph theory, obtained by merging graph theory with probability theory.

The primitive hypothesis, for a random wiring, is that the nodes are linked together with a probability $p$. Formally,

\begin{definition}[\textit{"Random Network"}]
A random network $G(N,p)$ has N nodes where two nodes are connected with probability $p$.
\end{definition} 

Due to its random nature, this model may have different realizations even with $N$, $p$ fixed parameters. Therefore, the number of links and the nodes degree distribution (see \autoref{sec:GraphTheory}) becomes vital informations to be considered.
In particular, a specific realization could exhibit $L$ links with a probability
\begin{equation}
	\label{eq:probLrndNet}
	p_L = p^L \cdot (1-p)^{ \binom{N}{2} - L } \cdot \binom{\binom{N}{2}}{L}.
\end{equation}
The \autoref{eq:probLrndNet} is the product of $3$ terms: the probability to have $L$ edges; the probability not to have the remaining ones knowing that the total possible node pairs are \[ \binom{N}{2} = \frac{N(N-1)}{2}; \] the total combinations in the choice of the $L$ edges, since what counts is only to pick a number $L$ of edges and not which ones.
As expected, $p_L$ could be interpreted as $L$ successful results knowing that an edge is chosen with probability $p$ and the total trials are $\frac{N(N-1)}{2}$ pairs. Thus, a Binomial distribution with the average number of links equal to
\[ D:= \langle L \rangle = \sum_{L = 0}^{\frac{N(N-1)}{2}} p_L L = p\frac{N(N-1)}{2} \label{eq:meanL} \] and, thus, the average per node contacts \[ \langle k\rangle = \frac{2\langle L \rangle}{N} = p(N-1) \label{eq:meank}. \]

The two equations above highlight that $\langle L \rangle$ and $ D$  could be obtained by multiplying $p$ by the total number of available links and neighbors resp.\footnote{This is accordance with the formal definition of the "average"}. Alongside, as the network becomes denser, i.e. increasing $p$, also $\langle L \rangle$ and $\langle k\rangle$ would be enhanced.
Moreover, by multiplying the expression by $q$, it is possible to obtain $\sigma_{\langle x\rangle} = q \, \cdot \langle x\rangle,$ where $x = L \textnormal{ or } k$.

Similarly, the probability of having k number of contacts is 
\begin{equation}
	\label{eq:probkrndNet}
	p_k = p^k \cdot (1-p)^{ \binom{N-1}{2} - k } \cdot \binom{\binom{N-1}{2}}{k}.
\end{equation}
where $N-1$ are the total neighboring nodes differently from $\binom{N}{2}$, which were the total node pairs (cf. \autoref{eq:probLrndNet}).
Another way to recover $\langle k\rangle$ and $\sigma_{k}$ is by means of $p_k$.

Real network are sparse. In fact, by defining the "sparsity" of a network as the ratio $s : = \langle k\rangle/N$, the internet-routers has $s \simeq 3.0 \cdot 10^{-5}$, since $N \simeq 200000 \text{ while } \langle k\rangle \simeq 6$. Many others concrete example support this sparsity nature of real networks \cite{barabasi::2016networkbook}. Therefore, in the $\langle k\rangle / N \ll 1$ limit\footnote{At least for $\langle k\rangle \simeq 50 \text{ and } N \simeq 10^3$}, the \autoref{eq:probkrndNet} becomes the Poissonian distribution with average $\langle k\rangle$
\begin{equation}
	\label{eq:sparse_probk}
	p_k = e^{-\langle k\rangle} \frac{\langle k\rangle^k}{k!}.
\end{equation}

Therefore, keeping in mind that the \autoref{eq:sparse_probk} is only valid in the sparse regime,
\begin{itemize}
	\item the explicit expressions of $\langle k\rangle \simeq p\cdot N \textnormal{ and } \sigma_k = \langle k\rangle^{1/2}$ assume a simpler form for a Poissonian distribution. Moreover, as the binomial case, $\langle k\rangle \textnormal{ and } \sigma_k$ increases if p increases, since the network is becoming denser and, so, more spread in the node degrees.
	\item it allows the same description for a pletora of networks with the same $\langle k\rangle$, since the network characteristics does not depend on its size $N$.
\end{itemize}

\subsection{The "Small-World" Property}
\label{sec:SWProp}
A captivating argument, network science allows to study is the "Small-World (SW) phenomenon" or "six degrees of separation". The two quoted names comes, respectively, from a theme developed by the Hungarian writer Fridgyes Karinthy in a play called "Chains" ($1978$) and an empirical experiment injected by the psychologist S. Milgram in $1967$. In fact, the most famous version states that a person, e.g. Kevin Bacon, is linked to a random one, e.g. Andrea Scotti, through only few acquaintances: according to \href{https://oracleofbacon.org/movielinks.php}{Kevin Bacon Number}\footnote{https://oracleofbacon.org/movielinks.php} only by $2$ persons in common. Hence, the distance between two randomly chosen nodes in a graph is small. Random networks account for this phenomenon as we are going to deepen.

On average, the expected number of nodes $N$ at a certain distance $d$ is
\[N(d) \approx 1+ \langle k \rangle + \cdots + \langle k \rangle^d = \frac{\langle k \rangle^{d+1} -1 }{\langle k \rangle - 1},  \] 
where we taken advantage of the geometric series, after noting that $``1"$ is the selected nodes, $\langle k \rangle$ are its neighbors, $\langle k \rangle^2 \approx \langle k \rangle (\langle k \rangle - 1)$ the next neighbors and so on.
Thus, by considering that for a real network $\langle k \rangle \ll 1$ and that $N(d_{max}) \sim N$, 
\[
	d_{max} \sim \frac{\ln(N)}{\ln(\langle k \rangle)}
\]
On the other hand, the above equation is more suitable in describing $\langle k \rangle$, since $d_{max}$ is dominated by few distant paths from the core giant component. Hence, 
\begin{equation}
	\langle d \rangle \sim \frac{\ln(N)}{\ln(\langle k \rangle)} 
	\label{eq:SWrandnet}
\end{equation} 
is the formulation of the Karinthy's "Small-World phenomenon" obtained by considering that most of the nodes are contained within $\langle d \rangle$.
Indeed, for a real network, $\ln(N) \ll N$ drives to a "smaller" average path length compared to $N$, which is the typical scaling for a regular lattice\footnote{The common notion of physical distance is based on a regular lattice which do not shows the "Small-World" effect. At first glance, this result could be perceived as an uncomfortable.}
Moreover, the denominator of the \autoref{eq:SWrandnet} implies that the denser it becomes the network, the closer the nodes aggregate.
As a sociological example, the average distance of a random person, in the current century, would be derived by applying the \autoref{eq:SWrandnet} by fixing $N \sim 7\cdot 10^9$ and $\langle k \rangle \sim 10^3$ yielding $\langle k \rangle \sim 3.28$ which is a more reliable results than the "six degrees of separation" \cite{barabasi::2016networkbook}.

\newpage
\subsection{The Clustering Coefficient}
As far as a social network is considered, it seems natural to introduce a measure of community membership (\autoref{fig:degree_clustcoefficient_pathlength}) which capture the possibility to join a local community, e.g. an association or a family. More generally, real networks are characterized by the clustering formation, which "simplify" the network by aggregating the nodes, called clusters, which present common characteristics. Proceeding as the "coarse graining" technique of Statistical Mechanics, it becomes appealing to take care of the emergent properties exhibited by the "coarse-grained" network. In the following section, it is introduced the degree of "clusterization" of a network.

More precisely, the local clustering coefficient $C_i$ measures the chance of having a link among the neighbors of the $i-th$ node. To gain a rough intuition of its purpose, it is worthwhile to consider two opposite limits: 
\begin{itemize}
	\item $C_i = 0$ as there are no links among neighbors of $i$;
	\item $C_i = 1$ as there are fully connected neighbors of $i$.
\end{itemize}

Formally,
\begin{equation}
	C_i := \frac{\textnormal{average links of the i-th neigbors}}{\textnormal{total links among neighbors}} = \frac{\langle L_i \rangle}{\frac{k_i(k_i-1)}{2}} = p = \frac{\langle k \rangle}{N} = \langle C \rangle
	\label{eq:rnd_clustcoefficient}
\end{equation}

where $k_i \textnormal{ and } N$ are the amount of neighboring vertexes of $i$ and the total nodes respectively, \[ \langle L_i \rangle = p \cdot \frac{k_i(k_i-1)}{2} \quad \textnormal{ and } \quad \langle C \rangle := \frac{1}{N} \sum_{i = 1}^{N} C_i. \]

The presence of a link among the two neighbors closes a triangle with the focal node $i$ ( "triadic closure"). Hence, $C_i$ could also be interpreted as the normalized number of triangles centered in the selected node. In addition, $C_i = \langle C \rangle$ is independent by the $i-th$ node degree and, fixing the average degree of a network, it scales with $1/N$: for real networks $p = \langle k \rangle / N$ is small (real networks are sparse) and drives to a smaller $C$ that the one observed. A model that naturally generates "triangle", would be a good candidate to enhance the clustering coefficient even for small $p$.

\subsection{Problems in Random Networks}

By looking at a real social network, e.g. at a cocktail party, there is the co-presence of highly connected nodes, called \textit{"hubs"}, alongside with the less interacting ones. The ER graph does not account for the presence of high-degree nodes\cite{barabasi::2016networkbook}, since they are strongly damped by the  factor term $1/k!$ in \autoref{eq:probkrndNet}. Indeed, real networks are sparse but have also strongly heterogeneous degrees, showing a high variance through node degrees.

Secondly, by looking at the evolution of the contact network, e.g. the one underlying the previous cocktail party, there could be identified 4 topological regimes starting from isolated individuals for $\langle k \rangle = 0$ and ending with a fully connected graph for $\langle k \rangle = N-1$, where $N$ are the total invited persons. The ER model predicts the co-existence of a giant component, containing loops and cycles, and small components, which forms trees, for $1 < \langle k\rangle < \ln(N)$ - find a better description below. However, this is clearly at odds with reality since, as a concrete example, in a random electric power-grid some consumers should not get electric power \cite{barabasi::2016networkbook}. Many network, as the actor network, are in the connected regime; most are in the supercritical one while still connected.
In particular, these regimes scan the formation path of a fully connected network, passing trough a rapid emergence of a giant component.
\newline Schematically,
\begin{itemize}[noitemsep]
	\item Sub-critical Regime for $0 < \langle k \rangle < 1 \quad (p < 1/N)$ 
	\item Critical point for $\langle k \rangle = 1 \quad (p = 1/N)$
	\item Supercritical Regime for $\langle k \rangle > 1 \quad (p > 1/N)$: Single giant component formation
	\item Connected Regime for $\langle k \rangle > \ln(N) \quad (p > \ln(N)/N)$
\end{itemize}
This is in an one-to-one relation with a First-Order-Phase Transition treated in Statistical Mechanics. The formation of an ordered giant component could be compared with ice formation: the passage from disordered water molecules to an ordered structure.

Thirdly, the real world networks exhibits a "Small-World" phenomenon not in agreement with the \autoref{eq:SWrandnet}. Hence, a new "Small-World" measure has to be proposed.

Fourthly, fixing $N$, the theoretical expectation is to grasp the independent nature of $C$ with respect to $k$. Nevertheless, the results is unsatisfactory, since $C$ decreases with the increasing of $k$ for a pletora of the real networks.
%put an image of this
Furthermore, $C/\langle k \rangle (N)$, for high $N$, is higher that its theoretical expectation. Thus, a refined model is needed, to explain the high $C$ even at small $p$ (or high $N$).

\subsection{Watts-Strogatz Model}
\label{sec:WS_Model}
%insert a reference image
\begin{figure}[ht]
    \begin{subfigure}{\textwidth}
        \includegraphics[scale = 0.4]{../images/Networks/WS_Model}
        \centering
        \caption{In the top panel, the changing topology from lattice to random-like network; In the bottom panel, the behavior of average path length and clustering coefficient with $p$ \cite{Olaf:2011_NonRandomBrain}}
        \label{fig:WSmodel}
    \end{subfigure}
\end{figure}

To face the problem of the "high $C$ at low edge probability (for now, redefined as $p_{ER}$)", while preserving the "Small-World" property, the mathematicians Duncan Watts and Steven Strogatz proposed in the $1998$ a hybrid model which interpolated between a regular lattice for $p = 0$ to a random network model for $p = 1$. The new borne model is, thus, called "Watts-Strogatz (WS) model".
Practically, the idea is to start with a grid-like network, where all the nodes have $\langle k \rangle$ neighbors; then, with probability $p$, a link is chosen and one of the endpoints, e.g. the "rightmost", is replaced with a random vertex within the graph. The underlying degree distribution, hence, narrows the nodes degrees since it passes from an one-block histogram centered in $\langle k \rangle$ to a Poissonian distribution. Thus, nodes have barely different neighbors degree and no hubs are allowed.
A further constraint is that no multiple edges can connect the same pair of vertexes, i.e. no multi-edges. The presence of multiedges gives a correction of $1/N$ for big $N$, negligible in a real modeling scenario with big $N$.

The rationale of ER model is that by a little decrease of clustering (i.e. destroying triangles) corresponds a significant reduction in the average path length $\delta:= \langle d \rangle$. Other way around, by connecting nodes in a "long-range" fashion, the overall "triadic closures" are still relevant. 

It worths to highlight that the present $p$, called in this context the "rewiring parameter", is the "long-range" rewiring probability, while the ER model $p_{ER}$ is the probability of an edge formation either among neighbors ("short range" connection) or among distant nodes ("long range" connection). Thus, the "distant" connected vertexes are, on average, $p\cdot L$ where $L$ is the total number of links.
In particular, a regular lattice is characterized by a high clustering (neighboring nodes are fully connected) but a high average path length; while a random network, as seen before, exhibits manifestly the "Small-World" property alongside with a low clustering coefficient especially, since triangles are rare for small $p$.
Therefore, the parameter $p$ is introduce to fine tune the co-presence of the two kind of networks. As reported in \cite{Menczer:2020_1stCoursNetSci}, there is a range of rewiring probabilities $p \in (0.01,0.1)$ in which $\langle d \rangle_p \approx \langle d \rangle_{p=0} \textnormal{ and } C_p \approx C_{p=0}$ encoding the fact that the average path length and clustering coefficient of the WS model are, respectively, near the one of a random network and the one of a lattice.

Anyway, this model doesn't explain the presence of the hubs, since neglected by all the degree distributions, and the (inverse) dependence of $C(k)$ on the average network degree.

As a pedagogical spoiler, the (four) previous problems would be faced by modifying the WS model adding the emergent properties of the real networks, such as the "scale-free" property.
Hence, an useful approach would be to start from the degree distribution rather than on imposing a fixed probability of wiring as for ER and WS models.

\section{Configuration Model}
To face the problems previously exposed, a practical starting point could be to reproduce the degree distribution by taking advantage of the configuration model 
\cite{Menczer:2020_1stCoursNetSci}. Indeed, it is possible to built a network from an arbitrary degree sequence which either could be drawn by a distribution or by a real network of interest.
Precisely,
\begin{definition}[\textit{"Degree Sequence"}]
	The degree sequence is a list of $N$ numbers \newline $(k_0, \cdots, k_{N-1})$ where $k_i$ is the degree of node $i$.
\end{definition}
A degree sequence, thus, determines uniquely a degree distribution but the reverse is not true, since for a particular degree distribution there are $N!$ possibilities of labeling the nodes: $(1,2,3)$ has the same degree distribution of $(3,2,1)$.
Additionally, a method to wire the nodes has to be chosen. Especially, the configuration model wires the nodes randomly; thus, building a random network. For these reasons, the generated graph is also called "random network with a pre-defined degree sequence". 

As done before, a practical way of constructing a network clarifies many ideas.
As a first step, consider to have a set of nodes with an assigned degree sequence. Pictorially, this could be depicted as a node with a number of dangling stubs as its degree. Thus, the number of isolated stubs have to be twice the sum of all the degrees. 
The network is, further, composed by the following iterative steps:
\begin{itemize}
	\item A pair of stubs is selected at random;
	\item An edge is formed, by attaching together the selected stubs. 
\end{itemize}
This tying technique is replicated until all the stubs are saturated and it is random by construct. Therefore, this method generates random networks with a fixed degree distribution.

Since the number of stubs equals the node degree, each node ends up having the desired degree. Thus, from the selected distribution, multiple (random) networks could be created; even, showing some peculiar properties, such as loops or multi-edges. Therefore, further constraints has to be imposed to obtain a specific topology, such as a connection only to "short-range" nodes. 

The network is characterized by mainly two properties:
\begin{itemize}
	\item the probability that a fixed node $i$ may connect to another one $j$ is
		\begin{equation}
			p_{ij} = \frac{k_ik_j}{2L-1}.
		\end{equation}
		In fact, there are $k_i$ stubs (or rays) trying to match the $k_j$ ending of node $j$; while $2L -1$ are the overall rays available for the chosen one which produces the $"-1"$;
	\item the number of self-loops and multi-links decreases as $N$ increases, since it is less probable to connect with a specific node as $p \sim 1/N$. Typically it is not
	needed to exclude them \cite{Newman:2010_Net:AnIntro}. More importantly, arbitrarily rejecting self-loops or multi-links would result in a modification of the starting degree distribution, yielding the analytical calculations difficult. 
\end{itemize}

The different realizations of the same degree distribution have a statistically objective. Indeed, let's suppose a certain feature, such as the presence of hubs, is independent on the other network characteristics rather than the degree distribution. By exploiting an ensemble of graphs, it would be possible to obtain an average and a standard deviation of that feature. Thus, by comparison with the real value, evaluate the unique dependence on the degree distribution.

Another method to generate a network from a fixed degree distribution is the "hidden parameter ($\eta$) method" which, in addition, do not form multi-edges and loops \cite{barabasi::2016networkbook} and allows to tune the average degree $\langle k \rangle$ modifying $\eta$.
On the other hand, to recover a randomized version from the degree sequence, such as of a fixed real network, the "degree-preserving randomization" is the best help the theory provides. In this way, by just swapping two endpoint nodes at a time, it is possible to build a networks ensemble with the same degree distribution. Therefore, it allows to check whether a quantity depends only on the degree distribution itself or has a more involved structure.
In the following sections, only the Configuration Model is going to be used.

\clearpage
\subsection{Poissonian Small-World Network}
\label{sec:PSW_network}
\begin{figure}[ht]
    \begin{subfigure}{.45\linewidth}
        \includegraphics[width = \linewidth]{Results/PSW/AdjMat/NNO_Conf_Model_addE_True_AdjMat_1000_14.0_0.0.png}
        \centering
        \caption{Overlapping PSW degree distribution. }
        \label{fig:netmod_O-PSW}
    \end{subfigure}
	\hfill
	\begin{subfigure}{.45\linewidth}
        \includegraphics[width = \linewidth]{Results/PSW/AdjMat/NN_Conf_Model_AdjMat_1000_13.0_0.0.png}
        \centering
        \caption{Sparse PSW degree distribution}
        \label{fig:netmod_S-PSW}
    \end{subfigure}
	\caption{Two kind of PSW network for a "Overlapping" and "Sparse" scheme. The case of $p = 0.3$ is not show for conciseness, but could be straightforwardly obtained by the overimposing some long-range links to the current cases as in \autoref{fig:net_RegLat_D500_p0.3}}
\end{figure}
Social network are highly non trivial structure, by including a multilevel organization; weak ties between communities; and temporal aspects that suggest a degree of fluidity with stable social cores \cite{Thurner::NetBasedExpl}.
As seen in the \autoref{sec:ATechIntro}, however, the lockdown measures prevents the formation of highly connected nodes (hubs), expected in an unconstrained (social) scenario. Thus, a possible approach would be to draw a degree sequence from a Poissonian distribution, regardless on the ratio $\langle k \rangle / N$ (differently from \autoref{sec:WS_Model}); and build a graph by connecting the neighboring nodes.
This involved structure, called "Poissonian Small-World (PSW) Network" (\cite{Thurner::NetBasedExpl}), enables to capture the heterogeneity in the number of contacts (node degree); the SW phenomenon and the clusterization of families alongside with their overlap. Moreover, the WS parameter $p$ represents the fraction of individuals that are connected at "long-range" through leisure activities ($p = 0$ these are prohibited).

In order to built a PSW network, the starting point is by using the configuration model with a degree sequence drawn from a Poissonian distribution. To simulate a closed population, the nodes are assumed to be put on a circle: the last and the first of nodes of the degree sequence are assumed as neighbors. Hence, both the "SW" property (see "The emergence of the Small-World property" \autopageref{sec:SWProp}) and the heterogeneity on the node degrees could be embodied at the same time. 

With low values of the Poissonian parameter $\mu$ is possible to take into consideration the lock-down scenario where the average per node degree of contacts is the household size $D \sim 2.5$ \cite{Thurner::NetBasedExpl}. The configuration model generates a random wiring of the links, producing "long-range" connections which spoil the locality of the community structures (families). Therefore, by an ad-hoc algorithm, the stubs are forced to attach to the nearest nodes in the circle according to their degree. 
The rewiring procedure arises the choice of whether to preserve \textit{locality}  (\autoref{fig:netmod_O-PSW}), obtaining a narrower $p_k$, or to fix the \textit{Poissonian distribution} (\autoref{fig:netmod_S-PSW}), introducing some long-range connections. Based on the kind of connections, we address to the former as the "overlapping-PSW" (O-PSW); while the latter as the "sparse-PSW" (S-PSW). \\
To gain a perceiving understanding of this, we assumed that the nodes were arranged on a circle and we wired them anti-clock wise from the bottom. If the "locality" has to be preserved (\autoref{fig:netmod_O-PSW}), the "actor" node links to its nearest neighboring vertexes even if their degrees have been already saturated by previous wirings. Therefore, the Poissonian distribution is lost. This kind of $ p_k$ resembles the Watts-Strogatz one for $ p_k \neq 0$. The difference is that $ p \neq 0$ drives to a network with long-range interactions; while here we genearated only local connections.\\
On the other hand, by aiming at preserving $p_k$ (\autoref{fig:netmod_S-PSW}), we link an individual to the nearest contacts, whose degree has not been saturated by the previous re-links. Thus, the target nodes could be distant from the source one. Since in \cite{Thurner::Appendix_NetBasedExpl}, there are reported some intriguing behaviors for a Poissonian Small-World (PSW) but not which of the two kinds. Hence, we decided to examine both the O-PSW and S-PSW networks.

In practice, the wiring algorithm iterates over few steps\footnote{Recall that the degree sequence is already fixed and drawn by a Poissonian distribution}:
\begin{itemize}
	\item choose the lowest degree $k_l$ node that has not already been saturated;
	\item link an even number of times $\lfloor k_l /2 \rfloor$ on the clockwise and anti-clockwise nodes, where $\lfloor * \rfloor$ is the floor function of $*$;
	\item if the degree of the selected node is odd, wire one last time ($k_l - \lfloor k_l /2 \rfloor \, = k_l \bmod(2) =  1$), e.g. anti-clockwise;
	\item delete, among the available nodes, both the chosen node and the target nodes which have saturated their degree.
\end{itemize}

More practically, fixed $[(1, 0), (6, 1), (0, 2), (2, 2), (4, 2), (7, 2), (8, 2), (9, 3), (5, 3), (3, 4)]$, i.e. a degree sequence composed by (node,degree) tuples. 
The edges $(i,j)$ are created by connecting $i \textnormal{ to }j$ and diminishing the degree of $j$ at each step:
\begin{itemize}
	\item node $1$ is left alone as $deg(1)=0$;
	\item $(6,7)$;
	\item $(0,2)\textnormal{ and }(0,9)$
	\item $(2,0) \text{ (already present) and } (2,3)$;
	\item $(4,3)\textnormal{ and }(4,5)$;
	\item $(7,6)\textnormal{ (already present) and }(7,8)$; 
	\item $(8,7) \textnormal{ (already present) and } (8,9)$;
	\item $(9,3), (9,8) \textnormal{ (already present) and } (9,5)$ - "tunneling" nodes ;
	\item $(5,4), (5,9) \textnormal{ (already present) and } (5,3)$;
	\item node $3$ is left with $deg(3) = 1$, but this issue reduces with sparsity $\langle k \rangle \ll 1$.
\end{itemize}

Hence, the algorithm preserves the Poissonian degree distribution, while enhancing the local clustering of the nodes. However, it is possible to have "long-range" connections ($(9,5)$), since the nearest available vertexes could be already saturated; therefore, resulting in a distant linking. This "tunneling" nodes are neither "super-spreaders" (or hubs of the infection), as they are forbidden by the Poissonian degree distribution; nor "super-infectors", which would be characterized by an higher infectivity rate $\beta$.

\newpage
\section{Scale-Free Networks}
\subsection{Scale-Free Property}

\begin{figure}[h]
    \begin{subfigure}{\textwidth}
        \includegraphics[scale = 0.5]{../images/Networks/Scale-free-network-and-power-law-distribution-A-B-The-US-highway-system-has-a.png}
        \centering
        \caption{On the left: the comparison of a random network(top panel) and a scale-free one(bottom panel; On the right: their degree distributions on log-log scale) \cite{barabasi::2016networkbook}}
        \label{fig:PLDsVSEBDs}
    \end{subfigure}
\end{figure}

\begin{definition}[Scale-Free Network \cite{Barabasi:1999_ScalRndNet}]
	A scale-free network is a network whose degree distribution follows a power law.
\end{definition}

By plotting the degree distribution of the real networks, due to "hubs", a better approximation is obtained via a power-law distributions (PLDs) of the kind\footnote{Usually, reported in the log-log scale linear version: $\ln(p_k) \sim -\gamma \ln(k)$.} $p_k \sim k^{-\gamma}$  where $\gamma$ is called the \textit{degree exponent} . 

{\large \textbf{How a scale does (not) emerge}} \\
The PLDs are long-tailed functions; hence, describing a phenomenon that has not a reference scale.
For example, the heights distribution of a sample population displays a peak at the average height, which is the reference scale for that population. Instead, PLDs do not exhibit a peak but allows also for outliers, e.g. 100ft tall individuals.
More precisely, the variance, for a Poissonian distribution, is $\sigma_k = \langle k \rangle ^ {1/2}$, limited as the network grows. Therefore, the $\langle k \rangle$ scale is trustworthy. 

At the same time, for a PLDs the variance diverges since \cite{barabasi::2016networkbook}	
\begin{equation}
	\lim_{N \to \infty} \sigma_k^2 \approx k_{max}^{2-\gamma+1} = \infty.
	\label{eq:sigma_SFnets}
\end{equation}
since real networks have typically $\gamma \in (2,3)$ (WWW has $\gamma =  2.1$ \cite{barabasi::2016networkbook}) and $k_{max} \sim N$. 

Therefore, a reference scale for PLDs is not naturally present as, extending the Poissonian result, for the "Exponential Bounded Distributions" (EBDs) \cite{barabasi::2016networkbook}, i.e. when there is a exponential or faster decay for high $k$, such as binomial/Poissonian/Gaussian distributions.

{\large \textbf{The Degree(s) of Hubs}} \\
In the following, it is developed a quantitative comparison between the maximum degree allowed by EBDs and by PLDs to gain a numerical perception of their difference.
In detail, $k_{max}$ (or the "natural cutoff") is expected to be, roughly speaking, the size of the bigger hub; while $k_{min}$ approximates the smallest degree.
Therefore, for an exponential distribution \cite{barabasi::2016networkbook}, 
\begin{equation}
	k_{max} = k_{min} + \frac{\ln(N)}{\lambda}.
	\label{eq:Expkmax_up}	
\end{equation}
where $\lambda = 1$ for convenience. The same $\ln(N)$ dependence would be recovered of any other EBD.

On the other hand, applying the same rationale to a scale-free network, 
\begin{equation}
	k_{max} = k_{min}\,N^{\frac{1}{\gamma-1}}.
	\label{eq:SFkmax_up}
\end{equation}

The results are somehow expected, since for:
\begin{itemize}
	\item EBDs: $k_{max} \sim k_{min}$ since $\ln(N)$ strongly reduces contribution with $N$;
	\item PLs: there could be order of magnitude of difference between $k_{max}$ and $k_{min}$.
\end{itemize} 
Indeed, as a simple example, WWW forms a graph of on $N \sim 10^5$ documents with $\langle k \rangle \simeq 4.6$ and $\gamma = 2.1$ \cite{barabasi::2016networkbook}. 
Knowing that $k_{min} = 1$ for EBDs, $k_{max} \sim 14$; while $k_{max} = 95.000$. 
This reinforces the insight that big hubs are naturally arising by increasing $N$ only for PLDs.
\label{sec:SFProperties_up}

{\large \textbf{Ultra Small-World}} \\
Hubs represent a one-hop bridge for many nodes, by centralizing the otherwise-distant nodes. Indeed, the average distance $\langle d \rangle \sim \ln(\ln(N))$ for $\gamma \in (2,3)$, formally describing the so called "ultra small-world phenomenon". An heuristic example is the airport lines, which diminish the \(\langle d \rangle\) among (far) cities with respect the national highways.

Surrounding the "Ultra Small-World", there are $3$ other regimes
\cite{Cohen:2003_SFUSW}:
\begin{enumerate}
	\item \underline{\textit{Anomalous Regime ($\gamma = 2$)}} producing a "wheel rim configuration", 
	a central hub with spoke nodes. In this regime, $\langle d \rangle = constant$;
	\item \underline{\textit{Ultra-Small World Regime ($2 < \gamma < 3$)}}: $\langle d \rangle \sim \ln(\ln(N))$ gives rise to the "ultra-small world phenomenon" as a slower growth in $\langle d \rangle$ than random network;
	\item \underline{\textit{Critical Point ($\gamma = 3$)}} for which $\langle d \rangle \sim \frac{\ln(N)}{\ln(\ln(N))}$, marking the passage between the small-world and the ultra-small world;
	\item \underline{\textit{Small World ($\gamma > 3$)}} random networks are recovered, resulting in $\langle d \rangle \sim \ln(N)$.
\end{enumerate}
Thus, \(\langle d \rangle\) is changing with $\gamma$, as the smaller it is, the shorter would be the average distance; but also with $N$, as it is the "ab ovo" hypothesis for having big hubs.

{\large \textbf{Growth and Preferential Attachment}} 

Even with different origins, most real networks display two important features without which it is impossible for hubs to emerge \cite{barabasi::2016networkbook}: growth and preferential attachment (see \autoref{App:RecPLD},\autoref{App:OriginOfPA}). 

In particular, growth is an active process driven by the sequential increasing of the size of the network $N$ as per the addition of new nodes. Rather, a random network assume $N$ to be fixed. \newline
Furthermore, most real networks new nodes prefer to link to the more connected ones, a process called "preferential attachment". On the other hand, random networks wire randomly with other nodes.

Ça va sans dire \label{cit:A.Marzo}, the derided model, developed in \autoref{sec:BA_model}, has to be dynamical and encode a "preferential" probability which changes every time ("event time") there is a modification of the topology. 

{\large \textbf{Final Remarks on Scale-Free}} \\
It worths to recall that, in general, the hosted phenomenon (-a) is complex and affects the graph topology and, in turn, the degree distribution. Rebus sic stantibus \label{cit:D.Massa}, it is sufficient to establish a fair starting point, or EBDs or PLDs class, over which developing gradually ad-hoc features, rather then the meticulous fitting.

As a final remark, many interesting features of scale-free networks, from their robustness to anomalous spreading phenomena, are linked to the $\gamma \in (2,3)$; thus, due to the small average distance which strengthen the considered phenomenon.
For a more detailed dissertation, see \autoref{sec:SFD_details}.

\newpage
\subsection{Barabási-Albert Model}
\begin{figure}[ht]
	\includegraphics[scale = 0.4]{../images/Networks/Barabasi_Albert_Model}
	\centering
	\caption{Formation of a scale-free network \cite{Barabasi:2009_SF_DecadeBeyond}}
	\label{fig:LCD_growth}
\end{figure}

\label{sec:BA_model}
To take advantage of the coexistence of both growth and preferential attachment in the real networks, we proposed a minimal model, the Barabási-Albert model \cite{barabasi::2016networkbook}:
\begin{itemize}
	\item start with $m_0$ nodes randomly connected and a degree at least equal to $1$;
	\item \textbf{Growth:} at each event time add a new node with $m(\leq  m_0)$ stubs which are linked to different nodes;
	\item \textbf{Preferential Attachment:} the probability to wire with a node $i$ depends on the degree centrality, i.e. importance based on the degree:
	\begin{equation}
		\Pi(k_i) = \frac{k_i}{\sum_{j = 1}^N k_j}
	\end{equation}
\end{itemize}

Therefore, preferential attachment has a stochastic nature not a deterministic one. Nevertheless, it increases the appeal of the (already) high-degree nodes, alias \label{cit:S.Sagone} "rich-gets-richer" phenomenon. As a result, while most of the nodes end up having few links, a bunch of nodes become highly connected; thus, performing the role of big hubs. In turn, this translates into a degree distribution which does not decay exponentially, i.e. a power law with $\gamma = 3$ \cite{barabasi::2016networkbook}. 

Empirical studies on networks, such as actor and scientific collaboration networks, have found that the exponent at the numeratore of $\Pi(k_i) \sim k_i^\alpha$ could differ from $1$.
Indeed, there are $3$ paradigmatic kinds of Preferential Attachments (PAs) by varying the exponent $\alpha$: sublinear PAs ($0<\alpha<1$), (linear\footnote{Commonly, the here-called "linear" PAs is just called "preferential attachment" without further specification.}) PAs ($\alpha = 1$), superlinear PAs ($\alpha>1$). Briefly, the sublinear PAs drives to an "stretched exponential distribution" (see \autoref{sec:SFProperties}); the linear to the standard scale-free network; while in the superlinear almost all nodes connects to few super-hubs (winner-takes-all phenomenon).
Hence, only for $\alpha = 1$, a power-law distribution could be recovered, recalling that knowing the high-degree behavior is just a starting point to model the underlying phenomenon. 
In addition, after $t$ event times, the network has gained $t$ new nodes for a total of $N = m_0 + t$ nodes and $m_0 + mt$ links.

\newpage
\subsection{Linearized Chord Diagram}
Having in mind the general purpose and results, a more precise description on the building process would clarify two point left open, i.e. 
\begin{itemize}
	\item the arrangement of the initial $m_0$ nodes;
	\item whether the next $m$ links were added simultaneously or one at the time. This could drive to the formation of multi-links, i.e. conflicting edges, due to assumed independent nature of the new stubs. 
\end{itemize}

These problem are solved with the idea of sequentially adding nodes to the graph(s) created at a previous times.

Fixing $m=1$ for simplicity, start with the empty graph $G_{m}^t = G_1^0$.
At each event time, choose an initial vertex $v_i$ of \\ $G_1^{(t-1)}$ and connect it to the new vertex $v_t$ with probability $p$ such that
\begin{equation}
	p =
	\begin{cases}
		\frac{k_i}{2t-1} & if \quad i \in [1,t-1] \\
		\frac{1}{2t-1} & if \quad i = t
	\end{cases}
	.
\end{equation}

Rephrasing it, connect $v_t$ with $v_i$ with a probability of $\frac{k_i}{2t-1}$ if the nodes are different; otherwise, $\frac{1}{2t-1}$. This method does not forbid the formation of multi-edges and loops, but constraints their number to be negligible as the network grows.
The present technique referred to $m=1$ for an immediate perception. Whether $m > 1$ stubs are involved, add them one at the time, enabling their contribution to the hubs degree.

\section{Annealed Mean-Field Network}
\label{sec:Annealed_MF_Network}
As a benchmark of the network results, we introduced the "annealed-mean-field" network (AMFN) to properly simulate a homogeneous mixing with a fixed degree per node $D$. %For now, it is enough to know that the SIR model allows the susceptible nodes to be infected at a rate $\beta$ and the infected to recover at a rate $\mu$ (see \autoref{ch:sir-models}).
The definition of a AMFN will be given through the practical implementation of a SIR spreading over it, i.e. using a bottom-up approach. Briefly, the SIR model divides the individuals in 3 compartments and accounts for the (direct) infection scheme: $S - susceptible \stackrel{  \beta }{\implies} I-infected \stackrel{  \mu }{\implies}  R-recovered$, where $ \beta \textnormal{ and} \mu$ are the transmissibility and recovery rate.

Indeed, the mean-field SIR model is obtain, at every time-step $t$, with the following scheme: 
\begin{itemize}
	\item select an individual $I_1$ over the pool of infected;
	\item chose $\langle k \rangle$ neighbors at random among all the nodes\footnote{A fair spreading should consider as available contacts all the nodes, i.e. the susceptible but also the already infected or recovered ones. Indeed, all nodes are possible count; while only the susceptible ones could be infected.}, e.g. $I_2$,$I_3$;
	\item try to infect them with probability $\beta$ and to recover with probability $\mu$.
\end{itemize}
With this procedure, whenever the target infected node, e.g. $I_2$, is chosen to pass the pathogen at a future time $t'$, it is highly improbable to re-select its past infector $I_1$, since the probability goes as $D/N$, which typically is much less than one. 
\\Moreover, the number of neighbors is fixed to $\langle k \rangle$, giving to this model the "annealed" characteristic name.

As promised, a AMFN is defined as a (directed) random network whose $D$ links are randomly chosen by each node where the agent lays down. With this technique, the contacts are well mixed, emulating a "mean-field" approximation.

The spreading on network resembles the mean-field model, alias AMFN in our case, whenever either $R_0$ or the long-range connections $p \cdot N$ are high enough to allow the disease, reaching the epidemic state rapidly. Indeed, the comparison between mean-field and network spreading regards the fraction of total infected nodes and not how the nodes are infected: for the mean-field case the neighbors are chosen randomly along the circle; while they are fixed for the chosen network case. For this reason, there could an accordance in the measures considered.



\chapter{The Epidemiological Models}
\label{ch:sir-models}	
The most studied dynamical process on networks is the spreading of an agent. Rather than its common interpretation as a pathogen, this agent could also be considered as an information ("knowledge spreading"), an ask for collaboration, a mobile/computer virus, a business practice, a rumor or a meme, etc. These phenomena acts on different types of networks; are characterized by peculiar time-scales and follow various microscopic-transmission mechanisms. Despite all of these differences, they obey to a common pattern conveniently captured by analyzing their spreading on a network: the quoted graphs (cf. \autoref{ch:network-models}) provides different insights on how links could be created and preserved. Thus, although Satorras and Vespignani started from a diffusion of an epidemic \cite{VespignaniSatorras2001Epidemic}, it is used also in many other human-related fields, as the social sciences and digital security.

This thesis is devoted to the infective epidemiology: a paradigmatic model (SIR model) is let spread on different topologies simulating the COVID-19. In particular, infectious diseases are also called contagious, due to their transmission by a contacts with a secretion of an ill person, e.g. droplets. They account for $43\%$ of the global burden of diseases alongside with other noninfectious diseases (for example obesity, gambling or smoking) which are equally affected by the graph of contacts \cite{barabasi::2016networkbook}.

The epidemiological frameworks, in general, find their roots in two fundamental hypotheses:
\begin{itemize}
	\item Compartmentalization: Each individuals is classified according to a state, or compartment, allowed by the considered model. In particular, the simplest compartments are the following:
	\begin{itemize}
		\item Susceptible (S): vulnerable people which have not been in contact with the disease;
		\item Infectious (I): individuals, which are able the spread the pathogen to their neighbors;
		\item Recovered (R): infected individuals which has are removed from the I-state. No difference among deaths or recovered has been settled\footnote{In reality, this is not the case since death individuals are no more present in the society and leaves space for new contacts; while immunize nodes shields the more inner nodes, by arranging in a sun-like configuration (a susceptible core and spoken "recovered" nodes)}. Thus, many texts use the fair word "Removed" as a definition of the "R".
	\end{itemize}
	
	Driven by some transition probabilities, individuals are able to move among compartments: $S \rightarrow I$ is a random event regulated by the transmission rate ($\beta$); while $I \rightarrow R$ by the recovery rate ($\mu$). Therefore, as for COVID-19, in the early stages a large fraction of the population was susceptible, e.g. $99\%$, called "naive population". Then, the pathogen drives some nodes into the infectious state; while, at the end, to the "Recovered" compartment.

	For convenience, it is also possible to introduce many other compartments to allow for additional states, such as the "asymptomatic" which are able to spread the disease without exhibit symptoms, the first signal of the infection.
	The epidemiological frameworks are generally called as their constitutive compartments characterizing the model, e.g. "SIR" stands for the node path among the susceptible-infectious-recovered states.
	The division in compartments has to be considered at a macroscopic scale, since the aim is to improve the prediction of the number of infected; while not caring about the microscopic infection within the host body; all these details, indeed, are encoded in $\beta \text{ and } \mu$;
	\item Mixing Level: People live and mixes but has a fixed number of total individuals $N$, i.e. no death or birth are taken into account (see \cite{Newman:2010_Net:AnIntro}). Hence, two possible hypothesis on how the individuals, restricted to their compartments, could get exposed to the disease are the:
	\begin{itemize}
		\item \textit{homogeneous mixing}: this hypothesis assumes that each individual has the same chance of interact with another one, e.g. an infectious. For this reason, it is also called the "fully-mixed", "mass-action" or "mean-field" approximation. Indeed, the specific degree of a single node is not taken into account; rather, the number of infectious-contacts per node is fixed. In turns, this could be seen as a "field" of mean infectious spikes which attack the susceptible.
		Only the "global" scale is present;
		\item \textit{heterogeneous (degree-based) mixing}: this approach hypothesizes that the individuals are grouped by their degree of contacts $k$ and considered "statistically" equivalent within that class: this is a finer mean-field approximation and could be improved by considering an "individual-based" approximation. 
	\end{itemize}
\end{itemize}
It seems pretty natural that the "fully-mixed" hypothesis is false at some extent.
In particular, it would be possible to observe that for small "epidemic strength" ($R_0$) the network structure deeply plays a role (see \autoref{ch:Results}), since individuals may transmit a pathogen only to (local) neighbors. Nevertheless, if a pathogen is "strong" enough the total number of infected are comparable to the one of a "mean-field" approach.

The model which may be composed with the quoted compartments are the $SI$, the $SIS$ and the $SIR$ (the case of study). In detail, the $SI$ model accounts for the fact that it would be impossible to recover from the disease, e.g. herpes; the $SIS$ model for diseases where it would be not possible to waning immunity, thus, returning susceptible, e.g. the HPV, generic flu; the $SIR$ where the last state is the gained immunity, e.g. the most strain of seasonal influenza or chickenpox.

Before gaining the details on the two mixing hypothesis, it is worth defining the variables involved in the two approach.
In particular, by denoting the total number of individuals $N$, $s(t) := S(t)/N$ is the number of susceptible (healthy) normalized with $N$; $i(t):=I(t)/N$ is the fraction of already infectious persons; while $r(t) := R(t)/N$ the recovered one. In this way, the "closed population" constraint translates into $s(t)+i(t)+r(t)=1$ at any time $t$. 
Thus, at the initial time ($t = 0$), a seed of infected has to be injected to start the infection, e.g. $I(0) := 10$. Therefore, $s(0) = 1 - i(0)$ since the recovered are $r(0) = 0$.
Furthermore, let assume that the likelihood of transmitting the disease to a susceptible per unit time is $\beta$, i.e. the "transmission rate"; while the "recovery rate" is $\mu$. Hence, defining the \textit{basic reproduction number}  $R_0 := \beta \langle k \rangle / \mu$, this quantity embodies the number of secondary infected in a naive population. Indeed, the probability that a node $i$  becomes infected during a time interval $dt$ is $1-(1-\beta dt)^{k_i} \sim \beta k_i dt$, assuming $ \beta dt << 1$ \cite{barabasi::2016networkbook}. Similarly, the probability that an infector will infect a susceptible person in the next $d/dt = \frac{1}{ \mu dt}$ times is $\beta_d:= 1-(1-\beta \langle k \rangle dt)^{d/dt} \sim \beta \langle k \rangle d = \beta \langle k \rangle/\mu$, where $ \beta \langle k \rangle dt << 1$ and $k_i \sim \langle k \rangle$, as it is the case for random networks \autoref{ch:network-models}. The latter result could be understood as the complementary probability of not having a "risky" interaction for $d/dt$ trials \cite{Thurner::Appendix_NetBasedExpl}. 

The final goal would be to find the evolving number of new daily infected at each time (a slight modification of $I(t)$). Moreover, since the disease-spreading is a stochastic process, it would be the average of the various scenarios--in our case 50.

\newpage
\section{Homogeneous Mixing}

\begin{figure}[ht]
	\includegraphics[scale = 0.38]{Ch_TheEpidModels_Methodology/Homogeneous_MF_SIR.png}
	\caption{Mean-Field SIR with $N = 10^{3}, \langle k \rangle = 5, \beta = 0.2,  \mu = 0.2$.As shown, at the end of an epidemic, i.e. $ i(t) = 0$, a non-zero fraction of susceptible survives which, in turn, accounts for a $ r(t_{end}) = 1- s(t_{end}) \neq 1$ fraction of recovered nodes.}
	\label{fig:MF_SIR}
\end{figure}

Within this class of hypotheses, people mingle and meet completely at random: an infected person can be in contact with {\large $\frac{\langle k \rangle \, S(t)}{N}$} susceptible individuals. Taking into account that at a time $t$ there are $I(t)$ infected which spread the disease at a rate $\beta$\footnote{In many text books, e.g. \cite{Newman:2010_Net:AnIntro}, the $\beta \langle k \rangle$ total rate considered in the following is just $\beta$.} and recovers at a rate $\mu$,
the SIR equations are the following \cite{Newman:2010_Net:AnIntro}

\begin{equation}
	\begin{cases}
		\frac{ds}{dt} = -\beta \langle k \rangle s i \\ \\ 
		\frac{di}{dt} = \beta \langle k \rangle s i - \mu i = \beta \langle k \rangle \, (1-i-r) \, i -\mu i = \mu( R_0 s - 1) i  \\ \\
		\frac{dr}{dt} = +\mu i
	\end{cases}
	\label{eqs:homo_SIR_MF}
\end{equation} 
where it has been exploited the fact that the population is closed, i.e. no death/births are considered. This translates into $s+i+r=1 \quad  \forall t$ or even $ ds/dt + di/dt + dr/dt = 0 \quad \forall t$. In addition, the right most equality shows how the definition of $R_0$ could be recovered directly from the equations. Finally, note the removal of the time dependence since $s(t), i(t), r(t)$ is understood.

To solve \autoref{eqs:homo_SIR_MF}, by integrating "division" of the third equation and the first equation
\begin{equation}
	s(r) = s_0 e^{-\beta \langle k \rangle r / \mu}\
\end{equation}
where it has been required that $s(t=0)=s_0$ arbitrarily. 
Then, substituting $s(r)$ into the second equation \cite{Newman:2010_Net:AnIntro}, 
\begin{equation}
	\frac{dr}{dt} = \mu \, (1-r-s_0e^{-\beta \langle k \rangle  r/\mu}).
	\label{eq:r_SIR_MF}
\end{equation}

Now, solving this equation for $r$ gives, in turn, the possibility to find $s$ and, thus, $i$.
In principle,
\[
	t = \frac{1}{\mu} \int_0^r \frac{du}{1-u-s_0e^{-\beta \langle k \rangle  u/\mu}}.	
\]
The initial conditions can be chosen arbitrarily but the most suited is to fix a small number $c << N$ of infected individuals such that $s_0=1-c/N\approx1$, $i_0:=i(0)=c/N\approx0$ and $r_0\approx0$.

Unfortunately, this equations have no closed form, but special insights cloud be reached by looking at the plot of the numerical solutions of \autoref{eqs:homo_SIR_MF}.


The case where $R_0 < 1$ represents the scenario when the pathogen will die out fast from the population, i.e. a limited spreading occurs. 
\\Indeed, at early times $t\approx 0 \implies i(0)\sim 0, r(0)\sim 0$. 
\\Therefore, \cite{barabasi::2016networkbook} \[i(t\approx 0) \sim i_0 \, e^{(\mu(R_0 -1)t)}.\]
On the other hand, the SIR features are more involved if $R_0 > 1$:
\begin{enumerate}
	\item $s(t)$ is monotonically decreasing; while $r(t)$ is always increasing; 
	\item $i(t)$ increases depending on the availability of susceptible: at early times the increasing is exponential; then, deflect and decreases on the way to the end of the epidemic, i.e. $i(t_{max})=0$;
	\item $s(t_{max}) > 0$ since when $i \to 0$ there are no infected individuals left to infect the remaining susceptible. Formally, $r(\infty):=\lim_{t \to \infty} r(t)$ is the total size of the outbreak, i.e. the total number of individuals who ever catch the disease. 
	
	Setting $dr/dt \stackrel{!}{=}0$, $s_0\simeq1$ ("naive population") and using \autoref{eq:r_SIR_MF}, the solution of 
	\begin{equation}
		r = 1 - e^{-\beta \langle k \rangle  r /\mu}
		\label{eq:r_SIR_MF_GiantComp}
	\end{equation}
	is precisely $r(\infty)$. Therefore, whenever $r(\infty)\neq1$ is a sign that "herd-immunity" is reached, alongside with $1-r(\infty)$ susceptible left;
	\item the characteristic time \[ \tau  = \frac{1}{\mu(R_0-1)}\] is the time needed to reach about the $36\%$ of the population and it is the inverse of "disease velocity", which further depends both on the possibility to infect and the average nearest neighbors. With this new measure of epidemics, it would be possible to recover the previous result observing that there is a spread iff $\tau > 0$, i.e. $R_0 > 1$.
\end{enumerate}

Interestingly, it would be possible to recognize $S \leftrightarrow r$ and $D:= \langle k \rangle \leftrightarrow \beta \langle k \rangle/\mu$ (\autoref{eq:r_SIR_MF_GiantComp}) where the "left" quantities are describing the percolation phenomenon and the "right" ones the SIR spreading describes. In this way, the equation \autoref{eq:r_SIR_MF_GiantComp} regulates the size $S$ of the giant component of a Poisson random graph. In particular, the SIR infection of neighboring nodes could be seen as a bond percolation process of an agent, e.g. water, which propagates according to the same probability distribution \cite{Newman:2010_Net:AnIntro}, \cite{barabasi::2016networkbook}. 
This analogy allows to double the interpretations of the results of \autoref{eq:r_SIR_MF_GiantComp}.
Indeed, in percolation theory, the giant component size $S$ depends on the $D$ average degree of links per node when $N \to \infty$ . 
\\Therefore, the final outbreak size $r(\infty)$ depends on $\beta \langle k \rangle / \mu$ and the \textit{basic reproduction number} is, conveniently, defined as $R_0 := \beta \langle k \rangle / \mu$. 
\\Moreover, $r(\infty)$ goes continuously to $I(0)/N \sim 0$ as $1^{+} \leftarrow R_0$; while it is constantly $I(0)/N$ for $R_0 \to 1^{-}$. Analogously of the appearance of the giant component, the point where (first-order) phase transition occurs, i.e. $R_{0c} = 1$, is called epidemic transition. Thus, $R_{0c}$ separates the "epidemic" ($R_0 > R_{0c}$) from the "non-epidemic" ($R_0 < R_{0c}$) regime.
The $R_0$ dependence of $r(\infty)$ has to be somehow expected since if an infection has less transmissibility than recovery ($R_0 <1$), the pathogen would die out fast. On the way to $R_{0c}$, an increasing of the $\beta / \mu$ ratio would describe a less strong epidemic, which consecutively provide a minor $r(\infty)$.

To be precise, $R_0$ is the number of second infections in a naive population, i.e. at early times $t \approx 0$: $\beta/\mu = \beta \tau$ is the probability to infect over a time-interval of $\tau$. Thus, $R_0$ is an estimate of the slope of the curve describing the infection at the start of the epidemic. Furthermore, it is a rough marker of an exponential growth\footnote{For SI model, $\lim_{\mu \to 0} R(t) = \infty$ since every infected could arbitrarily infect all the other nodes. In a real scenario, $R_0 \, (\leq N')$ is finite, as the size $N'$ of a population is finite.}. (for $R_0 > 1$) or vanishing of the pathogen (for $R_0 < 1$) since $I(t) \approx R_0^{t/d}$. On the other hand, $R_0 =1$ is not indicative of whether this slope is going to increase until $r=1$ (pandemic scenario), decreases fast guiding into $r(\infty)<<1$, or both resulting in $r(\infty)<1$. Indeed, for a more precise signal on the spreading behavior depending only by the initial conditions, higher-order features of the underlying network should be taken into account. A new reproduction number is going to be proposed in the next section.

\newpage
\section{Heterogeneous Mixing}
\label{sec:degree-basedMF}
\begin{figure}[ht]
	\includegraphics[scale = 0.38]{Ch_TheEpidModels_Methodology/D4_ws_graph_sir.png}
	\caption{Degree-Based SIR using Erdös-Rényi Graph with $N = 10^{3}, p = 0, \langle k \rangle = 4, \beta = 0.3, \mu = 0.25$. $R_0 \sim 4.8 > R_{c-net} \sim 1.2$ where $R_{c-net}$ is defined in \autoref{eq:def_R_cnet}. Thus, the pathogen could evolve in the network. The dotted evolution are a obtained by solving the \autoref{eqs:homo_SIR_MF} for the standard compartments S-I-R; while the continuum line accounts for the daily new infected $ C(t)$, the total cases $ \pi(t) = P(t)$ and the susceptible as $ \tilde{s}(t) = 1 - \pi(t)$. Eventually, the recovered nodes shifted by the average recovered time $d = 1/ \mu$ are similar but not the same of the total cases (solid green line). Lastly, by means of the \autoref{eq:picrit_network}, the green star ($Crit (t_c,P_c)$) is a good estimate of the maximum of $ i(t)$, as it predicts the critical time $ t_c$ and the value of $P_c$ correctly.}
	\label{fig:DB_SIR}
\end{figure}
As described in the previous chapter, within a well-mixed population, every node could infect, at any time, $\langle k \rangle$ susceptible neighbors. This is not the case for a pletora of real networks, e.g. Barabási-Albert model as they are "scale-free", namely $\langle k^2 \rangle$ typically diverges for the \textit{degree exponent} $\gamma \leq 3$. Thus, imposing that each individual must have $\langle k \rangle$ contacts, it drives to a model that underestimate the number of infected. This, in turn, could have worser effect than overestimating it.

An improvement would be to consider that if a pathogen spreads on a network, the individuals with more links are more likely to be infected. Therefore, the nodes are further classified according to their degree and assumed statistically equivalent within their class. This approximation is, thus, called degree-based mean-field (DBMF) approach \cite{barabasi::2016networkbook}. Indeed, there would be $3 \cdot k_{max}$ classes, i.e. $3$ compartments for each degree, but there are no further differences among nodes with the same degree $k$. 

Formally, the total fraction of infected is $i(t) = \sum_{k=0}^{k_{max}} p_k i_k(t)$. Iterating the same decomposition on the susceptible $ s(t)$, recovered $ r(t)$ and substituting them into the \autoref{eqs:homo_SIR_MF},
\begin{equation}
	\begin{cases}
		\frac{ds_k}{dt} = -\beta  k  s_k \Theta_k \\ \\ 
		\frac{di_k}{dt} = \beta  k  s_k \Theta_k - \mu i_k = \beta  k  \, (1-i_k-r_k) \, \Theta_k -\mu i_k \label{eqs:SIR_degree-based} \\ \\
		\frac{dr_k}{dt} = +\mu i_k
	\end{cases}	
\end{equation}
ehere $ \beta$ is defined as the transimission rate and $ \mu$ the recovery rate.
Note, in addition, that these equations are valid for $k = 0,\cdots,k_{max}$ and that we suppressed the $t$ dependece for easiness of notation.
Furthermore, in \autoref{eqs:SIR_degree-based}, the \textit{density function} at $ t \approx 0$ is defined
\begin{equation}
	\Theta_k(t) = i_0 \frac{\langle k \rangle - 1}{\langle k \rangle} e^{t/\tau}.
\end{equation}
Namely, it represents the fraction of infected nodes surrounding a susceptible individual with degree $k$ at early times. Its explicit expression would be recovered shortly but note that, a priori, it can depend both on $k$ and $t$.

Lastly, the \autoref{eqs:SIR_degree-based} depend, by construction, on $k$ but the $\langle k \rangle$ dependence is no more present. In turn, the network structure is encoded into the $\Theta_k(t)$ factor, which in the homogeneous case was $i(t)$.
Before tackling the problem of solving them, it is necessary to explicitly recover the $\Theta_k(t)$ factor.

\subsection*{The Density Function}
The density function, as reported before, provides the fraction of infected nodes neighboring a susceptible node of degree $k$. In fact, as we are going to prove, this estimate accounts for all the infectors connected with an arbitrary number of hops, since it has no upper-limit. 

To start with, assume that the underlying topology has no degree correlation among nodes, i.e. vertexes are connected at random, thus an hub could equally connect with another hub or a lower-degree node. These network are called \textit{neutral networks}. Hence, the probability of a vertex to point to a degree $k'$ node is the excess degree 
\begin{equation}
	q_{k'} = \frac{k' p_{k'}}{\langle k \rangle}
	\label{eq:q_excess_degree}
	.
\end{equation}
Indeed, the probability of choosing a degree-$k'$ node is $p_{k'}$ times $k'$, since it owns $k'$ stubs to connect with. As $q_{k'}$ should be a probability, the denominator comes to match the $\sum_k q_k \stackrel{!}{=} 1$ constraint.
The \autoref{eq:q_excess_degree} is local, random and linear in the "bias term" $k$. Therefore, as reported in the \autoref{sec:linear_pa_link_selection}, it is the starting point to build the (linear) preferential attachment.

For a disease to spread, it is assumed that at least one of the spokes of the infected node is connected to the its infector node: only $k'-1$ links would be available for the contagion.
Therefore,
\begin{equation}
	\Theta_k(t) = \frac{\sum_{k'} (k'-1)p_{k'}i_{k'}(t)}{\langle k \rangle} = \Theta(t)
	\label{eq:Theta_generic}
\end{equation}
where the rightmost equation explicitly display the independence on $k$.

In order to capture the time-dependence of $\Theta(t)$, it would be taken advantage of the SIR model, following these steps: differentiate the \autoref{eq:Theta_generic}, insert \autoref{eqs:SIR_degree-based} and consider $1-i_k-r_k \approx 1$, which it is the case at early times. This procedure yields \cite{barabasi::2016networkbook}

\begin{equation}
	\begin{cases}
		\frac{d\Theta}{dt} = \left( \beta\frac{\langle k^2 \rangle - \langle k \rangle}{\langle k \rangle} - \mu \right) \Theta \\ \\
		\Theta(0) \stackrel{!}{=} i_0 \frac{\langle k \rangle -1}{\langle k \rangle } \qquad \text{I.C.}
	\end{cases}
\end{equation}
which solving by $\Theta$ yields 
\begin{equation}
	\Theta(t) = C e^{t/\tau}
	\label{eq:Theta_SIR_network}
\end{equation} 
where
\begin{equation}
	C := i_0\frac{\langle k \rangle -1}{\langle k \rangle}  \qquad \text{and} \qquad
	\frac{1}{\tau} := \beta \left(\frac{\langle k^2 \rangle}{\langle k \rangle}-1\right)
	-\mu.
	\label{eq:tau_SIR_networks}
\end{equation}

\begin{figure}[t]
	\includegraphics[scale = 0.38]{../images/Ch_TheEpidModels_Methodology/ER_Epid_Threshold.jpg}
	\centering
	\caption{Epidemic Threshold $\lambda_c := \beta_c / \mu$ of a ER Graph with $N = 10^{4}, \beta \in [0,0.4], \langle k \rangle \sim 10, \mu = 0.8$. Using $ R_0 = \lambda \cdot \langle k \rangle \stackrel{!}{=}1$, the departure from zero happens near $\lambda_c = 0.1$, due to finite size effects. Thus, $\lambda < \lambda_c = 0.1$ implies a fast-decaying pathogen.}
	\label{fig:ER_Epidem_Thr}
\end{figure}

The onset at $t \approx 0$  of an epidemic is possible if, and only if, $\tau > 0$. This, further, implies that the number of infected nodes grows exponentially with time (cf. \autoref{eq:Theta_SIR_network}). This threshold depends on the ratio $\beta / \mu$ definedthe \textit{biological factor} $ \lambda := \beta/ \mu$, since it depends only on the epidemic parameters.  
Indeed, separating the \textit{biological factor} $\lambda$ from the network features, 
\begin{equation}
	\lambda > 
	\lambda_c
	\Rightarrow
	R_0 > R_{c-net} \geq 0
	\label{eq:lambdac_Rc_netSIR}
\end{equation}
where we have defined the \textit{critical reproduction number}  $ R_{c-net}$ as
\begin{equation}
	R_{c-net} := \frac{ \langle k \rangle^2 }{\langle k^2 \rangle-\langle k \rangle}
	\label{eq:def_R_cnet}
\end{equation}
and the "epidemic threshold" $ \lambda_c$ as
\begin{equation}
	\lambda_c:=\left[ \frac{\langle k^2 \rangle}{\langle k \rangle} - 1\right]^{-1}.
	\label{eq:def_lambdac}
\end{equation}
The left-most side of \autoref{eq:lambdac_Rc_netSIR} underlines that the natural decay of a pathogen, i.e. fixed $ \beta$, depends on the degree-heterogeneity ($\langle k^2 \rangle$), $ \mu$  and $\langle k \rangle$. \\ 
As $\lambda_c$ is defined as a "threshold", the final outbreak size, namely the total recovered $r(\infty)$, is not linear by increasing the spreading rate; rather, it goes under a phase-transition exceeding $\lambda_c$. This behavior is shown in \autoref{fig:ER_Epidem_Thr} for a (random) Erdös-Rényi model. 
\\For a \underline{\textit{Poissonian network}} $\langle k^2 \rangle = \langle k \rangle (\langle k \rangle + 1 )$\footnote{As a comparison, for a Poisson-distributed random variable $k$ holds $\sigma_k^2 = \langle k^2 \rangle - \langle k \rangle^2 = <k>$. Thus, $\langle k^2 \rangle = \langle k \rangle^2 + \langle k \rangle$}, 
resulting in the \textit{epidemic threshold} $ \lambda$ of a random network \cite{barabasi::2016networkbook}
\[ \lambda_c = 
	\frac{1}{\langle k \rangle} \Rightarrow R_{c-net} = 1.
	\label{eq:Rcnet=1}
\]
where a general definition of the \textit{critical reproduction number} $R_{c-net} $ could be find in \autoref{eq:def_R_cnet}.
Since the average number of contacts $\langle k \rangle$ is finite, $\lambda_c$ plays the role of a true threshold, which separates the epidemic regime to the non-endemic regime according to \autoref{eq:lambdac_Rc_netSIR}.
\\For a \underline{\textit{scale-free network}}, the second moment $\langle k^2 \rangle \stackrel{N \to \infty}{\longrightarrow} N^{3-\gamma} \to \infty$ diverges for large networks, namely $N\to \infty$, since $\gamma < 3$ (see \autoref{sec:SFProperties}). In this limit, $\lambda_c, \tau \to 0$ showing, respectevely, the fact that even low-transmissibility disease are successfully spreading in the population and are instantaneous. In reality, the finite size of the network forces $ \lambda_c \textnormal{ and } \tau$ to be small but finite. Moreover, the average path length $ \langle d \rangle \to 0$ in the same limit, since the hubs become bigger as the number of nodes grows. Hence, the hubs play the role of the super-infectors that enable the pathogen to persist and diffuse within the population. 
\\The exposed examples are at the extrema of the plethora of graph models. For many other networks exhibiting an enanchement of the second moment $\langle k^2 \rangle > \langle k \rangle (\langle k \rangle +1)$, there is a reduction both of the epidemic threshold and the characteristic time of the disease. 
In conclusion, in contrast with the "mean-field" predictions, which drives to $ \lambda_c = 1 / \langle k \rangle$ , in a heterogeneous SIR model the same quantity depends according to \autoref{eq:def_lambdac}. Thus, it varies, by changing the underlying topology.

To sum up, for $\lambda>\lambda_c$ the total epidemic outbreak size $i(t \to \infty) \neq0$; while for $\lambda < \lambda_c$, $i(t \to \infty) = 0$, since the pathogen is not strong enough to reach an endemic state.
Moreover, $\lambda_c = 0$ for a "typical"($\gamma<3$) large scale-free network; while $\lambda_c \neq0$ for the random networks.

\subsection*{About the SIR equations}

No analytic solution exists for the equations of the SIR model. Furthermore, even the early times analysis exhibits some technical difficulties which demands for the numerical simulations of the ODEs of \autoref{eqs:SIR_degree-based}.

\subsection*{Early Times}
At early times ($t\approx 0$) the recovered and the susceptibles individuals are negligible, namely $r_k, s_k\approx0$. Therefore, according to \autoref{eqs:SIR_degree-based} and \autoref{eq:Theta_SIR_network}, the fraction of infected is \vspace{3mm}
\begin{equation}
	\begin{cases}
		\frac{di_k}{dt} = - \mu i_k + i_0 \beta k \frac{\langle k \rangle -1}{\langle k \rangle } e^{t/\tau} \\ \\
		i(0) \stackrel{!}{=} i_0 \qquad \text{I.C.}
	\end{cases}
\end{equation}
whose, first equation, could be straightforwardly rewritten as
\begin{equation}
	\frac{d i_k}{dt} + \mu i_k - i_0 B e^{t/\tau} = 0
\end{equation}
where $i_0 B(k) := i_0 \beta k \frac{\langle k \rangle -1}{\langle k \rangle }$.

Hence, the solution of the last equation assumes the form
\begin{equation}
	i_k(t)=i_0 \left[C_1(k)e^{t/\tau} + C_2(k) e^{-\mu t}\right]
\end{equation}
where we defined as \vspace{3mm}
\begin{equation*}
	\begin{cases}
		C_1(k):= \frac{B(k) \tau}{1+ \mu \tau} = \lambda \cdot \left[k\left(\frac{\langle k \rangle -1}{\langle k \rangle }\right)\right]
		\cdot \frac{1}{\tau} \\ \\
		%\frac{\beta}{\mu+\tau^{-1}} \left(\frac{\langle k \rangle -1}{\langle k \rangle }\right) k \\ \\
		C_2(k):= 1 - C_1(k)
	\end{cases}
\end{equation*}
Note how $C_1(k)$ is determined by the contribution of the pathogen ($\lambda:=\frac{\beta}{\mu}$), the network and the interaction among the two ($\tau^{-1}$).

In this way, the initial exponential-phase has two contribution: the first, which grows in time, due to an interplay among the disease and the underlying network; the second is diminishing the number of infected according to the recovery of infected individuals.

For \textit{scale-free networks}, the "degree exponent" $\gamma<3$ accounts for $k$ and $\tau^{-1}$ to diverge as the network grows. This, in turns, gives birth to a peculiar limit of $C_1(k)$: \vspace{3mm}
\begin{equation}
	C_1(k)\propto \tau k \propto \frac{1}{\int k^2 p_k dk}k  \to 0 \cdot \infty.
	\label{eq:limit_C1}
\end{equation}
The underlying probability degree distribution $p_k$ has to be exploited in order to solve the limit \autoref{eq:limit_C1} and gain epidemiological insights.

On the other hand, the networks, such that $k \sim \langle k \rangle$, e.g. Poissonian ones, find a good approximation in the random limit, i.e. when the individual contacts are limited by a cost-benefit constraint as the power-grids. Therefore, also $\langle k^2 \rangle $ is bounded and
\begin{equation}
	i_k(t) \approx i(0)  + \left(C - C_2(\langle k \rangle )\mu \right) t
\end{equation}
where $C:= \frac{\beta (\langle k \rangle -1)}{\tau}$ since $\langle k \rangle \approx k$ and $e^{at}\approx1+at$ as either $t\approx0$ or $a \approx 0$.

Summarizing, the degree-block approximation is itself a "mean-field" framework, since all the nodes with degree $k$  are equivalent. However, this approach, although simplifying the calculations, it is not completely correct. Indeed, for the SIS model (with reinfection), the formal mathematical calculations drive to a vanishing epidemic threshold even for $\gamma>3$ \cite{barabasi::2016networkbook}.

\textbf{A new quantity for the epidemic severity} 
\label{sec:def_epidemic_severity}
As it is clear from \autoref{fig:sir_RegLat_D61430}, $R_0$ should be modified as it represents only the initial strength of the pathogen without considering the underlying topology, e.g. the "long-range" contacts $pN$. Concretely, it could drive to completely different scenarios where the epidemic either brutally invade the population or is limited to a small percantage. Thus, we introduced a new "severity quantity" $ \Delta R_0 (\delta)$ defined as
\begin{equation}
	\Delta R_0 (\delta):= \frac{R_0 - R_{c-net}}{\delta}
	\label{eq:def_DR0delta}
\end{equation}
where $\delta:=\langle l \rangle $ is the average path length.

In particular, the dependence on the "network effectiveness" $\frac{1}{\delta}$ captures the fact that as long-range nodes increase the epidemic is favored, since there are allowed the "jumps" into a new pool of susceptible.

\section{Order Parameter}
\label{sec:OrderParam4LinContagion}
According to \autoref{eq:lambdac_Rc_netSIR}, a disease spreads at early times if the average number of contacts $D := \langle k \rangle$ exceed the \textit{critical average degree} $D_c$ defined by imposing $R_0 = \lambda \cdot D \stackrel{!}{=} 1$. \\Formally, 
\begin{equation}
	D_c := \frac{R_{c-net}}{\lambda}
	\label{eq:earlytimes_Dc}
\end{equation}
where the \textit{critical reproduction number} $R_{c-net}$ is defined in the \autoref{eq:lambdac_Rc_netSIR}. Thus, the exponential growth of the number of cases is recovered for $ D > D_c$. Moreover, whether the network is not so heterogeneous, $R_{c-net} \sim 1$, which becomes exact ($=1$) for a Poissonian distribution (see \autoref{eq:Rcnet=1}). In general, as for the reported networks (\autoref{ch:Results}), \autoref{eq:earlytimes_Dc} yields $D_c \sim \frac{ R_{c-net} \mu}{\beta}$ for $ t \approx 0$. The Barabási-Albert model is the only exception where $D_c$ is smaller, due to the high heterogeneity of its underlying degree distribution. 

A rough estimate of the daily new cases is $C(t) \propto R_0^{t/d}$ where $d$ is the average time an individual remains infected, namely $ d:= 1/ \mu$. Generally, since the transmission rate $ \beta \textnormal{ and the recovery rate }  \mu$ are fixed, the exponential growth occurs for $D > D_c$. For $D \sim D_c$, the number of total infected $ \pi(t)$  will behave critically, i.e. $\pi(t) \propto t^{\alpha}$, where $\alpha \in (1,2)$ for a simply connected (no multiedges or loops) short-range network embedded in dimension $2$. More in detail, $\alpha \sim 2$ for a network resembling a regular lattice in $2$ dimensions, since $C(t) \propto t^2$ is proportional to the covered area of the infection front; while $\alpha \sim 1$ for a tree or a collection of 1-dimensional chains, as the front spreads linearly as a flame along a fuse, i.e. $C(t) \propto t$. For this reason, we would refer to the \textit{"fuse-model"}  as a 1D-grid with $D$ neighbors per node. Thus, the Overlapping Poissonian small-world network (alias OPSW) of \autoref{fig:netmod_O-PSW} is an extension of this model since it allows for a Poissonian distribution of the number of contacts per person \cite{Thurner::NetBasedExpl}. 
In between these regimes, the specific $\alpha$ is influenced and shaped by non-pharmaceutical interventions (NPIs).

Schematically, for a fixed pathogen with $\lambda = \beta d$ and the rewiring probability $p$ , $R_0 \propto D$ and $D_c$ characterizes the nature of the epidemics as \cite{Thurner::NetBasedExpl}
\begin{itemize}
	\item for average number of contacts $D>D_c$, the situation starts to resemble a mean-field with the fraction of total cases $\pi(t) = R(t+d)$, where the shift in time is due to the fact that the average time of one infected to recover is $d$ days. In addition, the number of infected assumes a typical bump in the immediate days after the beginning and it is an evident mark of an exponential growth both in the daily new cases $C(t) \text{ and the total cases} \pi(t)$ \autoref{fig:sir_O-PSW_D14_p0}.
	\item for $D<D_c$, the sub-exponential behavior is recovered with the consequence that the final outbreak size is lower than the mean-field one \autoref{fig:sir_O-PSW_D5_p0}.
\end{itemize}
A proper way to characterize this transition is per the definition of the order parameter \cite{Thurner::NetBasedExpl} as the standard deviation (SD) of the new daily cases $ C(t)$ , after excluding all the days without new cases.
\\Formally,
\begin{equation}
	O := SD(C(t)) = 
	\begin{cases}
		0 \qquad \text{if $C(t) = constant$}\\\\
		\neq 0 \qquad \text{otherwise.} 
	\end{cases}
	\label{eq:def_OrdP}
\end{equation}
\\In other words, a linear growth of the total cases $ \pi(t)$ is possible only when the new daily cases are constants, since $\pi(t) \propto t$. In most of the curves present in \autoref{ch:Results}, the exponent $ \alpha < 1$, but still the epidemic develops a "sub-exponential growth" (gree curve) which is comparably interesting since it deviates from the mean-field solution (orange curve) (\autoref{fig:sir_RegLat_D61430}).  
For $D > D_c$, $C(t)$ develops a defined peak which, in turn, produces an enhancement of the $SD$ alongside with an exponential growth of the total cases, similarly as in the mean-field case. The evolution of the epidemic curves at different $D$ is reported in \autoref{fig:sir_RegLat_D61430}. Hence, a strong deviation of $SD$ from zero signals the presence of a nonlinear increase of $\pi(t)$.

\subsection*{Analytical critical degree}
In Statistical Mechanics, the dimensionality of a system is crucial to legitimate the mean-field approximation: the Ising Model is well modeled by a mean-field in a dimension $d \geq 4$ as it captures its phase transition. Similarly, on networks with non-regular topologies, the average degree (if the network is not "scale-free") $D$ can set a threshold/scale above which the mean-field solution will be a good approximation of the phenomenon. Moreover, the \autoref{eq:earlytimes_Dc} is valid only for early times. Hence, to account for the time evolution, it should be considered $R(t)$ as defined in \autoref{eq:def_Rt}. In turn, this will allow to account for an estimate of the average contaged neighbors $n(t)$\footnote{This quantity considers both the current and the past infected, i.e. infected and recovered or, with a twisted lettering, the "non-susceptible" individuals.}  and, therefore, obtain a different $D_c$ for a Erdös-Rényi and a "fuse" models: as $n(t)$ increases, also $ D_c$ has to be larger for an exponential growth.

%Taking care of the dimensional effects, it is worthwhile to define the curvature of the epidemic front as $ \mathcal{K}:= \pm 1/\mathcal{R}_{front}$ where $\mathcal{R}_{front}$ is the radius of the fitting circle of the front.  $\mathcal{K}>0$ for a front spread in a circular shape; while $\mathcal{K}<0$ if the front surrounds an island of susceptible. For a grid, e.g. a fuse model or a lattice grid, the curvature is $\mathcal{K}=0$.    

In particular, as the epidemic grows an contaged person would have at least one infected neighbor, that is its infector. Hence, we will call \textit{effective reproduction number} the $R(t)$ defined as \cite{Thurner::Appendix_NetBasedExpl}
\begin{equation}
	R(t) := (D-n(t))\lambda,
	\label{eq:def_Rt}
\end{equation}
where $n(t)$ is the average number of not-susceptible neighbors. 
Other way around, the fraction of susceptible is defined as $\nu(t) := 1 - n(t)/D$. 

Since the "fuse-model" accounts only for local interactions, $n(t)$ represents the fraction of susceptible individuals in the neighborhood of the infection front; while for the ER model, $n(t)$ is the fraction of the entire population. Therefore, a low infectivity ($\nu(t)\sim1$) implies that for an Erdös-Rényi model, $n(t) \sim 1$, since an infected is surely infected to its infector. Still, for a "fuse-model" $n(t) = (1-\nu(t))/D$ where $ \nu(t)\sim 1/2$ as, intuitively, only the individuals over the epidemic front remain susceptible and on average are half of the network.
\\Hence, whenever $n(t)$ is known, the critical degree $ D_c$ assumes the form
\begin{equation}
	D_c = n(t) + \lambda^{-1}.
	\label{eq:D_c_analytical_discussion}
\end{equation}   

In the following section, it is going to be derived $n(t)$ and, in turn, $D_c$ for the ER model (see \autoref{ch:network-models}) and the tree- or chain-like "fuse model" \cite{Thurner::NetBasedExpl}.

\subsection*{Erdös-Rényi Graph}
For a Erdös-Rényi random graph with "rewiring probability" $p$, the average degree of contacts is $D = Np$. Hence, the number of not susceptible nodes near an infected vertex is 
\begin{equation}
	n(t) \sim 1 + (D-1)(1-\nu(t))\
	\label{eq:n(t)_ER}
\end{equation}
where $1$ is the past infector of the chosen node added with the remaining neighbors which are infected or recovered \cite{Thurner::Appendix_NetBasedExpl}. This expression yields $ n(t) \sim 1$ for a low infective epidemic as $ \nu \sim 1$. 
\\Inserting the obtained $n$ in \autoref{eq:D_c_analytical_discussion}, 
\begin{equation}
	D_c^{ER} = 1 + \frac{ \lambda^{-1} }{ \nu(t)}.
	\label{eq:Dc_ERenyi}
\end{equation}
In this manner, $D_c^{ER}$ increases as $\nu(t)$ drops: more contacts are needed to spread a disease if there are less susceptible available. However, for low infection or at the starting of the epidemics $\nu(t) \sim 1$ and the $ D_c$ is fixed by chosing the biological factor $ \lambda$. 
%\\Other way around, for a fixed $D$ since $\nu(t) \leq 1$,
%\begin{equation}
%	\nu(t)_c = \text{min}\left(1, \frac{1}{(D-1)rd}\right)
%	\label{eq:nu_c_ER_model}
%\end{equation} 
%which diminish as $D$ increases: if, on average, $\nu(t)' < \nu(t)$ it is likely to have a diffuse pathogen since $D_c' >  D_c$. 
%Moreover, $\nu(t)_c = 1$ provides that a pathogen dies out whenever, at the beginning of the spreading, the average contacts $D < 1+1/rd$.

\subsection*{The fuse model}
\label{sec:simple_D_c_fuse_model}
\begin{figure}[t]
	%scale = 0.27, trim = {10cm 0 1cm 0}
	\includegraphics[trim = {2cm 0 1cm 0}, width=.8\textwidth]{../images/Results/PSW/OPSW/OrdParam/p0.3/NNO_Conf_Model_addE_True_ordp_p0.3_beta0.015_mu0.07.png}
	\centering
	\caption{In the figure, it is reported the order parameter defined in \autoref{eq:def_OrdP}. More specifically, it is the average of the standard deviations of the daily new cases (Avg SD(Cases)) and show a typical transition from linear to exponential regimes of a Poissonian-SW Network. Using \autoref{eq:prelim_Dc_fusemodel}, $D_c \sim 8.2$ is a fair estimate of the average number of contacts for which a burdening outbreak, barely contaging half of the population.}
	\label{fig:SD_Threshold_Fuse_Model}
\end{figure}
A "fuse-model" is a one-dimensional chain of individuals with $D$ neighbors per node.
Therefore, similarly to the Erdös-Rényi case, 
\begin{equation}
	n(t) \sim 1+ (D-1)(1-\nu(t))(1-p)
	\label{eq:n(t)_fusemodel}
\end{equation}
where the fraction of long-range nodes $ p$ has been introduced since the fuse model accounts only for local interactions. 
Hence, inserting the derived $ n(t)$,
\begin{equation}
	D_c = 1 + \frac{2 \lambda^{-1}}{(1+p)}.
	\label{eq:simple_Dc_fusemodel}
\end{equation} 
where the fraction of susceptible $ \nu(t) \sim 1/2$ on average.  
Formally, averaging the initial and the final fraction of susceptible, 
\begin{equation}
	\nu(t_{max}) \sim 1-\frac{vt_{max}+0}{2} = 1/2
\end{equation}
where $1 = N$ is the (normalized) total population; $ t_{max}:= N/v = 1/v$ is the maximum time of the infection; $v$ the velocity of propagation of the epidemic front.  
Indeed, the infection roughly propagates as a wave at constant velocity $v$ . Thus, the "right-part" of the "fuse" is composed by susceptible nodes ($\nu(t) \sim 1/2$), while the "left-part" by the infected or recovered vertexes.

This equation provides the average number of contact below which the mean-field approximation fails, as a function of $p,\beta,\mu = 1/d$. On the other hand, a "fuse model" account for a spreading over a segment of $N$ nodes; while the considered network models are characterized by a circular structure. Hence, even if exploiting the local interactions, the "fuse-model" does provide a good estimate of $ D_c$ only for some networks, e.g. \autoref{fig:Ordp_OPSW_Dc8.3_p0.3}. In the other cases, it is expected to overestimate the critical degree since the epidemic is more constrained than in the studied network.

\subsection*{Mathematical Derivation of the Critical Degree for the \textit{Fuse Model} }

In this section, it is going to be obtained the critical degree $ D_c$  \cite{Thurner::NetBasedExpl} for a "fuse-model": a one-dimensional chain of individuals with $D$ neighbors per node.
\\In particular, 
\begin{equation}
	D_c = 1 + \frac{2 \lambda^{-1}}{1+p}.
	\label{eq:prelim_Dc_fusemodel}
\end{equation}
The same result may be used for the Poissonian small-world network.

The first step is to introduce an invariant probability function $\rho(x,t) = f(x-vt)$ that grasps the dynamics of the infection front: $\rho(x,t)$ is the probability, a node in the $x$ location is infected at time $t$.
In particular, $x$ is the network distance, as the number of in-between nodes from the initial infected node; $t$ is the time passed in days after disease started infecting and $v$ is the traveling velocity of the spreading along the $x$ axis.
A pedagogical representation of $\rho$ could be find in \cite{Thurner::Appendix_NetBasedExpl}: roughly speaking, it has the shape of a $\arctan(x-vt)$ where, on the $x$-axis, there is the 1d-chain on  nodes; while, on the ordinates, the probability $ \rho(x,t)\in [0,1]$ interval\footnote{The "past" nodes have higher $\rho$ while the future nodes have diminishing probability of being infected.}. Furthermore, the center of $ \rho$ conicides with an arbitrary node ($q$), which has $\rho(q) = 1/2$.

To estimate $v \text{ and } \rho(x,t)$, it is taken advantage on $\rho(x,t+1)$ assuming that $v$ is such that all the "non-susceptible nodes" are indeed infected, not recovered. Hence, the probability of being infected at a following time $t+1$ is
\begin{equation}
	\rho(x, t+1) = \rho(x,t)+(1-\nu(t))2D \beta \langle \rho \rangle(x,t) (1-\rho(x,t))
	\label{eq:fuse_model_rho(x,t+1)}
\end{equation}  
where $\langle \rho \rangle(x,t)$ is the (local) average probability of being infected at $(x,t)$ over the adjacent neighbors.
In other words, the \autoref{eq:fuse_model_rho(x,t+1)} considers the probability of already being infect; alongside with 2 terms:
\begin{itemize}
	\item $1-\nu(t)$ and $1-\rho$ which are the fraction of infected nodes and the probability of being susceptible;
	\item $\delta:= 2(1-\nu(t))D \beta$ is the total probability rate of having (at least) a contagion over the $2(1-\nu(t))D$ infected neighbors.
\end{itemize}
For a one-dimensional front, its radius proceed at a $x=vt$ pace and, defining $\tau$ as the next infection time, the a ratio of the non-susceptible/susceptible nodes may be approximated as 
\begin{equation*}
	\frac{1-\nu(t)}{\nu(t)} = \frac{t+\tau}{t} = 1+\frac{\tau}{t} = 1+v \tau \mathcal{K}.
\end{equation*}
Moreover, defining $\tau$ as the time one single node is infected $v \cdot \tau = 1$ implying that 
\[ \nu(t) = \frac{1}{2+\mathcal{K}} = \frac{1}{2} \]
since for a flat "fuse model" $\mathcal{K} = 0$. 
The naive expectation is recovered as $\nu(t) \sim 1/2$. 

Inserting the \autoref{eq:fuse_model_rho(x,t+1)} on the invariance condition 
\begin{equation}
	\frac{\partial \rho}{\partial t} = - \frac{\partial x}{\partial t} \frac{\partial \rho}{\partial x} = -v \frac{\partial \rho}{\partial x},
\end{equation}
with the further approximation that $\langle \rho \rangle(x,t) \sim \rho(x,t)$,
\begin{equation}
	\rho(x,t) = \frac{1}{1+e^{\delta(\tau x - t)}}
\end{equation}
with $\delta:= 2(1-\nu(t))D \beta$. 
For this solution, $\rho(vt,t) = \rho(0,0) = 1/2$ marks the infection front \cite{Thurner::Appendix_NetBasedExpl}. 

The average probability of the nodes on the left of the front being infected is
\begin{equation}
	\hat{\rho} \sim \frac{1}{\nu(t) D} \int_{-\nu(t) D}^{0} dx \rho(x,0) = 1+ \frac{1}{\delta'} \log( \frac{1+e^{-\delta'}}{2} )
	\sim \frac{1}{2} + \frac{1}{8} \delta' + O(\tau^3) 
	\label{eq:rho_hat_fuse_model}
\end{equation}
where it has been exploited that $\delta':=\tau \delta \nu(t) D$ and the last expansion as $\tau<<1$ \cite{Thurner::Appendix_NetBasedExpl}. Thus, $\hat{\rho}$ could also interpreted as the probability of the past infected nodes.

Moreover, $n$ could be obtained considering the situation where a $\nu(t)$ nodes are susceptible but the "past" nodes are not and viceversa: $\nu(t) \hat{\rho} \text{ or } (1-\nu(t))(1- \hat{\rho})$. 
\\Formally,
\begin{equation}
	n \sim 1+ (D-1)(\nu(t)\hat{\rho}+(1-\nu(t))(1-\hat{\rho}))
	\sim 1+ (D-1)(\frac{1}{2} - (1-2\nu(t)) \frac{1}{8} \delta')
\end{equation}
which for a flat infection, where $\nu(t)\sim 1/2$, reduces to
\begin{equation}
	n = 1 + \frac{1}{2}(D-1).
\end{equation} 

Ultimately, introducing the $pD$ long-range ("lr") neighbors; while keeping the infection low, $n_{lr} \sim 1$.
\\Since $n$ is a local estimate, removing the $n_{lr}$ contribution,
\begin{equation}
	n = 1 + \frac{1-p}{2}(D-1)
\end{equation}   
and, therefore,
\begin{equation}
	D_c = 1+ \frac{2 \lambda^{-1}}{1+p}.
	\label{eq:final_D_c_fuse_network}
\end{equation}

This estimate express the critical degree, i.e. the average number of contact under which the mean-field approximation fails, as a function of $p,\beta,\mu = 1/d$. As a second order approximation in $\tau$ as been exploited in \autoref{eq:rho_hat_fuse_model}, overestimates the number of infected which, in turn, drives to an overestimation of $D_c$. Other sources of divergence from the simulated critical degree may be the finite size effects or deviation from $\mathcal{k} = 0$.

\chapter{Methodology}
\label{ch:Methodology}
\begin{figure}[ht]
	\includegraphics[width = \linewidth]{Results/Caveman_Model/p0.0/Caveman_Model_SIR_R0_3_N994_D13.0_p0.0_beta0.015_d14.0.png}
	\caption{A pathogen spreading on a Caveman model with $D = 14$. The plot shows some curves for a network spreading: the total cases $\pi(t)$ (green), the daily new cases $ C(t)$ (blue) and the infected $ i(t)$ (azure dots). Following the same order, but for a Annealed-Mean-Field Network, $\pi(t)$ (orange) and  $ C(t)$ (violet). Moreover, $ \pi(t)$ are plotted on the left axis; while $ C(t) \textnormal{ and } i(t)$ on the right. The two dashed red lines are marking the number of starting infected at the beginning of infection. Every pale-green trajectory could be thought as a realization of the COVID-19 in different parts of the world, as if evolving with these parameters. The big stars mark the estimated maximum for the mean-field approximation as a yellow star (cf \autoref{eq:picrit_AMFN}) and the heterogeneous SIR in green (cf. \autoref{eq:picrit_network}). If the level of $ \pi(t_{critical})$ is not reached by the simulated total cases, the star is not shown, as in this case. Still, we reported the estimated $ \pi(t_{critical})$ in the legend.}
	\label{fig:Method_sir_CM_D13_ORL1}
\end{figure}
As reported in \autoref{sec:ATechIntro}, the goal of this thesis is to study of the "(quasi-)linear formation" \footnote{The "(pseudo)-linear" is recovered for an epidemic where $C(t) = \textnormal{ constant}$ for a reasonable amount of time, e.g. 20 time-steps. In turns, this implies a linear growth of the total cases.} of the total cases $\pi(t)$ for a SIR evolution on networks, e.g. \autoref{fig:Method_sir_CM_D13_ORL1}. Indeed, as NPIs measures prune the social contacts to avoid the presence of highly connected nodes (super-spreaders or hubs), the "well-mixed assumption" drives to diverging results from the real ones. To appreciate this difference, the evolution on a network and on a "Annealed Mean-Field Network" (see \autoref{sec:Annealed_MF_Network}) will reported in the same figure (cf. \autoref{ch:network-models}). Moreover, there will be reported the number of infected $ i(t)$ of the SIR ODEs (see \autoref{eqs:SIR_degree-based}) only for the network spreading, in order to validate whether the epidemic has started, namely $ di/dt > 0$.

\textbf{Infection Scheme}
As in \cite{Thurner::NetBasedExpl}, we initialized the $N = 1000$ total individuals as susceptible and we randomly chose $i(0) = 10$ vertexes as the starting infectors. Moreover, we select an "epidemic", i.e. by fixing the transimission rate $\beta, \textnormal{ and the recovery rate } \mu$, alongside with the average number of contacts $D:= \langle k \rangle$ and the fraction of long-range contacts $p$ in the underlying network.

The infection scheme, equal for both the mean-field, via Annealed-Mean-Field Network (AMFN), and the network models, is the following.
At every time-step $t$, we find all the infected nodes and we infect the susceptible neighbors with probability $\beta$ per unit time (transmissibility or microscopic spreading rate). After this "infectious" phase, at the same time-step $t$, we simulate their recovery with probability rate $\mu = 1/d$ (recovery rate), where $d$ are the average days, an individual stays infected.

\noindent\fbox{%
    \parbox{0.97\textwidth}{%
	\textit{To implement the stochasticity nature of an epidemic, generate a random number between $q \in [0,1]$ and infect the chose susceptible neighbors as $q\leq \beta$. Similarly, for the recovery transition with $\mu$.}
    }%
}

For every $t$, collect the infected $ i(t)$, the "new daily cases" $C(t)$\footnote{$C(t) = N(i(t) - i(t-1) + r(t) - r(t-1))$. A clear example is the following: \newline $(I(t-1),S(t-1)) \to (R(t),I(t))$, $C(t) = 1$ as $i(t)-i(t-1)=0$ but $r(t)-r(t-1) = 1/N$.} alongside with their (normalized) "cumulative sum" $\pi(t):=\sum_{\bar{t}\leq t} C(t)/N$, as shown in the panels in \autoref{sec:ATechIntro} reporting the real collected data. Proceed iterating the infection chain, until the dynamic comes to a halt, i.e. $i(\infty)=0$, while $s(\infty)\neq0, r(\infty) \neq0$.

After having collected the daily new cases $C(t) \textnormal{and the total cases } \pi(t)$ also for the AMFN (see \autoref{sec:Annealed_MF_Network}), we produced a plot with the joined $C(t) \textnormal{ and } \pi(t)$ from a specific network, e.g. Watts-Strogatz, and the AMFN. Moreover, there would be a series of plots for each model, since $ D, p, \beta,\mu$ are the free parameters to be chosen. Referring to \autoref{fig:Method_sir_CM_D13_ORL1}, one finds one scale for $ \pi(t)$ (left ordinate axis) and another on the right axis for $ C(t) \textnormal{ and } i(t)$. For the network evolution there are $ \pi(t)$ (solid green line), $ C(t)$ (solid blue line) and $ i(t)$ (azure dots); while, for the AMFN, $ \pi(t)$ (solid orange line) and $ C(t)$ (solid violet line). The starting infected seeds are reported as a straight red dashed horizontal line in the two different scales.
Thanks to this method, one gains more insight on the departure of the network spread from the mean-field SIR.

%In the simulated plots, there are a plethora of behaviors which could be compared with the real COVID-19 to gain some realistic insight. In \autoref{fig:USA-AUT-ITAtotalcasesOWID}, the linear part of the US suggests that the ratio $r$  among the total infected $ \pi(t)$ at the end (8/05/2020) over the start (25/03/2020) is
%\begin{equation}
%	f :=  \frac{\pi_{USA}(8/05/2020)}{\pi_{USA}(25/03/2020)} \sim 14.9
%\end{equation}  
%as reported in the legend of the inset figure on the lower right. Hence, over our population of ${N = 1000}$ individuals, $f_{N} = 1.49 \%$ of the total population- Indeed, $ =_{N}$ means that $ f$ has to be rescaled according to $ N = 1000$ nodes. This implies that, in order to capture the linearity the growth factor should be of order $1$. 

Finally, since \autoref{eqs:SIR_degree-based} are not linear, there is a strong dependence on the initial conditions: an epidemic reaching $ 150$ individuals starting with $ 10$ infected could have a different trend than the one that diffuses in $ 15$ nodes with $ 1$ initial contagion.

{\textbf{Relevant Quantities on Adjacency Matrix Plots}  }
%\label{sec:res_RegLat}
\begin{figure}[ht]
	\centering
	\includegraphics[width = .5\linewidth]{Results/WS_Pruned/AdjMat/WS_Pruned_AdjMat_1000_500.0_0.0.png}
	\caption{Lattice Graph panel for $D = 500$. On the upper left, there is the graphical realization of the network, characterized by a fan-shaped structure of connections for each node. On the upper right, the adjacency matrix; while, on the bottom, the probability distribution $ p_k$ .
	$N_{3-out} \textnormal{ and } SW_{C}$ are, respectively the number of nodes whose degree is $k>3D$ and the coefficient of small-worldliness $SW_{C} := \delta / \ln(N)$ where $ \delta$ is the average path length and $C$ display whether the network is connected. Instead, the size of the largest component is going to be returned.} 
	\label{fig:Method_RegLatAdjMatrix}
\end{figure}

\textbf{Relevant Quantities on SIR Plots.}
\begin{figure}[ht]
	\includegraphics[width = \linewidth]{Results/Caveman_Model/p0.0/Caveman_Model_SIR_R0_3_N994_D13.0_p0.0_beta0.015_d14.0.png}
	\caption{A pathogen spreading on a Caveman model with $D = 14$. The plot shows some curves for a network: total cases $\pi(t)$ (green), the daily new cases $ C(t)$ (blue) and the infected $ i(t)$ (azure dots). Following the same order, but for a Annealed-Mean-Field Network, $\pi(t)$ (orange) and  $ C(t)$ (violet). Moreover, $ \pi(t)$ are plotted on the left axis; while $ C(t) \textnormal{ and } i(t)$ on the right. The two dashed red lines are marking the number of starting infected at the beginning of infection. Every pale-green trajectory could be thought as a realization of the COVID-19 in different parts of the world, as if evolving with these parameters.}
	\label{fig:Method_sir_CM_D13_ORL1_2}
\end{figure}

In the SIR plots, e.g. \autoref{fig:Method_sir_CM_D13_ORL1_2}, there are reported different quantities which is better to highlight. Hence, from left to right: $R_0 \textnormal{ and } R_{c-net}$; the average degree $D$ with at the subscript the overall individuals $N = 1000$\footnote{ $ N$ would not be always fixed to $N = 1000$. In fact, for a Caveman Model of clique size equal to $ 33$, $ N = 999$.}; the "OnRingLinks"\footnote{We introduced a parameter which accounts for how many links departs from a clique to the next one on a circle, since the cliques are not connected locally in a Caveman Model. Thus, $OnRinLinks = 1$ means that one family is connected clockwise and anti-clockwise.} if a Caveman Model is considered; the rewiring probability $p$ and the epidemic parameters $\beta \textnormal{,} \mu$.
In the legend, there are present the fraction of total cases $P(t) \textnormal{ or }\pi(t)$ of the mean-field and the network evolutions; the daily new cases $ C(t)$ of both the AMFN and the studied network; the estimated maximum ($\bigstar$) for both of the mean-field and the network epidemics; the percentage of the starting infected nodes. 
Furthermore, the difference $ \Delta R_0 := R_0 - R_{c-net}$; the $ \langle k^2 \rangle$; the average path length $ \delta_C$; the division by the average path length of the previous quantities and the Order Parameter $ SD(C(t))$.
All the quantities in the rounded brackets are the errors obtained by using the propagation formula (see \autoref{App:error_propagation}).

Formally, we estimated the maximum of the cases $ C(t)$ ( $ \bigstar$ ) in two ways.
The first, according to \autoref{eqs:homo_SIR_MF}, yields 
\begin{equation}
	R_0 \cdot s(t) \stackrel{!}{=} 1 \implies \pi(t_{critical}) = 1 - \frac{1}{R_0}
	\label{eq:picrit_AMFN}
\end{equation}
where the fraction of susceptible $ s(t) = 1- \pi(t)$.  
Since $ \pi(t_{critical})$ is obtained using the mean-field equations, it is valid at every time and only for the AMFN (orange curve).
On the other hand, by substituting $ R_0$ with $ R(t)$ into the \autoref{eq:lambdac_Rc_netSIR},
\begin{equation}
	R(t) = (D-n(t))\lambda \stackrel{!}{=} R_{c-net}
	\label{eq:RcRnet_network}
\end{equation}
which yields
\begin{equation}
	\pi(t_{critical}) = \frac{1}{1-p} \left[1- \frac{R_{c-net} \lambda^{-1}}{D-1} \right]
	\label{eq:picrit_network}
\end{equation}
where the average number of infected $n(t) \sim 1+(D-1)\pi(t)(1- p)$ (cf. \autoref{eq:n(t)_fusemodel} ) with $p \neq 0$.
By contrast, this estimate is valid only at early times and, as it will be seen, produces a better estimate not in all the scenarios but whenever the diffusion is similar to a mean-field one.
Recovered $ \pi(t_{critical})$, by interpolation with the two nearest total cases $ \pi(t)$, it could be obtained the intermediate time $(t_{critical})$. Hence, the tuple $(t_{critical},p_{critical})$ is estimated.

The rationale behind is that after $ t_{critical}$, the number of cases are going to decrease since $R_0 \cdot s(t) < R_{c-net}$, as the susceptible are no more feeding the pathogen which is going to die out.

\textbf{Non trivial dependence of $ t_{max}$ and $ \sigma(t_{max})$.} \\
The duration of an average of different epidemics $t_{max}$ seems to increase as an interplay among the network and the pathogen strength. Indeed, $ t_{max}$ is higher as the pathogen posses a "balanced" diffusion for which a plethora of many trajectory could last more. By constrast, for a weak diffusion, many scenarios accounts for a fast decaying pathogen; while for a stronger one, the outbreak will reach all the population in a short time. See \autoref{sec:res_OPSW}. 

The variance $\sigma(t_{max})$ embodies the "degree of randomness" of the trajectories displayed in pale green (network-based) and brown (mean-field): we reported them after the $\pm$ sign in the legend. Its behavior is similar to the one of $t_{max}$. For a in-depth analysis, see \autoref{sec:res_OPSW} or \autoref{sec:res_RegLat}.

\textbf{Order Parameter at work}\\

The theoretically estimated average critical degree of contacts $D_c$ have been obtained by means of 3 models: homogeneous mean-field approximation, ER-model, fuse-model (cf. \autoref{eq:D_c_analytical_discussion}).
Note that $D_{c-homog model} < D_{c-ER model} < D_{c-fuse model}$, since it is easier for the epidemic to exponentially grow in a random network than following local paths (fuse model). In addition, the fuse model, in many cases, overestimates $D_c$, since it considers an epidemic which is strongly suppressed by moving in a fuse (see \autoref{sec:simple_D_c_fuse_model}). Other sources of divergence could be the average number of susceptible $ \nu \sim 1/2$ which it is not the case at early times. Thus, instead of an exact prediction, the estimated $ D_c$s allow to put an upper and a lower bound on the real $D_c$ of the studied networks. Indeed, the ER case provides a good comparison with an homogeneous approximation, as for networks with a large fraction $ p$ of distant nodes; while the "fuse model" is on the other extrema where the nodes strongly overlaps only locally, i.e. the regular lattice case reported in \autoref{sec:res_RegLat}.

Ultimately, the difference of the \autoref{fig:SD_Threshold_Fuse_Model} with \autoref{fig:ER_Epidem_Thr} is that, even if similar in shape, the former represents the evolution of the order parameter $SD(C(t))$ driven by the average number of contact $D$. Meanwhile, the second the final infected size $ i(t_{max})$ as guided by the transmissibility $ \beta$. A possible improvement should be to consider a plot $ i(t_{max})$ dependent by $D$, which is expected to behave as \autoref{fig:ER_Epidem_Thr}.

\textbf{Parameters Discussion} \\
According to \cite{Liu::2021_Review_SContactPattern} (2021), the most relevant studies \footnote{These works are extracted from PubMed, Medline, Embase and Google Scholar} on social contact patterns report $2-5$ average contacts per day during the lockdown, i.e. nearly the household size. This estimate is, roughly, lower than the pre-COVID-19 ones of $7-29$ average contacts per day. On the other hand, Mossong et Al. (\cite{Mossong:2008_preCOVID-europe_SCP}) (2008), based on $8$ European states, reported a pre-COVID-19 average of $13$ contacts per day, while Leung et Al. \cite{Leung:2017_HKSocialCP} (2017) find an average per day contacts of $8$ individuals for the habitants of Hong Kong.
The purpose of this thesis is to be grounded on real estimates. Thus, the main plots are going to be focused on the $D < 30$ regime, especially on $ D = 6,11,14,24$. Little room is going to be left for $D > 30$ as it can be the case for leisure activities, e.g. exhibitions or discotheques. Since COVID-19 spreads over face-to-face interactions, the latter case is crucial for the re-opening of the crowded activities.

For the "Caveman Model", we chose families of housesize $ 3$ according to \cite{Householdsize:2020} and the average number of contacts $ D = 5$ for the comparison with the minimum $D$ for all the reported networks. 

The epidemic parameters we choose as the transmissibility $ \beta = 0.015$ (\cite{Thurner::NetBasedExpl}) and the average days of recovery $ d = 14 \, days$ (\cite{LaurerSA:2020_IncPeriodCOVID-19}). Then, in order to capture different scenarios, $ \beta = 0.1$  or $ d = 4 \, days$ while preserving the other parameters, e.g. $ D,\cdots$ . In particular, $ \beta = 0.1$ embodies a stronger epidemic; while $ d =4\, days$ the introduction of Pharmaceutical Measures, e.g. vaccines. In particular, $d = 4 \, days$ days are comparable with the recovery time of a generic flu. Hopefully, this could be the case after a strong vaccination campaign. Since the SIR model does not distinguish among asymptomatic or symptomatic, $d = 4\, days$ would characterize both an asymptomatic and an hospitalized infected.

Lastly, $\beta$ and $\mu = d^{-1}$ (see \autoref{App:muD_table} for measure units) depends on many factor and especially on the studied population. Therefore, to have a broad inspection of the capabilities of a network topology it is worth considering different combinations of $\beta \textnormal{ and }\mu$. 

\chapter{Results}
\label{ch:Results}
In the following sections, after a discussion on the \textit{basic reproduction number} $R_0$, we introduced the \textit{epidemic severity} $ \Delta R_0 (\delta)$ to account for the burdening of a pathogen within a population.
Subsequently, we recovered the evolution of a disease (see \autoref{sec:degree-basedMF}) on different graphs (see \autoref{ch:network-models}). In particular, we generated one version of each network with local connections, namely with $ p = 0$, and a second one with long-range interactions, i.e. $ p = 0.3$. 
Thus, we simulated the COVID-19 spreading, by fixing $\beta = 0.015 \textnormal{ and } d = 14$ \cite{Thurner::NetBasedExpl}. In addition, we obtained two scenarios by chosing, one at a time, the transmissibility $\beta = 0.1$ and the recovery days $ d = 4$. The average contacts $D$ and the distant fraction of nodes $p$ to the COVID-19 curves. Ultimately, we compared the different evolutions of the pathogens, in order to understand the interplay among the disease and the underlying social network.

%This review provides some insights on which topology is better suited in constraining a pathogen among a Regular Graph, Overlapping-PSW, Sparse-PSW, connected Caveman model and a Scale-Free network.
The main result is that the Caveman model is the best suited topology in costraining the diffusion among the studied graphs. By constrast, for a pathogen with more transmissibility ($ \beta = 0.1$) a large fraction of the population is infected. Thus, only major restrictions are effective, e.g. forced quaratines.
The other networks have less control on the disease since they are not made of clusters. More precisely, we organized the nodes on a circle and we wire them with a defined scheme. In turn, the latter procedure generate a \textit{fan-shape} structure which strongly overlaps as $D$ increases. Therefore, we can order the networks based on the final outbreak size $ \pi_{max}$ at $ p = 0$: regular Watts-Strogatz (\autoref{sec:res_RegLat}), Overlapping Poissonian Small-World (O-PSW) model (\autoref{sec:res_OPSW}), sparse Poissonian Small-World (S-PSW) model (\autoref{sec:res_SPSW}) and a Barabási-Albert model (\autoref{sec:res_BA}).

For a practical implementation, we use networks with $N = 1000$ nodes and $10$ starting infected individuals. Then, we performed the simulation over the Google Colab CPUs of \cite{GoogleColab}.
Lastly, before facing the following technical part, we suggest to firstly dive into \autoref{ch:Methodology} for a more general discussion on the introduced quantities and behaviors.
%Moreover, since we are interested in the "sub-exponential" regime, we will report the last (quasi-)linear behavior but not the first exponential one as done in the second and third figures of \autoref{fig:sir_O-PSW_COVID}.

\section{Lattice Graph}
\label{sec:res_RegLat}
\begin{figure}[ht]
	\begin{subfigure}[t]{0.48\linewidth}
		\centering
		\includegraphics[width = 0.9\linewidth]{Results/WS_Pruned/AdjMat/WS_Pruned_AdjMat_1000_500.0_0.0.png}
		\caption{Lattice Graph panel for $D = 500$: a realization of the graph (upper left), adjacency matrix (upper right), degree distribution (lower band). The node (thin azure border) are connected among the neighbors via $ D = 500$ edges (black annulus). The white inner circle represent to missing of short-cut connections.} 
		\label{fig:net_RegLat_D500}
	\end{subfigure} 
	\hfill
	\begin{subfigure}[t]{0.48\linewidth}
		\centering
		\includegraphics[width = 0.9\linewidth]{Results/WS_Pruned/AdjMat/WS_Pruned_AdjMat_1000_500.0_0.3.png}
		\caption{Regular graph with an average number of contacts $D = 500$ and $p = 0.3$.
		The shadowed center of the graphical representation (upper left) signals the presence of shortcuts connecting distant nodes.}
		\label{fig:net_RegLat_D500_p0.3}
	\end{subfigure}
	\caption{Regular Lattice Network for average contacts $ D = 500$. We show on the upper left the graphical representation of the network; on the upper right its adjacency matrix and on the lower part the degree distribution (see \autoref{ch:Methodology})}
	\label{fig:net_RegLat}
\end{figure}
The \textit{basic reproduction number} $R_0$ is defined as the number of secondary cases at the beginning of the epidemic. Thus, the goal of this section is to test whether $R_0$ can account also for the "epidemic strength", i.e. the total cases $ \pi_{max}$, among different network models. We will recover that it is not suited for this scope, since different evolutions share the same $ R_0$. 
To prevent this collapse, we propose a new quantity called the \textit{epidemic severity}  $\Delta R_0(\delta):= \frac{R_0 - R_{c-net}}{\delta}$ where $1/\delta$ is a kind of "network efficiency": a low value of the average path length $ \delta$  drives to a higher spreading of a pathogen. 
\\Therefore, we will show that $\Delta R_0(\delta)$ seems to better describe how a pathogen seeps into a population.

The work-flow is the following. We generate a fully-connected graph using a "Watts-Strogatz" (WS) algorithm with $D = 999, p=0$. This model is, thus, called "Regular Lattice Graph". Then, the core idea is to fix $ R_0 $ and visualize how the epidemic curves change by varying the transmissibility $ \beta$ and $ D$. In particular, we fixed the recovery rate $ \mu = 1/d$ and, then, we divided the average number of contacts $ D$ while doubling $\beta$. 
Formally,
\begin{equation}
	R_0 = const = \frac{D}{q} \cdot \frac{\beta q}{ \mu}
\end{equation}
where $q$ goes from 1 to the maximum power of $2$ s.t. $D/q > 1$.
Hence, $\mu$ fixes the value of the \textit{basic reproduction number} $ R_0$  since $ R_0 = \, constant / \mu$. The resulting progression is $D \in [999,500,124,62,30,14,6,2]$ where, since the WS algorithm works only with even $D$, we, arbitrarily, rounded all the odd $D$ to the lower (even) integer. Furthermore, we also simulated the epidemics on a Watts-Strogatz graph with short-cut probability $p = 0.3$ (called "Long-Range WS") in \autoref{sec:res_RegLat_p0.3}. The network panel in \autoref{fig:net_RegLat} shows a WS network with $D = 500$ for both $ p=0 \textnormal{ and } p=0.3$.\\

For a rough representation, every node connects with its neighboring vertexes producing a $\vee$ structure of edges. The overlap among the $ \vee$'s increases as $D$ is enanched (see \autoref{fig:net_RegLat}). In this way, the pathogen is constrained to move locally, yielding a limited number of new daily cases $C(t)$ (blue curve) and, in turn, total cases $ \pi(t)$ (green one).\\
Finally, since the transmissibility $\beta \textnormal{ and the average number of contacts } D$ are arranged in a peculiar way, we do not report the Order Parameter $SD(C(t))$. 

\subsection*{SIR spreading over a Regular Lattice Graph}
\begin{figure}[ht]
	\includegraphics[width = \linewidth]{Results/WS_Pruned/p0.0/WS_Pruned_SIR_R0_3_N1000_D2.0_p0.0_beta0.105_d14.0.png} %../images/
	\centering
	\caption{Network SIR model (green) benchmarked with the Annealed-Mean-Field Network (orange). Since $R_0 > R_{c-net}$ (\autoref{eq:RcRnet_network}) the pathogen could increase the fraction of infected $ i(t)$ (azure dots). On the other hand, since the network is weakly connected, the total cases $ \pi(t)$ remains limited.}
	\label{fig:sir_RegLat_D2_p0}
\end{figure}
In this subsection, we display the SIR curves for a local ($p = 0$) lattice graph while we leave for the following section the comparison with the epidemics diffusing on a Long-Range WS (see \autoref{sec:res_RegLat_p0.3}).

As a starting point, the \autoref{fig:sir_RegLat_D2_p0} displays a scenario where the pathogen could spread on the network, namely the \textit{basic reproduction number} $R_0 > R_{c-net}$. Neverthless, its diffusion remains limited to a much smaller fraction of the population ($4.3 \%$ of the total population) than in the Annealed-Mean-Field Network (AMFN) case. In fact, the epidemic is just spreading on a 1D lattice, since $ D = 2$, where only nearest neighbors are connected as in a fuse with the identified extrema. On the other hand, the mean-field SIR infects random nodes on the fuse. Thus, the stochasticity of an epidemic of an AMFN is slightly larger than the network one, since $ D$ is low. Thus, the increasing value of the infected $i(t)$ (azure dots) implies that the epidemic has started but the fuse model is strongly containing the pathogen. 

Secondly, it is worths defining the final fraction of total cases as
\begin{equation}
	\pi_{max} := \pi(t_{max})
	\label{eq:def_pmax}
\end{equation}
where $ t_{max}$ is time at the end of the infection, i.e. when the fraction of infected individuals vanishes ($i(t) = 0$).
Therefore, by fixing $R_0 \sim 2.94$ as in \autoref{fig:sir_RegLat_D61430}, the $ \pi_{max}$ grows as $D$ increases. In addition, \autoref{eq:lambdac_Rc_netSIR} implies that the
\textit{critical reproduction number} $R_{c-net} = (1-D^{-1})^{-1}$ decreases when $D$ increases. As expected, $R_{c-net}$ is more likely to be overtaken when a regular lattice has more neighbors.

Moreover, \autoref{sub@fig:sir_RegLat_D6} displays a the (pseudo-)linearity regime for $ D = 6$. As expected, the final outbreak size is increased: $ \pi_{max}$ is around $ 3$ times higher than the $ D=2$ case. In addition $D = 6$, is slightly above the upper bound of $2-5$ lockdown contacts per person \cite{Liu::2021_Review_SContactPattern}. Hence, this could be the evolution of a small village with light stay-at-home orders, as the network is not restricted into families.

%The total cases $ \pi_{max} \sim 4.3$ is apprimatevely $3$ times higher than compared to COVID-19 the USA growth factor $f \sim 1.5\%$ (see \autoref{ch:Methodology} and \autoref{fig:USA-AUT-ITAtotalcasesOWID}). Hence, even it seems suppressed, it is still relevant.

By continuing enanching $ D$, the network becomes more tangled, due to the increasing overlapping among  the neighboorhoods. Thus, the epidemic diffuses more rapidly showing that the $ R_0$ is informative only to early times. Rather, $\Delta R_0(\delta)$ seems a more precise quantity to account for the epidemic severity, since it augments as $D$ increases (cf. \autoref{fig:sir_RegLat_D14}).

Finally, using \autoref{eq:picrit_network}, the estimated maximum of the infected nodes $ i(t)$ (green star) overestimates the real maximum of the heterogeneous SIR evolution (cf. \autoref{fig:sir_RegLat_D30}). To obtain the \autoref{eq:picrit_network}, we made the following assumptions: \autoref{eq:RcRnet_network}, \autoref{eq:n(t)_fusemodel} to hold for every time. The former takes into consideration only quantities at early times. Thus, this divergence is somehow to be expected. The latter seems a fair approximation at every time.
A possible solution could be to refine the \textit{critical reproduction number} $ R_{c-net}$. In fact, if $ R_{c-net}$ increases, then, the $ \pi(t_{critical})$ diminishes.   
The prediction worsens even more when the long-range wiring probability $ p$ is diffrent from zero (see \autoref{sec:res_RegLat_p0.3}). 
Instead, the maximum value predicted by the \autoref{eq:picrit_AMFN} is correct as it is obtained directly from from the ODEs \autoref{eqs:homo_SIR_MF} (see \autoref{ch:Methodology}).

\clearpage
\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.9\linewidth}
        \centering
        \includegraphics[width=0.97\linewidth]{Results/WS_Pruned/p0.0/WS_Pruned_SIR_R0_3_N1000_D6.0_p0.0_beta0.035_d14.0.png} 
        \caption{Regular Lattice with $D = 6 \textnormal{ and } \beta = 0.036$. This evolution displays a remarkable (pseudo-)linearity in the total cases $ \pi(t)$ (green curve) and a total outbreak size nearly $3$ times higher that the one reported in \autoref{fig:sir_RegLat_D2_p0}. Ultimately, $ D = 6$, \cite{Householdsize:2020}, could represent the evolution of a small village with light stay-at-home orders.} 
		\label{fig:sir_RegLat_D6}
    \end{subfigure}
	\vfill
    \begin{subfigure}[t]{0.9\linewidth}
        \centering
        \includegraphics[width=.97\linewidth]{Results/WS_Pruned/p0.0/WS_Pruned_SIR_R0_3_N1000_D14.0_p0.0_beta0.015_d14.0.png} 
        \caption{Regular Lattice with $D = 14$. Linearity is lost.} 
		\label{fig:sir_RegLat_D14}
    \end{subfigure}
    \vfill
    \begin{subfigure}[t]{0.9\linewidth}
        \centering
        \includegraphics[width=.97\linewidth]{Results/WS_Pruned/p0.0/WS_Pruned_SIR_R0_3_N1000_D30.0_p0.0_beta0.007_d14.0.png} 
        \caption{Regular Lattice with $D = 30$. The estimated maximum of $ i(t)$ (green star) is overestimated; while the maximum for a mean-field is correct (yellow star).} 
		\label{fig:sir_RegLat_D30}
    \end{subfigure}
    \caption{The spreading curves over a regular lattice as $D$ increases. The classical $R_0$ remains constant, while the \textit{epidemic severity} $\Delta R_0(\delta)$ (cf. \autoref{sec:def_epidemic_severity}) varies.}
	\label{fig:sir_RegLat_D61430}
\end{figure}

\clearpage
\subsection{Long-Range Watts-Strogatz model}
\label{sec:res_RegLat_p0.3}
As the probability of connecting to distant nodes is switched on, i.e. $p = 0.3$, the "Long-Range" Watts-Strogatz model starts to resemble a mean-field network where all the nodes are connected at random (see \autoref{fig:net_RegLat_D500_p0.3}). Therefore, the total case at the end of the epidemic will grow.The SIR spreading for $ D = 6$ (\autoref{fig:sir_RegLat_D6_p0.3}) shows an increasing final fraction of total cases $\pi_{max}|_{p=0.3} \sim 72\%$ against the $\pi_{max}|_{p=0} \sim 12\%$ of the regular case in \autoref{fig:sir_RegLat_D6}. This is, somehow, the aim from the \autoref{sec:ATechIntro}: the network really plays a role in constraining the disease, yielding a linear growth of the total infected even for big $R_0$ ($R_0 = 2.94$) but a small $ D=6$ comparable with the number of contacts in a light lockdown \cite{Liu::2021_Review_SContactPattern}.

In \autoref{ch:Methodology}, we briefly indicated that $t_{max}$ and the variance $ \sigma(t_{max})$ increase as the pathogen has a "balanced diffusion". In particular, in the following panel (\autoref{fig:sir_RegLat_D2614_p0.3}), the $ \pi_{max}$ of the $ D = 6$ evolution displays an intermediate value between the $ D = 14$ (\autoref{fig:RegLat_D14_p0.3}) and $ D = 2$ (\autoref{fig:sir_RegLat_D2_p0.3}) cases. Furthermore, the fluctiations are higher for the $ D =6$ than in the other evolutions. A rough explanation comes from the upper bound of population size $N$ and the lower one as an epidemic ends whenever $ i(t) = 0$. In fact, those constraints seems to even out the trajectories, producting a lower $t_{max}$ and $ \sigma(t_{max})$.

Since for Long-Range WS the spreading is enanched, the take home message is that local wiring, and eventually social distancing, is effective. In turn, this could drive to a remarkable suppression of fraction of total cases $ \pi(t)$ if $ D$ is small enough as seen in \autoref{fig:sir_RegLat_D2_p0} or \autoref{fig:sir_RegLat_D6}.

\clearpage
\begin{figure}[H]
    \centering
	\begin{subfigure}[t]{\textwidth}
        \centering
        \includegraphics[width=.97\textwidth]{Results/WS_Pruned/p0.3/WS_Pruned_SIR_R0_3_N1000_D2.0_p0.3_beta0.105_d14.0.png} 
        \caption{Remarkably linear regime over barely the entire evolution. As the network accounts for small $ D$ and low rewiring $ p$, the epidemic is flatten similarly to the $ p=0$ case: \autoref{fig:sir_RegLat_D2_p0}} 
		\label{fig:sir_RegLat_D2_p0.3}
    \end{subfigure}
	\vfill
    \begin{subfigure}[t]{\textwidth}
        \centering
        \includegraphics[width=.97\textwidth]{Results/WS_Pruned/p0.3/WS_Pruned_SIR_R0_3_N1000_D6.0_p0.3_beta0.035_d14.0.png} 
        \caption{The (quasi-)linearity is lost and the exponential growth is recovered. By contrast to the $ D=2$ case, here the enanchement with respect to \autoref{fig:sir_RegLat_D6} is more pronunced: the total cases are barely $ 6$ times the "regular" ones. As quoted before, the estimated maximum (green star) worsens as $ p \neq 0$. Moreover, only $\Delta R_0(\delta)$ grasps the epidemic severity with respect \autoref{fig:sir_RegLat_D6}. Indeed, the two $R_0$'s are equals; while the differences $ R_0 - R_{c-net} $ could suggest that the $ p = 0$ case would be stronger that the current case. Neverthless, it is the opposite as captured by $\Delta R_0(\delta)$. Finally, $t_{max}$ and $ \sigma(t_{max})$ are higher than the $ D = 2$ and $ D = 14$ scenarios.} 
		\label{fig:sir_RegLat_D6_p0.3}
    \end{subfigure}
	\vfill
    \begin{subfigure}[t]{\textwidth}
        \centering
        \includegraphics[width=.97\textwidth]{Results/WS_Pruned/p0.3/WS_Pruned_SIR_R0_3_N1000_D14.0_p0.3_beta0.015_d14.0.png} 
        \caption{Watts-Strogatz model for $D = 14 \textnormal{ and } p = 0.3$. As quoted before, the estimated maximum (green star) from \autoref{eq:picrit_network} worsens as $ p = 0.3$.} 
		\label{fig:RegLat_D14_p0.3}
    \end{subfigure}
    \caption{Watts-Strogatz model spreading curves for $D = 6$ and $D = 14$ and $p = 0.3$ .}
	\label{fig:sir_RegLat_D2614_p0.3}
\end{figure}

\clearpage
\section{Poissonian Small-World Network}
\thispagestyle{empty}
\label{sec:res_PSW}
\begin{figure}[ht]
    \begin{subfigure}{.45\linewidth}
        \includegraphics[width = \linewidth]{Results/PSW/AdjMat/NNO_Conf_Model_addE_True_AdjMat_1000_14.0_0.0.png}
        \centering
        \caption{Overlapping PSW degree distribution. }
        \label{fig:net_O-PSW}
    \end{subfigure}
	\hfill
	\begin{subfigure}{.45\linewidth}
        \includegraphics[width = \linewidth]{Results/PSW/AdjMat/NN_Conf_Model_AdjMat_1000_13.0_0.0.png}
        \centering
        \caption{Sparse PSW degree distribution}
        \label{fig:net_S-PSW}
    \end{subfigure}
	\caption{Two kind of PSW network for a "Overlapping" and "Sparse" scheme. The case of $p = 0.3$ is not shown for conciseness, but could be straightforwardly obtained by overimposing some long-range links to the current cases as in \autoref{fig:net_RegLat_D500_p0.3}}
\end{figure}
The NPIs measures have forced the individuals to lower their number of contacts, i.e. $2-5$ contacts \cite{Liu::2021_Review_SContactPattern}, in order to avoid the hubs formation, whose role is to produce a vanishing epidemic threshold (see \autoref{ch:sir-models}).
Therefore, to capture the absence of hubs while retaining the heterogeneity on the number of contacts, we introduced a Poissonian small-world (PSW) network.
%: we drew the degree of each vertex from a Poissonian distribution $ p_k$ with mean equals to $ D$ and we "properly" rewired the nodes to the nearest ones, trying to mimic the lockdown scenario \cite{Thurner::Appendix_NetBasedExpl}. 
As introduced in \autoref{ch:network-models}, we will use the Overlapping Poissonian Small-World (O-PSW) and the Sparse Poissonian Small-World (S-PSW) model. The former is a "local" PSW since we connected the neighboring nodes according to its degree, drawn from a poissonian distribution of average $ D$. The latter does preserve the underlying Poissonian distribution but enables some long-range nodes even at $ p = 0$. 

Our goal would be to test if this configurations enanch or diminish the total cases $ \pi(t)$ with respect the Watts-Strogatz model (see \autoref{sec:res_RegLat}). In particular, we simulated the COVID-19 pandemic, by fixing the transmissibility $\beta = 0.015$ (\cite{Thurner::NetBasedExpl}) and the incubation period $d = 14 \, ( \mu \sim 0.07)$ (see \autoref{App:muD_table}) from \cite{LaurerSA:2020_IncPeriodCOVID-19}. As before, we analyze also the $d = 4$ case, choosing $\beta = 0.015$ and enanching $ D = 24$. In addition, we report the scenario where $ \beta = 0.1$ (a stronger epidemic) (see \autoref{fig:sir_O-PSW_D5_d14_b0.1}).
The final result will be that the SPSW produces a higher fraction of total cases $\pi(t)$ than the OPSW, which, in turn, displays a bigger $\pi(t)$ than the Watts-Strogatz model. 

\subsection{Overlapping PSW}
\label{sec:res_OPSW}
In this section, we will display the typical behaviors of a SIR model on a Overlapping Poissonian Small-World (O-PSW) network for both $p = 0.0 \textnormal{ and } p=0.3$. For brevity, we will refer to the one with $ p = 0$ as the "regular" OPSW (R-OPSW), while the latter as the "long range" OPSW (LR-OPSW).
%We will focus on the (pseudo-)linear evolution of the fraction of total cases as we change the epidemic parameters $ \beta \textnormal{ and } d$, the average number of contacts $D$ and the fraction of long-range connections $ p$.
As said, we will recover that the OPSW model provides less control on the pathogen spreading with respect to the Watts-Strogatz model. 
%The comparisons will be among the figures (\autoref{fig:sir_O-PSW_D5_p0},\autoref{fig:sir_RegLat_D6}) and (\autoref{fig:RegLat_D14_p0.3},\autoref{fig:sir_O-PSW_D14_p0.3}).

Finally, we will show the change of the order parameter, namely the standard deviation of the daily cases $SD(C(t))$, as a function of $ D$. This will highlight the separation among a sub-exponential regime and an exponential growth of the fraction of total cases $ \pi(t)$. The total cases will grow exponentially for $ D = 14$.  

\subsubsection*{SIR on Regular O-PSW}
The \autoref{fig:sir_O-PSW_COVID} displays the appearance of the exponential growth of the final fraction of total cases $ \pi_{max}$ (cf. \autoref{sec:res_RegLat}) as $D$ increases. For $ D = 5, 11$ there is not an exponential growth, even at early times where there is a big pool of susceptible. Rather, this is the case for the Annealed-Mean-Field Network (orange curve) representing a mean-field approximation.

In \autoref{sec:res_SPSW} (cf. \autoref{sec:res_RegLat}), by varying $D$ while fixing the \textit{biological factor}  $\lambda:=\frac{\beta}{ \mu}$ , we will use the \textit{epidemic severity}  $\Delta R_0 (\delta)$ better described the diffusion of a pathogen in a network.\\
In \autoref{fig:sir_O-PSW_D5_d14_b0.1}, we will underline how by increasing the transmissibility $ \beta$  also the $ \pi_{max}$ rises nearly to $ 14$ times than the homologous plot for $ \beta = 0.015$ (\autoref{fig:sir_O-PSW_D5_p0}).\\
In \autoref{fig:sir_O-PSW_D24_d4}, we will display the evolution of a pathogen faced with medical interventions (higher $ \mu$) than the COVID-19 one.

Lastly, as introduced in \autoref{ch:Methodology}, the maximum duration $t_{max}$ of an epidemic and its variance over the mean $\sigma_{max}$ are higher as the pathogen diffuses niether too weak nor too strong (see \autoref{fig:sir_O-PSW_COVID}). Moreover, fixing $D$ while increasing $ \beta$, the outbreak time increases (cf. \autoref{fig:sir_O-PSW_D5_d14_b0.1}). The same phenomenon is recovered by changing $ p$ or $ \mu$  (cf. \autoref{fig:sir_O-PSW_D24_d4_p0.3}, \autoref{fig:sir_O-PSW_D24_d4}). 
On the other hand, the epidemic lasts less if the pathogen is too strong since it reaches the population in a smaller time (see \autoref{sec:res_SPSW}).

\begin{figure}[p]
	\centering
    \begin{subfigure}[t]{\linewidth}
        \includegraphics[width = .90\linewidth]{Results/PSW/OPSW/p0.0/NNO_Conf_Model_addE_True_SIR_R0_1_N1000_D5.0_p0.0_beta0.015_mu0.07.png}
		\centering
        \caption{SIR spreading for $D = 5$ with COVID-19 parameters. Note that $R_0 < R_{c-net}$ showing that the pathogen is naturally extinguishing. Moreover, there is no exponential growth, even at early times, where there is a big pool of susceptible.}
        \label{fig:sir_O-PSW_D5_p0}
    \end{subfigure}
	\vfill
	\begin{subfigure}[b]{\linewidth}
		\centering
        \includegraphics[width = .90\linewidth]{Results/PSW/OPSW/p0.0/NNO_Conf_Model_addE_True_SIR_R0_2_N1000_D11.0_p0.0_beta0.015_mu0.07.png}
        \caption{SIR (pseudo-)lineraity for $D = 11$: no exponential growth occurs. Rather, the fraction of total cases $\pi(t)$ grows exponentially for the Annealed-Mean-Field Network (orange curve).
		The figure shows a higher maximum $ t_{max}$ and $ \sigma(t_{max})$ than the other cases, since the pathogen diffuses with a "balanced strength" (see \autoref{ch:Methodology}).}
        \label{fig:sir_O-PSW_D11_p0}
    \end{subfigure}
	\vfill
	\begin{subfigure}[b]{\linewidth}
		\centering
        \includegraphics[width = .90\linewidth]{Results/PSW/OPSW/p0.0/NNO_Conf_Model_addE_True_SIR_R0_3_N1000_D14.0_p0.0_beta0.015_mu0.07.png}
        \caption{SIR spreading for $D = 14$. The current topology ease the diffusion of the pathogen than the regular Watts-Strogatz graph (cf. \autoref{sub@fig:sir_RegLat_D14}). By zooming into the onset of the outbreak, it could be seen an exponential increase of the total cases of the network curve (green curve). For $D > 14$, the epidemic curves on network develop a more definited exponential growth and start to resemble the mean-field ones.}
        \label{fig:sir_O-PSW_D14_p0}
    \end{subfigure}
	\caption{SIR spreading with COVID-19 parameters and a maximum $D = 14$.}
	\label{fig:sir_O-PSW_COVID}
\end{figure}

\clearpage
\begin{figure}[H]
	\centering
	\begin{subfigure}{\linewidth}
		\centering
		\includegraphics[width = .90\linewidth]{Results/PSW/OPSW/p0.0/Pec_Beh/NNO_Conf_Model_addE_True_SIR_R0_7_N1000_D5.0_p0.0_beta0.1_mu0.07.png}
		\caption{A pathogen with more transmissibility than COVID-19 and the other parameters drawn from \autoref{fig:sir_O-PSW_D5_p0}. $\pi_{max}$ rises nearly to $ 14$ times than the $ \beta = 0.1$ case (cf. \autoref{fig:sir_O-PSW_D5_p0}). As said in \autoref{ch:Methodology}, the maximum time of the epidemic, namely $t_{max} $, and the variance of the mean $\sigma(t_{max})$ are higher than \autoref{fig:sir_O-PSW_D5_p0}.}
		\label{fig:sir_O-PSW_D5_d14_b0.1}
	\end{subfigure}
	\vfill
	\begin{subfigure}[t]{\linewidth}
		\centering
		\includegraphics[width = .90\linewidth]{Results/PSW/OPSW/p0.0/Pec_Beh/NNO_Conf_Model_addE_True_SIR_R0_1_N1000_D24.0_p0.0_beta0.015_mu0.25_SEASINFLUENZA.png}
		\caption{The evolution for COVID-19 faced with pharmaceutical interventions (PIs). They plays a relevant role since for $ D = 11, d = 14$ the final outbreak size overtakes the $40 \% $ of the population while, here, the final fraction of total cases $\pi(t_{max})\sim 13\%$ as $D \sim 23, d = 4$. The maximum time of the epidemic, namely $t_{max} $, and the variance of the mean $\sigma(t_{max})$ are higher than \autoref{fig:sir_O-PSW_D14_p0}.}
		\label{fig:sir_O-PSW_D24_d4}
	\end{subfigure}
	\vfill
	\begin{subfigure}{\linewidth}
		\centering
		\includegraphics[width = .90\linewidth]{Results/PSW/OPSW/p0.3/Pec_Beh/NN_Conf_Model_SIR_R0_1_N1000_D24.0_p0.3_beta0.015_d4.0.png}
		\caption{The sub-exponential growth for a $D$ slightly above $D_c$ of \autoref{fig:Ordp_OPSW_highmu_p0.3} and $p = 0.3.$ It has been reported here for a direct comparison with the $p = 0$ case. Indeed, the $ \pi_{max} $ is greater than the one reported for $ p= 0$ as the long-range nodes are present. For $ D < 24$, the curves show trajectories which decay fast and are not smooth. \autoref{fig:sir_O-PSW_D5_p0} shows how a pathogen could behave on the same network without Pharmaceutical Interventions.}
		\label{fig:sir_O-PSW_D24_d4_p0.3}
	\end{subfigure}
	\caption{Spread for different epidemic parameters}
	\label{fig:OPSW_COVID_p0.3}
\end{figure}

\clearpage
\subsubsection*{SIR on Long-Range O-PSW}
The diffusion of the pathogen for $p = 0.3$ shares the overall shape with the $p = 0$ case, but with an enhancement due to the possibility to jump into new pools of susceptible. In this way, an infected node may have more susceptible around and could spread easily.

\begin{figure}[htbp]
	\centering
	\begin{subfigure}[t]{\linewidth}
		\centering
		\includegraphics[width = .90\linewidth]{Results/PSW/OPSW/p0.3/NNO_Conf_Model_addE_True_SIR_R0_1_N1000_D5.0_p0.3_beta0.015_mu0.07.png}
		\caption{Diffusion in a network with $p = 0.3$ fraction of long-range nodes. As $R_0 < R_{c-net}$, the pathogen naturally dies out. Therefore, the long-range connections does not sustain the spreading since the individuals are recoverying rapidly.}
		\label{fig:sir_O-PSW_D5_p0.3}
	\end{subfigure}
	\begin{subfigure}[t]{\linewidth}
		\centering
		\includegraphics[width = .85\linewidth]{Results/PSW/OPSW/p0.3/NNO_Conf_Model_addE_True_SIR_R0_2_N1000_D11.0_p0.3_beta0.015_mu0.07.png}
		\caption{SIR spreading on OPSW with $ p = 0.3$.The total cases $ \pi(t)$ are, roughly, linear in the first hundred days. Moreover, the \textit{epidemic severity} $ \Delta R_0(\delta)$  accounts for the outbreak size $ \pi_{max}$: the current evolution has $\Delta R_0(\delta) \sim 0.272$ while the one in \autoref{fig:sir_O-PSW_D11_p0} as $ \Delta R_0(\delta) \sim 0.037$. On the other hand, the $R_0 \sim 2.35$ and the differences  $R_0 - R_{c-net} \sim 1.3$ are similar to the these ones. Yet, the $\pi_{max} \sim 48\%$ roughly twice as the $\pi_{max} \sim 20\%$ obtained for $ p = 0$.
		Finally, as $ d = 4$ the total cases goes from $\pi(t)|_{d = 14, D = 11} \sim 48\% \textnormal{ to } \pi(t)|_{d = 4, D =24} \sim 23\%$ \autoref{fig:sir_O-PSW_D24_d4_p0.3}. On the other hand, for a regular OPSW the transition is lighter, namely $ 20\% \to 13\%$ as we reported in \autoref{fig:sir_O-PSW_D14_p0} and \autoref{fig:sir_O-PSW_D24_d4}.}
		\label{fig:sir_O-PSW_D11_p0.3}
	\end{subfigure}
	\begin{subfigure}[t]{\linewidth}
		\centering
		\includegraphics[width = .85\linewidth]{Results/PSW/OPSW/p0.3/NNO_Conf_Model_addE_True_SIR_R0_3_N1000_D14.0_p0.3_beta0.015_mu0.07.png}
		\caption{SIR spreading for $ D = 14$ showing an enanchement in $ \pi_{max} $ with respect the Watts-Strogatz one in \autoref{sub@fig:RegLat_D14_p0.3} }
		\label{fig:sir_O-PSW_D14_p0.3}
	\end{subfigure}
	\caption{Overlapping PSW spread for COVID-19 parameters with $p = 0.3$ }
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width = .90\linewidth]{Results/PSW/OPSW/p0.3/Pec_Beh/NNO_Conf_Model_addE_True_SIR_R0_7_N1000_D5.0_p0.3_beta0.1_mu0.07.png}
	\caption{SIR diffusion for $ D = 5$ but with higher $\beta$. As expected from the presence of long-range connections, $\pi(t_{max})$ reach $\sim 2.3$ times the total infected of the $ p=0$  case.}
	\label{fig:sir_O-PSW_D5_p0.3_b0.1}
\end{figure}

\clearpage
\subsubsection*{Order Parameters}
\begin{figure}[t]
	\begin{subfigure}[t]{0.48\linewidth}
		\centering
		\includegraphics[width=\linewidth, keepaspectratio]{Results/PSW/OPSW/OrdParam/p0.0/NNO_Conf_Model_addE_True_ordp_p0.0_beta0.015_mu0.07.png} 
		\caption{Order Parameter with $D_c \sim 10$ as shown by the small exponential phase at the early times of \autoref{fig:sir_O-PSW_COVID}. The $ D_{c-fuse\, model}$ properly estimates the real degree threshold.}
		\label{fig:Ordp_OPSW_COVID19_D14}
	\end{subfigure}
	\begin{subfigure}[t]{0.48\linewidth}
		\centering
		\includegraphics[width=\linewidth, keepaspectratio]{Results/PSW/OPSW/OrdParam/p0.0/NNO_Conf_Model_addE_True_ordp_p0.0_beta0.015_mu0.25.png}
		\caption{Order Parameter with higher $D_c$ since recovery rate is enhanced. $D_c \sim 20$.
		The fuse model deeply overestimates $ D_c$ as the Poissonian structure facilitates a faster growth of the standard deviation, i.e. the daily new cases, more than a fuse one. The transition is better described by the Erdös-Rényi $ D_c$ .}
		\label{fig:Ordp_OPSW_highmu_COVID19}
	\end{subfigure}
	\caption{Order Parameter for Regular OPSW with different recovery rates at $p = 0$. }
	\label{fig:Ordp_OPSW_COVID19_panel}
\end{figure}

\begin{figure}[t]
	\begin{subfigure}[t]{0.48\linewidth}
		\includegraphics[width=\linewidth, keepaspectratio]{Results/PSW/OPSW/OrdParam/p0.3/NNO_Conf_Model_addE_True_ordp_p0.3_beta0.015_mu0.07.png}
		\caption{Order Parameter dependence as in the upper plot, but $ p = 0.3$. The fuse model approximation yields a proper estimate of $ D_c \sim 8.3$}
		\label{fig:Ordp_OPSW_Dc8.3_p0.3}
	\end{subfigure}
	\begin{subfigure}[t]{0.48\linewidth}
		\includegraphics[width=\linewidth, keepaspectratio]{Results/PSW/OPSW/OrdParam/p0.3/NNO_Conf_Model_addE_True_ordp_p0.3_beta0.015_mu0.25.png}
		\caption{Order Parameter for Regular OPSW with different recovery rates at $p = 0.3$.
		The critical degree of a fuse-model is corrected with the rewiring probability $ p$. Thus, the estimates is more similar to the real change of regime.}
		\label{fig:Ordp_OPSW_highmu_p0.3}
	\end{subfigure}
	\caption{Order Parameter for Long-Range OPSW of different pathogens and recovery rates.}
	\label{fig:Ordp_OPSW_COVID19_p0.3_panel}
\end{figure}

\textbf{Regular O-PSW and Long-Range O-PSW Order Parameter}
In this section, we will display how the order parameter (see \autoref{sec:OrderParam4LinContagion}) changes as we vary the $ \mu \textnormal{ and } p$ parameters.
Formally, the order parameter is the standard deviation of the daily cases $SD(C(t))$ and we will consider it as a function of the average number of contacts $D$. Moreover, as $ D$ increases, it develops a kind of phase transition characterized by the critical degree $ D_c$: as $ D < D_c$, $ SD(C(t)) \sim 0$; while for $ D > D_c$, $ SD(C(t)) \neq 0$. In turn, the epidemics for $ D>D_c$ show an exponential grow at early times similar to the mean-field one.
As a final result, we will obtained that in some cases the $ D_c$ is correctly estimated by a fuse-model (cf. \autoref{eq:D_c_analytical_discussion}), while on the other the fuse overestimates it.

In \autoref{sub@fig:Ordp_OPSW_COVID19_D14}, we exhibit the $ SD$ evolution for the COVID-19 epidemic parameters. The transition occurs for $ D_c \sim 10$ and it is well estimated by a fuse model. The second \autoref{sub@fig:Ordp_OPSW_highmu_COVID19} has a higher value of $ \mu$ as a result of the insertion of pharmaceutical intervetions, e.g. vaccines. Indeed, this provides a higher $ D_c$, since exponential growth of the total cases is more difficult. On the other hand, $ D_c$ of a fuse-model overestimates the simulated one, since a OPSW graph eases the spreading more than a fuse one. The Erdös-Rényi model provides a better measure of $D_c$.  

Switching on the long-range interactions ( $ p = 0.3$ ), the shape of $ SD(C(t))$ are similar to the previous ones. In \autoref{fig:Ordp_OPSW_COVID19_p0.3_panel}, the most reliable prediction of $ D_c \sim 8.3$ comes from the \textit{fuse model}, since the OPSW resembles a \textit{fuse model}.
In the \autoref{fig:Ordp_OPSW_highmu_p0.3}, we displayed the same scenarios of \autoref{sub@fig:Ordp_OPSW_highmu_p0.3} but also the long-range interactions. The best estimate of $ D_c$ is provided by the Erdös-Rényi approximation. Nevertheless, as one finds in the legend, the fuse estimation is diminished since we actively considered the distant node $ D_{c-fuse \, model}$ as susceptible individuals in the analytical derivation (see \autoref{ch:Methodology}).

As seen before, the epidemic curves are enanched as we introduced the long-range interactions. By contrast, the evolution of the order paramter is similar to the one for $ p=0$ and still depends from the epidemic parameters similarly as before: for $d = 4$, the $ D_c$ rises. Hence, the order parameter seems slightly modified by the presence of $pN = 300$ long-range interactions.

\clearpage
\subsection{Sparse PSW}
\label{sec:res_SPSW}
This section aims at describing the diffusion of a pathogen on a "S-PSW" network for both $p = 0.0 \textnormal{ and } p=0.3$. Inheriting the previous notation, the former would be called the "regular" S-PSW (R-SPSW) while the latter "long range" S-PSW (LR-SPSW).
This type of network reinvigorates the pathogen with respect to the Overlapping Poissonian Small-World (O-PSW), as the underlying topology of S-PSW accounts for long-rage edges even at $p=0.0$  (cf. \autoref{fig:net_S-PSW}). As before, we will report the behavior of the order parameter at the end of the subsection.

By constrast with the O-PSW case, we will report at the beginning the epidemics with an higher transmissibility $ \beta = 0.1$ or recovery days $ d = 4$; while we postpone the plots for the epidemic spreading for COVID-19 parameters \autoref{fig:sir_SPSW_COVID}.

\subsubsection*{SIR on Regular S-PSW with enanched $ \beta = 0.1$ or $ d = 4$}
The following plots display how an epidemic behaves both for $ \beta = 0.1$ or $ d = 4$.
The former displays an enanchement of the final outbreak size $ \pi_{max}$ of nearly $ 21$ times the homologous for COVID-19 parameters \autoref{fig:sir_S-PSW_D5_p0.0}. The homologous Overlapping Poissonian Small-World (O-PSW) transition showed the total cases growing from $ \pi_{max} \sim 3 \% \textnormal{ to } \pi_{max} \sim 42 \%$(\autoref{sub@fig:sir_O-PSW_D5_p0}, \autoref{sub@fig:sir_O-PSW_D5_d14_b0.1}). The current is a more profound transition since the total cases for the CODIV-19 parameters are similar ( $ \pi_{max} \sim 4 \%$ ) while $ \pi_{max}\sim 82\%$ for the current network. Thus, a enanchement of $ 20$ times for \autoref{fig:SPSW_D5_b0.1_d14} over the previous $14$ of \autoref{sub@fig:sir_O-PSW_D5_d14_b0.1}.

By constrast, for the transition $D = 24, d = 4 \Rightarrow D = 11, d = 14 $ (\autoref{fig:sir_S-PSW_D10_p0.0} to \autoref{fig:sir_SPSW_D23_beta0.015_d4}) one finds that the growth factor is slightly higher the same as the OPSW one. More precisely, for the OPSW case, the total cases for $D = 11, d = 14$ are $ 1.5$ times the one for $ D = 24, d = 4$. Similarly, the same transition for the SPSW network yield that the former one is $ 2.43$ times the second. 

Finally, the sparse Poissonian Small-World (S-PSW) network is more sensible over the chosen parameter and, especially, on the change of the transmissibility $ \beta$. In fact, by accounting for long-range connection, it helps the pathogen to dive into pools of susceptible even if $ p = 0$.     

\clearpage
\begin{figure}[H]
	\centering
	\begin{subfigure}{0.8\linewidth}
		\includegraphics[width = \linewidth]{Results/PSW/SPSW/p0.0/Pec_Beh/NN_Conf_Model_SIR_R0_6_N1000_D5.0_p0.0_beta0.1_d14.0.png}
		\caption{Evolution of a disease with same recovery rate of \autoref{fig:sir_S-PSW_D5_p0.0} but an augmented $\beta$. The network constraints less the epidemic with respect to the O-PSW (see \autoref{fig:sir_O-PSW_D5_d14_b0.1}). Thus, helping the pathogen to reach $ 20$ times the population of \autoref{fig:sir_S-PSW_D5_p0.0}}
		\label{fig:SPSW_D5_b0.1_d14}
	\end{subfigure}
	\par\medskip
	\begin{subfigure}{0.8\linewidth}
		\includegraphics[width = \linewidth]{Results/PSW/SPSW/p0.0/Pec_Beh/NN_Conf_Model_SIR_R0_1_N1000_D23.0_p0.0_beta0.015_d4.0.png}
		\caption{(Pseudo-)linear growth of the total cases $\pi(t)$ for $d = 4$, e.g. after a COVID-19 vaccination campaign. The transition $D = 24, d = 4 \Rightarrow D = 11, d = 14 $ is slightly stronger than the one for a OPSW.}
		\label{fig:sir_SPSW_D23_beta0.015_d4}
	\end{subfigure}
	\caption{SIR evolution for increased transmissibility $ \beta = 0.1$ or recovery time $ d = 4$ .}
\end{figure}

\clearpage
\subsubsection{SIR evolutions increasing the average number of contacts}
The panel \autoref{fig:sir_SPSW_COVID} shows how the pathogen diffuses more easily than in the Overlapping Poissonian Small-World (O-PSW) (\autoref{fig:sir_O-PSW_COVID}) since the network is more scattered. We report the epidemic curves of the average contacts from $D = 5$ to $D = 14$ (\autoref{fig:sir_SPSW_COVID}), since at lower $D$, it is understood that the stochasticity is going to play a relevant role in blocking the diffusion; while on higher $D$ the exponential growth is recovered.

As a first remarkable result, the curve in \autoref{fig:sir_S-PSW_D10_p0.0} exhibits a maximum of the total cases $ \pi_{max}$ nearly $1.5$ times higher than the one in \autoref{fig:sir_O-PSW_D11_p0}. As expected, the strength of an epidemic depends also on the rewiring scheme of the nodes and not only by the degree distribution which node degrees were drawn from. Indeed, the evolution for $ p = 0$  bends nearly at the same time but with less infected, since the "local" interactions gives less sustain to the linear growth. As said also for the O-PSW, all the curves with a $D \lesssim D_c$ develop a pseudo linearity in the first part of the evolution (\autoref{fig:sir_O-PSW_D11_p0.3}). Then, after a certain time, they bend to reach the herd immunity.

\begin{figure}[p]
	\centering
	\begin{subfigure}{\linewidth}
		\centering
		\includegraphics[width = 0.9\linewidth]{Results/PSW/SPSW/p0.0/NN_Conf_Model_SIR_R0_1_N1000_D5.0_p0.0_beta0.015_d14.0.png}
		\caption{SIR spreading for $D = 5$ and COVID-19 parameters as in \autoref{fig:sir_O-PSW_D5_p0}. As in that case, $R_0 \gtrsim R_{c-net}$ provides a disease, which in short will naturally die out.}
		\label{fig:sir_S-PSW_D5_p0.0}
	\end{subfigure}
	\vfill	
	\begin{subfigure}{\linewidth}
		\centering
		\includegraphics[width = 0.9\linewidth]{Results/PSW/SPSW/p0.0/NN_Conf_Model_SIR_R0_2_N1000_D8.0_p0.0_beta0.015_d14.0.png}
		\caption{SIR evolution as the average number of contacts $ D = 8$ and $ p = 0$.}
		\label{fig:sir_S-PSW_D8_p0.0}
	\end{subfigure}
	\vfill
	\begin{subfigure}{\linewidth}
		\centering
		\includegraphics[width = 0.9\linewidth]{Results/PSW/SPSW/p0.0/NN_Conf_Model_SIR_R0_2_N1000_D10.0_p0.0_beta0.015_d14.0.png}
		\caption{The evolution for a larger number of contact $D = 10$. This is the upper bound of the threshold average contacts $ D_c \sim 10$, implying a small exponential outbreak at early times. As compared to the homologous in \autoref{fig:sir_O-PSW_D11_p0} there is a sensible enhancement (nearly of a $1.5$ factor of the total cases), due to the different network topology.}
		\label{fig:sir_S-PSW_D10_p0.0}
	\end{subfigure}
	\caption{Sparse PSW spread for COVID-19 parameters with $p = 0.0$ }
	\label{fig:sir_SPSW_COVID}
\end{figure}

\clearpage
\subsubsection*{Enanching transmissibility and recovery days for a Long-Range S-PSW}
Here, we will review the epidemic curves as generated by a stronger pathogen than COVID-19, i.e. $ \beta = 0.1$, or as the pharmaceutical interventions were at work diminishing the recovery days to $d = 4$.

\begin{figure}[H]
		\includegraphics[width = \linewidth]{Results/PSW/SPSW/p0.3/NN_Conf_Model_SIR_R0_7_N1000_D5.0_p0.3_beta0.1_d14.0.png}
	\caption{Higher final fraction of total cases with respect \autoref{fig:sir_O-PSW_D5_p0.3_b0.1}. On the other hand, the transition from local connections ($ p = 0$) to $ p= 0.3$ is higher for the OPSW network, since the underlying structure is locally constraining the pathogen. Hence, as $ p = 0.3$, the distant connections produces a stronger diffusion than in the SPSW, since the latter accounts for long-range interactions even at $ p=0$: $ \pi_{max} \sim 82 \%$ already at $ p = 0$ \autoref{fig:SPSW_D5_b0.1_d14}.}
	\label{fig:sir_SPSW_p0.3_D7}
\end{figure}
\begin{figure}[H]
	\includegraphics[width = \linewidth]{Results/PSW/SPSW/p0.3/NN_Conf_Model_SIR_R0_1_N1000_D24.0_p0.3_beta0.015_d4.0.png}
\caption{The evolution for a larger number of contact $D \sim 8$. The linearity is more evident in the $p = 0.3$ case \autoref{fig:sir_SPSW_p0.3_D7}.}
\label{fig:sir_SPSW_p0.3_D24}
\end{figure}

\clearpage
\subsection*{SIR evolution on Long-Range S-PSW}
As for the Overlapping Poissonian Small-World (O-PSW) network, we report the changing of behavior of the SIR epidemics by increasing the average number of contacts $D$. Since as expected the shape and behavior are barely the same of the case without long-range connections, we focus only on the main new features: the others, e.g. the fluctuations over the mean could be easily explained by looking at \autoref{ch:Methodology}.

\begin{figure}[ht]
	\centering
	\begin{subfigure}{\linewidth}
		\centering
		\includegraphics[width = 0.9\linewidth]{Results/PSW/SPSW/p0.3/NN_Conf_Model_SIR_R0_1_N1000_D5.0_p0.3_beta0.015_d14.0.png}
		\caption{SIR spreading for $D = 5$ and COVID-19 parameters as in \autoref{fig:sir_O-PSW_D5_p0}. Since $R_0 - R_{c-net}$ is positive but small, the epidemic starts but its randomness drives the pathogen to reach faster the turning point for which it will constantly decay. The \autoref{fig:sir_S-PSW_D5_p0.0} scenario was stronger even without long-range nodes. In constrast to what seen before, the long-range interactions seems to provide an escape route for the susceptible which facilitates the pathogen to die out.}
		\label{fig:sir_SPSW_COVID_D5_p0.3}
	\end{subfigure}
	\vfill	
	\begin{subfigure}{\linewidth}
		\centering
		\includegraphics[width = 0.9\linewidth]{Results/PSW/SPSW/p0.3/NN_Conf_Model_SIR_R0_1_N1000_D7.0_p0.3_beta0.015_d14.0.png}
		\caption{The evolution for a larger number of contact $D \sim 7$. Remarkably, there is a sharper bending after the first hundred days where linearity is at work.}
		\label{fig:sir_SPSW_COVID_D7_p0.3}
	\end{subfigure}
	\caption{Sparse PSW spread for COVID-19 parameters with $p = 0.0$ }
	\label{fig:sir_SPSW_COVID_p0.3}
\end{figure}

\clearpage
\begin{figure}[h]
	\centering
	\includegraphics[width = 0.9\linewidth]{Results/PSW/SPSW/p0.3/NN_Conf_Model_SIR_R0_2_N1000_D11.0_p0.3_beta0.015_d14.0.png}
	\caption{The evolution for a larger number of contact $D = 11$. This is the upper bound of the threshold average contacts $ D_c \sim 10$, implying a small exponential outbreak at early times. As compared to the homologous in \autoref{fig:sir_O-PSW_D11_p0.3} the transition from $ p = 0 \rightarrow p = 0.3$ brings to a smaller enhancement, nearly of a $1.8$ factor of the total cases with rispect to the $ 2.5$ of the Overlapping Poissonian Small-World (O-PSW) network.}
	\label{fig:sir_SPSW_COVID_D11_p0.3}
\end{figure}

\clearpage
\subsubsection*{Order Parameters}
\begin{figure}[ht]
	\begin{subfigure}[t]{0.48\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Results/PSW/SPSW/OrdParam/p0.0/NN_Conf_Model_ordp_p0.0_beta0.015_d14.0.png} 
		\caption{Order Parameter with fixed COVID-19 parameters. \newline $D_c \sim 8-10$ as in \autoref{fig:sir_O-PSW_COVID}}
		\label{fig:Ordp_SPSW_COVID-19_d14}
	\end{subfigure}
	\begin{subfigure}[t]{0.48\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Results/PSW/SPSW/OrdParam/p0.0/NN_Conf_Model_ordp_p0.0_beta0.015_d4.0.png}
		\caption{Order Parameter exhibiting a higher critical $D_c \sim 23$ since $\mu$ has been enhanced (cf \autoref{fig:sir_SPSW_D23_beta0.015_d4})}
		\label{fig:Ordp_SPSW_d4_COVID19}
	\end{subfigure}
	\caption{Regular Order Parameter at different epidemic rates $\mu = 1/d$}
	\label{fig:Ordp_SPSW_COVID}
\end{figure}

\begin{figure}[ht]
	\begin{subfigure}[t]{0.48\linewidth}
		\includegraphics[width=\linewidth, keepaspectratio]{Results/PSW/OPSW/OrdParam/p0.3/NNO_Conf_Model_addE_True_ordp_p0.3_beta0.015_mu0.07.png}
		\caption{Order Parameter dependence on $D$ with fixed COVID-19 parameters. $D_c \sim 10$ \cite{Thurner::NetBasedExpl} (cf. \autoref{fig:sir_SPSW_p0.3_D7})}
		\label{fig:Ordp_SPSW_p0.3}
	\end{subfigure}
	\begin{subfigure}[t]{0.48\linewidth}
		\includegraphics[width=\linewidth, keepaspectratio]{Results/PSW/OPSW/OrdParam/p0.3/NNO_Conf_Model_addE_True_ordp_p0.3_beta0.015_mu0.25.png}
		\caption{$D_c \sim 23$ as shown for \autoref{fig:sir_SPSW_p0.3_D24}}
		\label{fig:Ordp_SPSW_d4_p0.3}
	\end{subfigure}
	\caption{Long-Range Order Parameter for different recovery rates.}
	\label{fig:Ordp_SPSW_COVID_p0.3}
\end{figure}
In this subsection, we will report the evolution of the order parameter $SD(C(t))$ driven by  average number of contacts $D$, alongside with $D_{c-homog \, model} < D_{c-ER \, model} < D_{c-fuse \, model}$. Moreover, the critical degree $D_c$ is difficult to estimate at a plain eye inspection, as in the \autoref{fig:Ordp_OPSW_COVID19_panel}, since the transition among the linear-to-exponential is not so sharp. Hence, by looking at the SIR simulations, $D_c$ could be defined as the point, which $SD(C(t))$ grows with a different slope for.
For example, in \autoref{fig:Ordp_SPSW_COVID}, it could be seen that the departure from a pseudo-linearity is expected at $D \sim 10$.

\textbf{Regular and Long-Range S-PSW}

\autoref{fig:Ordp_SPSW_p0.3} displays two evolution of the Order Parameter similar to the $p = 0.0$ case.
Switching on the long-range interactions, the epidemics acquire enough strength to ease the exponential growth. Nevertheless, $p = 0.3$ produces a light modification in the number of daily cases which, in turn, produce a similar behavior of the standard deviation (SD) and on the position of $ D_c$. Thus, we used a cross comparison with previously reported SIR evolutions, \autoref{fig:Ordp_SPSW_COVID} and \autoref{fig:Ordp_SPSW_COVID_p0.3}, for a better estimation of in the different $D_c$ circumstances.

Moreover, as for the first figures in the two panels, the most reliable prediction of $ D_c$ comes from the \textit{fuse model} estimate $ D_c \sim 10$, since the $ p=0.3$ is sufficiently small to allow that the network resembles a fuse.
Rather, for the \autoref{fig:Ordp_SPSW_d4_COVID19}, the "fuse model" overestimates $ D_c$ as the Poissonian structure ease the growth of the standard deviation of the dainly new cases more than a fuse one. The critical degree of separation $ D_c$ is better described by the Erdös-Rényi model.
A slight better estimation from the fuse model is obtained if $ p = 0.3$ (\autoref{fig:Ordp_SPSW_d4_p0.3}), since $ D_{c-fuse \, model}$ is refined with the according to the probability of long-range nodes. Nervertheless, the $ D_c$ seems to be better approximated by the $D_{c-ER \, model}$.

Therefore as in the Overlapping Poissonian Small-World (O-PSW) case, the epidemics are enanched as the long-range interactions are switched on, namely when $ p=0.3$. By contrast, the critical degree for $ p = 0.3$ is similar to the one for $ p=0$ and behaves the same for parameter change, e.g. it rises for $d = 4$. Nevertheless, the Order Parameter curves seems to be slighly translated to the left for $ p = 0.3$, indicating that smaller average contacts $D$  drive to higher variation in the daily number of cases.

\clearpage
\section{Caveman Model}
\label{sec:res_CM}
\begin{figure}[t]
	\centering
	\includegraphics[width = 0.8\linewidth]{Results/Caveman_Model/AdjMat/Caveman_Model_AdjMat_999_3.2_0.3.png}
	\caption{The visualization of a Caveman model properties: the graphical representation (upper right), where the colored dots represent a family; the adjacency matrix (upper right) and the degree distribution (lower figure). In particular, this realisation is composed by 333 families arrange on a circle. We connected each clique on the (two) nearest neighboring caves through $1$ edge each. Then, we introduce a $p = 0.3$ fraction of distant nodes. Thus, the \autoref{eq:CavemanMod_D} yields $D \sim 3.2$.}
	\label{fig:CM_AdjMat_p0.3}
\end{figure}
The most sensible lock-down measure was the household restriction. By limiting the individuals to have contacts only within families (or small communities), the pathogen was enclosed into small pools of susceptible and, hopefully, confined, e.g. \autoref{fig:sir_CM_D5_ORL1}. As previously seen, forcing the nodes into overlapping neighboorhoods with a sufficiently low $ D$, diminishes the final outbreak size $ \pi_{max}$. Therefore, we will arrange the individuals in cliques; while fewer connections will be left for connecting to other families either locally or distantly. As expected, this network will reduce the fraction of total cases $\pi(t)$ with respect to the previous ones and, in particular, the Watts-Strogatz model.

Concretely, we used a "Caveman Model" (see \autoref{sec:RLN-Caveman_Description}) and we connected the communities/caves to the nearest neighboring ones with $ 1$ "on-ring link": in the following plots, we reported the "OnRing" links quantity (see \autoref{ch:Methodology}). By introducing these "local" interactions, the assumption is that a family shares with two other ones only \textit{one} "risky contact", e.g. going to the \textit{same} supermarket. This is case whenever the families are distant or only a small fraction of the population is traced, e.g. by a voluntary usage of the mobile-application Immuni.

Moreover, we introduced the wiring probability $p$ to the distant nodes to account for the leisure activities as expected for a light lockdown. All the edges are added to the previously existing connections not to destroy the family structures. Therefore, we calculated the average number of contacts $D$ by using 
\begin{equation}
	D \sim N_{cl}-1+2 \cdot p+\frac{2\cdot L_{nx}}{N}
	\label{eq:CavemanMod_D}
\end{equation} 
where $N_{cl}, L_{nx}$ are, respectively, the number of nodes composing a community and the number of links, the next community is reached with. 

As a brief outline, we will treat firstly the COVID-19 scenario ($\beta = 0.015 \textnormal{ and } d = 14$), then, we will modify the transmissibility $\beta = 0.1, \textnormal{ and the recovery days }  d = 4$. More specifically, we considered $\beta = 0.1$ to test how the network structure could respond to a stronger pathogen; while $ d = 4$ to capture the evolution of the COVID-19 when treated with the pharmaceutical interventions, such as a vaccines.

Lastly, the evolution of the order parameter is not displayed since we simulated the epidemics for a limited number of average contacts $D$.


\clearpage
\subsection*{SIR with Local Interactions}
In this part, we will report the spreading of COVID-19 on a Caveman Model with $1$ on ring link and $p = 0.0$\footnote{In truth, we simulated the epidemic for both $1 \textnormal{ and 3}$ on-ring-links, but we review only the $OnRing = 1$ case since $OnRing = 3$ have the same behavior but reaching a higher fraction of population.}. As seen previously, by fixing the epidemic parameters ($ \beta, \mu$), the epidemic grows faster as $D$ increases. 

In \autoref{fig:sir_CM_D5_ORL1}, the final outbreak size $ \pi_{max}$ is smaller then the other cases for the Overlapping Poissonian Small-World (O-PSW) model \autoref{fig:sir_O-PSW_COVID}. Thus, this topology shows a better control on the pathogen. Nevertheless, we report in \autoref{fig:sir_CM_D4_OR1_d14_b0.1} a scenario for which the pathogen invade a considerable fraction of the population. This drives to the insight that with an higher transmission rate, namely $ \beta = 0.1$, only drastic restrictions can limit the disease, e.g. forced quaranties. 

Moreover, in \autoref{fig:sir_RegLat_D2_p0} we showed a regular Watts-Strogatz model with the nodes disposed on a circle. In \autoref{fig:sir_CM_D3_ORL1}, instead, we will display a simlar structure: families of $3$ nodes connected only locally on a ring. The latter structure will slow down the spreading as compared to the former one. Indeed, the total cases $ \pi_{max} $ will diminish by the $ 37\%$: for a ring of nodes $ \pi_{max} \sim 4.3\%$ while, for the current model, $ \pi_{max} \sim 1.6\%$.
Note that the household size for European country has been estimated around $ 2.3$ persons per family \cite{Householdsize:2020} and similarly ($\sim 2.53 $) for the United States.
\autoref{fig:sir_CM_D5_ORL1} displays a COVID-19 diffusion for a family of $ 5$ individuals and  $"On Ring" = 1$ link: $D\sim 4.4$  as yielded by the \autoref{eq:CavemanMod_D}. The other plots will dimish the total cases as reviewed before.

\begin{figure}[htbp]
	\centering
	\begin{subfigure}{\linewidth}
		\includegraphics[width = 0.9\linewidth, height = 0.25 \textheight]{Results/Caveman_Model/p0.0/Caveman_Model_SIR_R0_1_N999_D3.0_p0.0_beta0.015_d14.0.png}
		\caption{A pathogen spreading on a Caveman Model with $D \sim 2.67$. We fixed each family to have three individuals and we wired each clique to the next one with $ 1$ edge. Thus, the disease spreads less than in \autoref{fig:sir_RegLat_D2_p0}: in that topology $ \pi_{max} \sim 4.3\%$ for $ D = 2$. Note that $ D = 2.67$ is comparable to household european size (\cite{Householdsize:2020}) or the USA one (\cite{HouseholdsizeUSA:2020}).}
		\label{fig:sir_CM_D3_ORL1}
	\end{subfigure}
	\centering
	\begin{subfigure}{\linewidth}
		\includegraphics[width = 0.9\linewidth, height = 0.25 \textheight]{Results/Caveman_Model/p0.0/Caveman_Model_SIR_R0_1_N1000_D4.0_p0.0_beta0.015_d14.0.png}
		\caption{A pathogen spreading on a Caveman Model with $D \sim 4.4$. Compared with \autoref{fig:sir_O-PSW_D5_p0}), the caveman model diminishes the final total cases $ \pi_{max} $.}
		\label{fig:sir_CM_D5_ORL1}
	\end{subfigure}
	\caption{COVID-19 pathogen spreading on cliques.}
\end{figure}
\begin{figure}[htbp]
	\begin{subfigure}{\linewidth}
		\includegraphics[width = \linewidth, height = 0.3 \textheight]{Results/Caveman_Model/p0.0/Caveman_Model_SIR_R0_2_N990_D10.0_p0.0_beta0.015_d14.0.png}
		\caption{A pathogen spreading on a Caveman Model with $D = 11$}
		\label{fig:sir_CM_D10_ORL1}
	\end{subfigure}
	\begin{subfigure}{\linewidth}
		\includegraphics[width = \linewidth, height = 0.3 \textheight]{Results/Caveman_Model/p0.0/Caveman_Model_SIR_R0_3_N994_D13.0_p0.0_beta0.015_d14.0.png}
		\caption{A pathogen spreading on a Caveman model with $D = 14$}
		\label{fig:sir_CM_D13_ORL1}
	\end{subfigure}
	\caption{Last two spreading regarding an average degree $ D = 11 \textnormal{ and } D = 14$, as the previous networks, with "OnRing" = 1. These epidemic curves shows how cliques produce a drop in the $ \pi_{max} $ reached by the pathogen as in contrast with the percentages reported in \autoref{fig:sir_O-PSW_D11_p0}, \autoref{sub@fig:sir_RegLat_D14}.}
	\label{fig:sir_CM_COVID}
\end{figure}

\clearpage
\subsection*{Exploring SIR parameter on Caveman Model}
This first figure of the next panel shows an epidemic curve as transmission rate $\beta = 0.1$ (\autoref{fig:sir_CM_D5_ORL1}) while the other parameters are drawn from \autoref{fig:sir_CM_D5_ORL1}. An example could be a new variant immune to a vaccine developed for the older one. Nevertheless, since the network allows for a localized spread, the overall fraction of total cases stays small even if the pathogen has $7$ times the transmissibility of the initial agent.

The second figure \autoref{fig:sir_CM_D13_ORL1} is characterized by a recovery rate of $ \mu = 1/4$ while other parameter are in accordance with the \autoref{fig:sir_CM_D23_d4}. This is a paradigmatic situation where pharmaceutical interventions are at work and the mean $ d = 4$ accounts for the fact that both vaccinated and not-vaccinated individuals are present inside a population. Therefore, it is reported a decreasing in the overall infected nodes.   

\begin{figure}[htbp]
	\centering
	\begin{subfigure}{0.8\linewidth}
		\includegraphics[width = \linewidth, height = 0.2\textheight]{Results/Caveman_Model/p0.0/Pec_Beh/Caveman_Model_SIR_R0_6_N1000_D4.0_p0.0_beta0.1_d14.0.png}
		\caption{A pathogen stronger than COVID-19 keeping fixed the time to recover, e.g. a new variant immune to a vaccine for a different type of COVID-19. The current structure drives to $ \pi_{max} \sim 13\%$; while for a OPSW model the \autoref{sub@fig:sir_O-PSW_D5_d14_b0.1} shows a greater fraction $ \pi_{max} \sim 82\%$.}
		\label{fig:sir_CM_D4_OR1_d14_b0.1}
	\end{subfigure}
	\par\bigskip
	\centering
	\begin{subfigure}{0.8\linewidth}
		\includegraphics[width = \linewidth, height = 0.2\textheight]{Results/Caveman_Model/p0.0/Pec_Beh/Caveman_Model_SIR_R0_1_N984_D23.0_p0.0_beta0.015_d4.0.png}
		\caption{Fixed the transmissibility coefficient to COVID-19, while decreasing the recovery to $d = 4$, the pathogen diffuses less than in \autoref{fig:sir_O-PSW_D24_d4}. This is also recovered by looking at the bump in the infected (azure dots) which is more contained than in the quoted figure.}
		\label{fig:sir_CM_D23_d4}
	\end{subfigure}
	\caption{SIR evolution for $D = 4, \beta = 0.1$ or $ D=23,d=4$. The remaining parameters are drawining from the previous plots.}
	\label{fig:sir_CMD4b0.1_D23d4}
\end{figure}

\clearpage
\subsection{Long-Range Caveman model}
\label{sec:res_LRCM}

In this section, there would be analyzed the epidemic curves of a Caveman with both local ("On Ring Links") and long-range interactions by switching on the wiring probability $p = 0.3$. Thus, the network has families arranged on a circle, but also distant links due, for example, to work or leisure activities.
In general, for $ p \neq 0$, the curves would be enhanced with respect to $ p = 0$, but at which extend strongly depend on the network: the sparse Poissonian Small-World (S-PSW) case, since even at the $ p = 0$ level accounted for some distant connection, the increasing in $ \pi_{max} $ was less significant (cf \autoref{fig:sir_O-PSW_D5_p0.3}) than in the OPSW network.  Thus, for a correct interpretation of the curves, it would be done a direct comparison with other topologies for $p = 0.3$. In particular, altough the enanchment, namely the ratio among $ p = 0.3$ and $ p=0$ cases, is similar to the \autoref{fig:Ordp_OPSW_COVID19_p0.3_panel}, the panel below validates the insight that this model is constraining more the epidemic that others, for e.g. the O-PSW case (cf. \autoref{fig:Ordp_OPSW_COVID19_p0.3_panel}).
\begin{figure}[htbp]
	\centering
	\begin{subfigure}{0.9\linewidth}
		\includegraphics[width = \linewidth]{Results/Caveman_Model/p0.3/Caveman_Model_SIR_R0_1_N1000_D5.0_p0.3_beta0.015_d14.0.png}
		\caption{A pathogen spreading in a Caveman Model with $D \sim 4.4+ 2\cdot p = 5$, according to \autoref{eq:CavemanMod_D}. The enanchement $ \frac{\pi_{max @ p = 0.3}}{\pi_{max @ p = 0.0}} $ is similar to the OPSW one (cf \autoref{fig:sir_O-PSW_D5_p0}) }
		\label{fig:sir_CM_D4_OR1_p0.3}
	\end{subfigure}
	\par\smallskip
	\begin{subfigure}{0.9\linewidth}
		\includegraphics[width = \linewidth]{Results/Caveman_Model/p0.3/Caveman_Model_SIR_R0_2_N990_D11.0_p0.3_beta0.015_d14.0.png}
		\caption{A pathogen spreading in a Caveman Model with $D = 11, p = 0.3$. The enanchement of $\pi(t)$, with respect to the $ p=0$ evolution, is comparable with the one of \autoref{fig:sir_O-PSW_D11_p0.3} but the overall value $ \pi_{max}$ is nearly $3$ times the present one. This supports the initial idea that this network constrains more the epidemic.}
		\label{fig:sir_CM_D11_p0.3}
	\end{subfigure}
	\par\smallskip
	\begin{subfigure}{0.9\linewidth}
		\includegraphics[width = \linewidth]{Results/Caveman_Model/p0.3/Caveman_Model_SIR_R0_3_N994_D14.0_p0.3_beta0.015_d14.0.png}
		\caption{A pathogen spreading in a Caveman model with $D = 14, p = 0.3$. The discussion is the same of $D = 11$ one.}
		\label{fig:sir_CM_D13_p0.3}
	\end{subfigure}
	\caption{SIR model with COVID-19 parameters evolution for different average number contact per individual.}
	\label{fig:sir_CM_COVID_p0.3}
\end{figure}

\clearpage
\subsection*{Exploring SIR parameters}
On the way to understand more deeply how network interacts with the pathogen, it is worth addressing the questions on how a different epidemic could express and at which extent the recovering of the nodes are relevant on the same underlying model. The former would be analyzed by changing only $\beta = 0.1$; while the latter by fixing $d = 4$.
\begin{figure}[H]
	\centering
	\begin{subfigure}{0.9\linewidth}
		\includegraphics[width = \linewidth]{Results/Caveman_Model/p0.3/Pec_Beh/Caveman_Model_SIR_R0_7_N1000_D5.0_p0.3_beta0.1_d14.0.png}
		\caption{A pathogen more contagious than COVID-19 but with same time of recovering, e.g. a new variant immune to a vaccine for a different type of COVID-19. Weighted against \autoref{fig:sir_O-PSW_D5_d14_b0.1}, the suppression is not so high since the pathogen is really strong. This is the effect of a strong epidemic agent, which could be nearly approximated by a "well-mixed" model. In fact, there are $p \cdot N \sim 600$ distant edges which drive the caveman model to be similar to an Annealed-Mean-Field Network.}
		\label{fig:sir_CM_D4_p0.3_OR1_b0.1}
	\end{subfigure}
	\par\bigskip
	\centering
	\begin{subfigure}{0.9\linewidth}
		\includegraphics[width = \linewidth]{Results/Caveman_Model/p0.3/Pec_Beh/Caveman_Model_SIR_R0_1_N984_D24.0_p0.3_beta0.015_d4.0.png}
		\caption{Fixed the transmissibility coefficient to COVID-19, while decreasing the recovery to $d = 4$, the pathogen is less diffuse than in \autoref{fig:sir_O-PSW_D24_d4_p0.3}.}
		\label{fig:sir_CM_D23_d4_p0.3}
	\end{subfigure}
	\caption{SIR evolution for $D = 4, \beta = 0.1, p = 0.3$ or $ D=23,d=4, p = 0.3$. The remaining parameters are drawining from the previous plots.}
	\label{fig:sir_CMD4b0.1_D23d4_p0.3}
\end{figure}

\clearpage
\section{Barabási-Albert Model}
\label{sec:res_BA}
\begin{figure}[t]
	\centering
	\includegraphics[width = 0.5\linewidth]{Results/BA_Model/AdjMat/BA_Model_AdjMat_1000_28.0_0.0_14_14.png}
	\caption{Barabási-Albert Model which generates the hubs according to the preferential attachment and growth mechanisms (see \autoref{sec:BA_model} and \autoref{App:OriginOfPA}). The presence of highly connected nodes could be seen in the standard deviation of the average number of contacts $ D$ . In fact, $ D$ is not a reference scale for the network as in the case of a Poissonian one (see \autoref{sec:SFProperties}). The white square on the top left represents the starting point to build a BA model. Indeed, we chose to begin with a star graph of $D/2$ nodes and, then, to add the newer node to it.}
	\label{fig:BA_model_Network}
\end{figure}

As seen in \autoref{sec:BA_model}, this network topology allows to fit a variety of real networks, since it accounts for the presence of the hubs. As for the description of the "lockdown", this is the case, but it is worthwhile to devote a section to it, in order to capture the novelties that hubs could provide with respect a less spread degree distribution such as a Poissonian one.
Ultimately, this kind of network is going to augment the spreading power of the disease. Hence, it would better used for other kind of spreading, e.g. the diffusion of knowledge.

\subsubsection*{SIR evolution}
The panel \autoref{fig:sir_BA_COVID} displays different epidemic curves depending on the average number of contacts $D$. By contrast to the previous evolutions, for $D = 6$ the scale-free topology allows to increase the pathogen power over the mean-field one, as shown in \autoref{fig:sir_BA_D6} and described in \autoref{ch:sir-models}.
After that burst, starting from $D = 10$ on, the "well-mixed" model retakes the lead in spreading the disease. 

An extended linearity, such as frequent as in the other topologies (\autoref{fig:sir_O-PSW_D24_d4}). However, it could be the case when the pathogen is constrained either by a small amount of neighbors (\autoref{fig:sir_BA_D2}) or by a high recovery rate \autoref{fig:sir_BA_d1D47}. More in depth, that figure shows a $D \sim 22 \textnormal{ and } d = 4$, which represents a huge number of average contacts and the smallest period of incubation. Therefore, the scale-free networks could enhance the pathogen strength, as the hubs are the high-ways for diffusion. On the other hand, it is possible to reduce the pathogen settling a vaccination campaign targeting the hubs (doctors, nurses,$\cdots$) or, further, closing the infrastructural hubs, such as airports or cruises.

\begin{figure}[p]
	\begin{subfigure}{.9\linewidth}
		\includegraphics[width = \linewidth]{Results/BA_Model/p0.0/BA_Model_SIR_R0_0_N1000_D2.0_p0.0_beta0.015_d14.0.png}
		\caption{A pathogen spreading in a BA model with $D = 2$. As expected, the value of the total cases $ \pi_{max}$ is higher than \autoref{fig:sir_CM_D3_ORL1}}
		\label{fig:sir_BA_D2}
	\end{subfigure}
	\vspace{.5cm}
	\begin{subfigure}{.9\linewidth}
		\includegraphics[width = \linewidth]{Results/BA_Model/p0.0/BA_Model_SIR_R0_1_N1000_D6.0_p0.0_beta0.015_d14.0.png}
		\caption{A pathogen spreading in a BA model with $D = 6$. The final outbreak size is far higher that the previous models (see \autoref{fig:sir_O-PSW_D5_p0})}
		\label{fig:sir_BA_D6}
	\end{subfigure}
	\vfill
	\begin{subfigure}{.9\linewidth}
		\includegraphics[width = \linewidth]{Results/BA_Model/p0.0/BA_Model_SIR_R0_2_N1000_D10.0_p0.0_beta0.015_d14.0.png}
		\caption{A pathogen spreading in a BA model with $D = 10$. The Barabási-Albert model has retaken the lead over the mean-field represeted by the Annealed-Mean-Field Network.}
		\label{fig:sir_BA_D10}
	\end{subfigure}
	\caption{SIR evolution on a Barabási-Albert Model}
	\label{fig:sir_BA_COVID}
\end{figure}

\clearpage
\subsubsection{Changing epidemic parameters}
Here, we report the most peculiar curve obtained by increasing the transmission rate $ \beta = 0.1$ and the days to recover $ d = 4$. 
\begin{figure}[H]
	\begin{subfigure}{\linewidth}
		\centering
		\includegraphics[scale = 0.15]{Results/BA_Model/p0.0/Pec_Beh/BA_Model_SIR_R0_8_N1000_D6.0_p0.0_beta0.1_d14.0.png}
		\caption{Diffusion on a BA model with $\beta = 0.1$. The straightforward comparison with the \autoref{fig:sir_SPSW_D23_beta0.015_d4}, highlights a pathogen with a remarkable power that with the same underlying parameter it has spread on the entire population with respect to COVID-19. Moreover, the fluctuations of the trajectories over the mean are negligible, yielding a scenario where it is highly improbable not to get the disease.}
		\label{fig:sir_BA_D6_b0.1}
	\end{subfigure}
	\par\bigskip
	\begin{subfigure}{\linewidth}
		\centering
		\includegraphics[scale = 0.15]{Results/BA_Model/p0.0/Pec_Beh/BA_Model_SIR_R0_1_N1000_D22.0_p0.0_beta0.015_d4.0.png}
		\caption{Despite the fast healing of the infected individuals, the network enables a diffusion on a larger fraction of population than "free" previous spreading. Only a vaccination campaign addressed to the hubs could produce a relevant drop in the number of cases.}
		\label{fig:sir_BA_d1D47}
	\end{subfigure}
	\caption{SIR model with enanched parameters}
\end{figure}

\clearpage
\subsubsection*{Order Parameters}
As the network enhances the possibility of a pathogen to diffuse, for the COVID-19 parameters a clear $D_c$ does not exists; meanwhile, taking advantage of the (possible) Pharmaceutical Interventions (PIs), the $d = 4$ case is characterized by a sharper transition among the linear and exponential growth. Only the "mean-field" approximation could capture the behavior of the $ D_c$ since hubs are enhancing the network strength of the pathogen over the AMFN. The "fuse model" clearly deviates from the $ D_c$ estimate. 
\begin{figure}[t]
	\begin{subfigure}[t]{0.48\linewidth}
		\centering
		\includegraphics[width = \linewidth, height = 5cm]{Results/BA_Model/OrdParam/BA_Model_ordp_p0.0_beta0.015_d14.0.png}
		\caption{Linear growth in the $SD(C(t))$ for COVID-19 parameters with no critical degree.}
		\label{fig:Ordp_BA_d14}
	\end{subfigure}
	\hfill
	\begin{subfigure}[t]{0.48\linewidth}
		\centering
		\includegraphics[width = \linewidth, height = 5cm]{Results/BA_Model/OrdParam/BA_Model_ordp_p0.0_beta0.015_d4.0.png}
		\caption{Order Parameter for a fast recovery rate $ d = 4$.}
		\label{fig:Ordp_BA_COVID_d1}
	\end{subfigure}
	\caption{Order Parameter for Barabási-Albert Model}
	\label{fig:Ordp_BA_COVID}
\end{figure}


\chapter{Conclusions}

The main purpose of this thesis, as anticipated in \autoref{sec:ATechIntro}, was to study the "evolution" of an epidemic outbreak over different social network topologies. In fact, the rationale was to try simulating the lockdown restriction either through a drop of the average number of contacts $D$, as reported by \cite{Liu::2021_Review_SContactPattern}; and changing the network structure, such as to consider the nodes aggregated into families \autoref{sec:RLN-Caveman_Description}.
Therefore, we obtained interesting results for a Watts-Strogatz model \autoref{sec:res_RegLat}, a realizations of a Poissonian Small-World (\autoref{sec:res_OPSW}, \autoref{sec:res_SPSW}) network,  the Caveman model \autoref{sec:res_CM} and a Barabási-Albert model \autoref{sec:res_BA}. 
Specifically, we recovered that the diffusion of the pathogen in a network is much constrained than the mean-field approximation. Many networks acconts for a  "sub-exponential" regime differently to the exponential one yielded by the homogeneous mean-field approximation e.g. \autoref{fig:sir_RegLat_D2_p0}. Yet, we reported also some configurations for which the mean-field approximation drives to a linear growth at early times. This is, really, the case when the average number of contacts $D$ is "sufficiently" small as in \autoref{fig:sir_CM_D5_ORL1}. Nevertheless, the focus is that the evolution of a heterogeneous SIR model (see \autoref{eqs:SIR_degree-based}) reveals that the underlying structure strongly affects the size of the outbreak.

The Caveman model provides the best way of tackling to a restrictions in contacts as it is show by accounting for $ D \sim 2.67$ as the european household size. Then, for a light reopening we find that the Overlapping Poissonian Small-World (O-PSW) network is better suited to constrait the epidemic burdening while allowing for a variability of contacts. Then, a Watt-Strogatz model, subsequently a Overlapping Poissonian small-world network and finally a Barabási-Albert model which enahanches the pathogen "strength" by taking advantages from the hubs.  


Moreover in \autoref{sec:res_RegLat}, we pointed out how the \textit{basic reproduction number} $ R_0 $ is only a local parameter which describes the number of secondary infected; while the network structure could develop antipodal outbreak sizes cf. \autoref{fig:sir_RegLat_D61430}. Therefore, we introduced the new measure called \textit{epidemic severity}
\begin{equation}
	\Delta R_0 (\delta):= \frac{R_0 - R_{c-net}}{\delta}
	\label{eq:res_def_DR0delta}
\end{equation}
where $\delta:=\langle l \rangle $ is the average path length. The quantity provides a more precise measure of how the pathogen could diffuse over the network also thanks to the "vicinity" of nodes captured by the inverse of the average path length $1/\delta$. An example is reported in \autoref{fig:sir_O-PSW_D11_p0}.

Looking for a transition among "sub-exponential" and "exponential" regimes, we considered the order parameter introduced by Thurner et al. in \cite{Thurner::NetBasedExpl}, namely
\begin{equation}
	O := SD(C(t)) = 
	\begin{cases}
		0 \qquad \text{if $C(t) = constant$}\\\\
		\neq 0 \qquad \text{otherwise.} 
	\end{cases}
	\label{eq:res_def_OrdP}
\end{equation}
as deepened in \autoref{sec:OrderParam4LinContagion}.
This quantity accounts for a kind of first-order-phase transition which typically emerges as in \autoref{fig:Ordp_OPSW_COVID19_panel} and has been reviewd only for the Overlapping Poissonian Small-World (O-PSW), the sparse Poissonian Small-World (S-PSW) and the Barabási-Albert models, since the Watts-Strogatz and the Caveman models were generated with peculiar properties \autoref{sec:res_RegLat}, \autoref{sec:res_CM}. 
Furthermore, we analyzed 3 critical degree of contacts $D_c$ for which the transition is expected (see \autoref{sec:OrderParam4LinContagion}): $D_{c-homog \, model}, D_{c-ER \, model}, D_{c-fuse \, model}$. 
In particular, for the Poissonian models (OPSW and SPSW) $D_c$ is well estimated by a fuse approximation when the recovery days $d$  are high, i.e. $d = 14$ \autoref{fig:Ordp_OPSW_COVID19_panel}, \autoref{fig:Ordp_SPSW_COVID}. This is somehow to be expected since we have actively rewired the Poissonian degree to generate the best local structure \autoref{sec:res_OPSW}, \autoref{sec:res_SPSW}.
On the other hand, whever $ d = 4$, e.g. vaccines are introduced, the  $D_{c-fuse \, model}$ overestimates the real transition degree. In particular, this is a peculiar result displaying that whenever the recovery rate is small, the fuse model constrains the epidemic in a more suited way than the Poissonian models. In turn, this implies that it would be more difficult to have an exponential outbreak and, thus, an higher $ D_c$.
By contrast, a Barabási-Albert model enhances the "permeability" of the pathogen into the population (see \autoref{sec:res_BA}). Thus,the critical degree is better estimated accoring to a mean-field model \autoref{fig:Ordp_BA_COVID}. Remarkably, considering the $d = 4$ scenario, the "sub-exponential" regime is extended until $D_{c-homog \, model}$. This could, further, suggest that recovering at first the highly connected nodes (hubs) could be a finer way to prevent an exponential outbreak in this kind of topology.

\section{Future Developments}

\appendix
\chapter{Appendix}
\section{Scale-Free Distributions Details}
\label{sec:SFD_details}
In the following part, the discrete approach, assuming $k = 0,1,2\cdots$, is going to be developed; while only the continuum result would be reported. In fact, the discrete approach provides the ready-to-use formulas handle by a calculator which, by construction, performs discrete operations. On the other hand, the continuum approach is useful for analytically support the calculations and could be obtained similarly to the discrete case.
Formally, by exploiting the constraint on probabilities $p_k = C\cdot k^{-\gamma}$ \[\sum_{k=1}^{\infty} p_k = 1,\] it is possible to recover the closed form \cite{barabasi::2016networkbook}
\begin{equation}
	p_k = \frac{1-p_0}{\zeta(\gamma)}k^{-\gamma}.
	\label{eq:p_scalefree}
\end{equation}
where $p_0 = p_{k=0}$ has been separated, since the power-law diverges for $k=0$.

On the another hand, the continuum formalism drives to \[p(k) = (\gamma-1)k_{min}^{\gamma-1}k^{-\gamma},\] since the the smallest value for the power law to hold is not $1$, as in the discrete approach, but the minimum degree for a node $k_{min}$. 

Formally, $k_{min}$ is the degree for which
\begin{equation}
	\int_0^{k_{min}-1} p(k) dk \stackrel{!}{=} 1/N \qquad \textnormal{or} \qquad P(k_{min}-1) \stackrel{!}{=} 1/N.
	\label{eq:kminrel}
\end{equation}

In the next part, the allowed maximum degree $k_{max}$ would be obtained both for an exponential bounded and a power-law distributions. Through this quantitative insight, it would be shown the dependence of $k_{max}$ on $N$, i.e. the size of the network. 

In particular, the exponential distribution for which \(\int_{k_{min}}^{\infty} p(k) dk = 1\) holds, is \[ p_k = \lambda e^{\lambda k_{min}} e^{-\lambda k} \] where, using \autoref{eq:kminrel}, $k_{min} = 1$.
Furthermore, $k_{max}$ (or the "natural cutoff") is defined to be such that the at most one node $i$ could have a degree $k_i$ larger than $k_{max}$. \newline In other words, the cumulative distribution for degrees greater than $k_{max}$ is $1/N$; and, hence, $k_{max}$ is expected to be the size of the bigger hub.

In formulas, 
\begin{equation}
	\int_{k_{max}}^{\infty} p(k) dk = 1/N \implies k_{max} = k_{min} + \frac{\ln(N)}{\lambda}.
	\label{eq:Expkmax}	
\end{equation}
Hence, $k_{max}$ would not differ much with respect to $k_{min}$ since $\ln(N)$ strongly reduces contribution due to the size of the graph $N$.
For a Poisson distribution, more effort is needed but the same interpretation holds.

On the other hand, applying the same rationale to a scale-free network, 
\begin{equation}
	k_{max} = k_{min}\,N^{\frac{1}{\gamma-1}}.
	\label{eq:SFkmax}
\end{equation}
In this case, $k_{max}$ can differ many order of magnitude from $k_{min}$.
Indeed, as a simple example, WWW forms a graph of on $N \sim 10^5$ documents with $\langle k \rangle \simeq 4.6$ and $\gamma = 2.1$ \cite{barabasi::2016networkbook}. 
By assuming $\lambda = 1 \textnormal{ and recovering that }, k_{min} = 1$ using \autoref{eq:kminrel}, $k_{max} \sim 14$; while $k_{max} = 95.000$ for a scale-free network with $\gamma = 2.1$, e.g. WWW network. This short result reinforces the quoted insight that for the class of "exponentially bounded distributions" the hubs are strongly forbidden since the nodes have comparably the same degree. Instead, the highly connected nodes are naturally arising by increasing $N$ with an underlying power-law distribution.
\label{sec:SFProperties}

Not all the network are scale-free since the hubs are present only if nodes have unlimited degree capacities.
In fact, there could be constraints, such as cost-benefit problem, which limit $k_{max}$ of the bigger node. In this overview, random network may be the best fit, e.g. national highways network, power grid of generators and switches, $\cdots$

With all the previous effort a more quantitative approach to the explanation on the "scale-free" etymology could be ultimate.
More precisely, defining the statistics momentums as
\begin{equation}
	\langle k^n \rangle := \int_{k_{min}}^{k_{max}} k^n\, p(k) dk
\end{equation}
it is possibile to recover the the mean and the variance for $n = 1,2$.
Thus, for a Poissonian distribution, the nodes degree $k$ belong to $\langle k \rangle \pm  \langle k \rangle ^ {1/2}$ interval, which drives to the desired $\langle k \rangle$ scale. At the same time, for a power-law distribution holds	
\begin{equation}
	\langle k^n \rangle \sim \frac{k_{max}^{n-\gamma+1}-k_{min}^{n-\gamma+1}}{n-\gamma+1}
	.
\end{equation}
Therefore, knowing that real networks have typically $\gamma \in (2,3)$, e.g. WWW has $\gamma =  2.1$ \cite{barabasi::2016networkbook}
\begin{equation}
	k \in \langle k \rangle \pm \lim_{N \to \infty} \langle k^2 \rangle = \infty.
\end{equation}
where the hidden limit of \( k_{max} \to \infty \) is understood, since $k_{max}$ increases with the system size. 
Hence, no scale naturally arises.

The result rapidly quoted before is surrounded by three other regimes 
\cite{Cohen:2003_SFUSW}:

\begin{equation}
	\langle d \rangle = 
	\begin{cases}
		constant & \gamma = 2 \\ \\
		\ln(\ln(N)) & \gamma \in (2,3) \\ \\
		\frac{\ln(N)}{\ln(\ln(N))} & \gamma = 3 \\ \\
		\ln(N) & \gamma > 3
	\end{cases}
	\label{eq:USWdistance}
\end{equation}
\newline
\textbf{Anomalous Regime ($\gamma = 2$)}: Due to $k_{max} \sim N$, the network is forced into a "wheel rim configuration", a central hub with spoke nodes. In this regime, the average path length is independent on the size of the graph.
\newline
\textbf{Ultra-Small World Regime ($2 < \gamma < 3$)}: By predicting a $\ln(\ln(N))$ trend of the average distance, \autoref{eq:USWdistance} guides to the concept of "ultra-small world phenomenon" as a slower growth than random network. Indeed, recalling the worldwide social network, \(\ln\ln(N) \sim 3 \text{ while } \ln(N) \sim 22\) more than few times higher than the expected "six degrees of separation".
\newline
\textbf{Critical Point ($\gamma = 3$)}: Looking back on the \autoref{eq:sigma_SFnets}, the variance ($n=2$) is finite, marking the passage between the small-world ($\sim \ln(N)$) and the ultra-small world ($\sim \ln(\ln(N))$) classes of graphs.
\newline
\textbf{Small World ($\gamma > 3$)}:
In this regime, the finiteness of the variance is understood, due to the light aggregation that the high-degree nodes could perform in these kind of networks.

Moreover, recalling the root of "ultra-small world" \autoref{eq:SFkmax}, for $N \lesssim 10^2$ the path length distributions overlap in all the reported regimes and, so, converges to a Poisson distribution ($\gamma > 3)$ whose hubs are small to produce the "ultra-small world" phenomenon. In fact, to validate the power-law nature of a distribution, the nodes degree should be separated by 2-3 orders of magnitude. Hence, reverting the \autoref{eq:SFkmax},
\[N = \left(\frac{k_{max}}{k_{min}} \right)^\frac{1}{\gamma -1},\]
which lucidly reproduce $N \sim 10^2$ for $\gamma = 2.1$ (WWW network).

Thus, \(\langle d \rangle\) is changing with $\gamma$, as the smaller it is, the shorter would be the average distance; but also with $N$, as it is the "ab ovo" hypothesis for having big hubs.

A sociological fact has to be remarked when trying to map the "ultra-small" world over social interactions. Indeed, an online experiment which aimed to replicate the "six degrees" concept find that individuals involved in complete chains, reaching their target, were less likely to send a message to a hub than individuals involved in incomplete chains \cite{Dodds:2003_GSonlineNet_6deg}. The reason may be self-imposed, since hubs are perceived as being busy, so contacted only in real need and avoid to concretely complete an "online experiment" challenge. Thus, network is not everything since actual success depends sensitively on individual incentives.


\newpage
\section{Recovering Power-Law Distribution}
\label{App:RecPLD}
Due to a new $m-$stubs node, the degree of an existing node $i$ changes at a rate
\begin{equation}
	\frac{dk_i}{dt} = m \Pi(k_i) = m \frac{k_i}{\sum_j k_j}
	\label{eq:BA_dk_i/dt}
	.
\end{equation}
Hence, for $t >> 1$, 
\begin{equation}
	k_i(t) = m \left(\frac{t}{t_i}\right)^\beta
	\label{eq:BA_modki(t)}
\end{equation}
where $\beta$, alias "dynamical exponent", has the value $\beta = 1/2$ \cite{barabasi::2016networkbook} and $t_i$ is the entering time for the node $i$.

The remarks, coming from the \autoref{eq:BA_modki(t)}, are multiple:
\begin{itemize}
	\item all the nodes follow the same power law, since $\beta$ is independent on the node label $i$. Furthermore, it is independent on $m$ and $m_0$ constructing parameters;
	\item the inverse dependence of $k_i \sim 1/t_i$ is a clear signal of the fact that old nodes are supposed to be larger, also called "first-mover advantage" in business;
	\item both $\beta = 1/2 < 1$ (sublinear growth) and the rate $dk_i/dt \sim 1/\sqrt{tt_i}$ underly a competing scenarios: the existing nodes compete for the $m-$new stubs with a growing bunch of nodes, resulting in a sublinear growth, which drives to a decreasing rate of acquaintances. 
\end{itemize}

To validate the power-law nature of the probability of having a certain node degree, by exploiting \autoref{eq:BA_modki(t)} it is possible note that the nodes $i$ with a degree higher than $k$ are such that \[t_i < t \left(\frac{m}{k} \right) ^{1/\beta}. \] Thus, for $t >> m_0$, the (cumulative) probability of having a degree less than $k$ is \[P(k) = 1 - \left(\frac{m}{k} \right)^{1/\beta}, \] from which the probability of having a degree $k$ could be recovered, by differentiating $P(k)$ and substituting $\beta = 1/2$, $p_k = 2m^2k^{-3}$ \cite{barabasi::2016networkbook}. As desired, the distribution exhibits a long-tail nature with $\gamma = 1/\beta +1 = 3$. Alongside with the BA model simulations, the dependence between $\gamma \textnormal{ and } \beta$ demonstrate the deep relationship among the graph topology and the temporal degree evolution, respectively contained in $\gamma$ and $\beta$ parameters.

Another feature present in \autoref{eq:BA_modki(t)} is that the degree distribution is independent on $t \textnormal{ and } N$ or a "stationary distribution". This result is the one expected, since the model aims at describing the real networks in general; thus, of rather different age and size.

\newpage
\section{The Origins of Preferential Attachment}
\label{App:OriginOfPA}
Since preferential attachment plays a relevant role in guiding the dynamics of a real network, the goal is to recover the same $\Pi(k)$ as the one assumed in the Barabási-Albert model.
It worths to introduce two classes of microscopic processes that generate it naturally \cite{barabasi::2016networkbook}:
\textit{"local (or random) mechanisms"} representing the interplay between random events and some structural properties of the network; and
\textit{"global (or optimized) mechanisms"} which take advantages of a cost-benefit analysis on the whole graph. 
In the following, it would be reviewed the "Link Selection" and "Copying" Models which belongs to the random class; and, finally, the "Optimization" Model of the second one.

\subsection{Local Mechanisms}
\subsubsection{Link Selection}
\label{sec:linear_pa_link_selection}
Assuming growth is at work, i.e. at each event time a new node is added, select randomly an edge and connect the new node to a vertex belonging to that edge.
Thus, the probability $q_k$ that the selected node, already present in the graph, has degree $k$ is 
\begin{equation}
	q_k = \frac{1}{\langle k \rangle} \cdot k p_k
\end{equation}
where the first factor exploiting the normalization constraint $\sum_k q_k = 1$.
Hence, it has the hoped form, being linear in the number of stubs ($k$) and in the frequency of the degree-k nodes ($p_k$). This displays an increasing of the chance of wiring to a degree $k$ node, by enhancing either the number of degrees or the presence of degree-k nodes themselves.

\subsubsection{Copying Model}
The idea is compute the probability of obtaining a connection of a degree-k node by mimicking the phenomenon of authors of a new webpage which copy links from existing webpages on the related topic \cite{Kleinberg:1999_WebAsAGraph}.

By introducing a new node $n$ in the network, as before, the difference stands in the link selection.
More in detail, selecting an existing node $u$ regardless of its degree, e.g. picking an arbitrary web document which topic is related to $n$, there are two possible way of connections:
\begin{itemize}
	\item Random (direct) connection: with a probability $p$, link $n$ to $u$;
	\item Copying (undirect) connection: with likelihood $1-p$, wire $n$ to an neighboring node $v$ of $u$. Reprising the web example, the new webpage $n$, copying the link of $u$, connects with its target $v$.
\end{itemize}

As a constraint to recover a dependence on $k$ of $\Pi(k)$, fix that $v$ should have degree $k$, by considering $p_v = k/2L$.
Hence, 
\begin{equation}
	\Pi(k) = \frac{p}{N} + \frac{k}{2L}(1-p)
	\label{eq:Pik_recovering}
\end{equation}
which is linear in k, yielding the desired preferential attachment.
The power of this approach is its "empirical" root which could be detected from citation networks to the social network of acquaintances.

\subsection{Global Mechanisms}
\subsection{Optimization Mechanism}
The principle of minimization of cost-benefits analysis in an economic market
\cite{Shively:2012_OverviewOfB-CAnalysis} can lead to preferential attachment whether a proper cost function is considered.

For simplicity assume that the vertexes are laying in an unit square, e.g. routers in a square continent. As before, at each event time a new router $i$ is added, while an edge with an existing node $j$ is created according to the cost function \cite{barabasi::2016networkbook}
\[
	C_i = min_{j\in G(V,E)} \left(\delta d_{ij}+h_j\right).
\]
where $d_{ij}$ is the euclidean distance between the vertex $i$ and $j$; while $h_j$ is the number of hops from $j$ to a pre-defined "center" which embodies the best network performance, e.g. net distribution hub. More clearly, $d_{ij}$ and $h_j$ represent the physical distance and "network-based" distance. Their summation describes the cost to be minimized for real results.

Depending on $\delta \textnormal{ and } N$, there are $3$ network topologies:
\begin{itemize}
	\item \textbf{Star Network $(\delta < (1/2)^{1/2})$}: only $\delta d_{ij}$ drives the growth, thus, the new nodes connects with the central one forming a star;
	\item \textbf{Random Network $(\delta \geq N^{1/2})$}: $h_j$ is the minimum quantity to be minimized. Hence, the new nodes connect to the nearest node;
	\item \textbf{Scale-free Network $(4 \leq \delta \leq N^{1/2})$}: in this intermediate regime scale-free topologies may be recovered as a result of optimization and randomness. In particular, optimization creates a basin of attraction with size $s \sim k_j$ and centered in $j$, within all the appearing nodes $i$ wire with $j$. On the other hand, Randomness is the chance of choosing a specific basin.
\end{itemize}

Thus, linear preferential attachment can come from both rational choice and random actions. Yet, most complex systems are driven by processes that have a bit of both luck or reason.

\section{Error Propagation and recovery time table}
\label{App:error_propagation}
There are reported the formulas for the estimation of the errors of all the relevant quantity. They are reported inside the plot under the rounded brackets "($\cdots$)".
Error propagation for $R_0$:
\begin{equation}
	\sigma_{R_0} = \sqrt{\beta / \mu} \cdot \sigma_D
\end{equation} 
Error propagation for $R_{c-net}$:
\begin{equation}
	\begin{aligned}
		\sigma_{R_{c-net}}^{2} &= \widehat{
			\left[\frac{2 D \langle k^2 \rangle - D^{2}}{\left(\langle k^2 \rangle - D \right)^{2}}\right]^{2} }
			\cdot \sigma_D^{2} + 
			\widehat{
			\left[ \frac{D^{2}}{\left(\langle k^2 \rangle - D\right)^{2}}\right]^{2} } 
			\cdot \sigma_{\langle k^2 \rangle}^{2} \\ \\
			&= \widehat{\left[\frac{R_{c-net}}{D}\right]^{4}} \cdot 
			\left[
			\widehat{ \left( \frac{2 \langle k^2 \rangle}{D} -1 \right)^{2} } \sigma_D^{2} 
			+ 
			\sigma_{\langle k^2 \rangle}^{2} \right]
	\end{aligned}
\end{equation}

Error propagation for $\Delta R_0 := R_0 - R_{c-net}$:
\begin{equation}
	\sigma_{\Delta R_0}^{2} = \sigma_{R_0}^{2} + \sigma_{R_{c-net}}^{2}
\end{equation}

Error propagation of secondary attack rate of COVID-19 $\beta_{COVID-19}$ for household restrictions: $\beta := 1 - (1-SAR)^{1/d} \textnormal{ , where } SAR := 19.3\% \, (95\% \, CI: 15.5\%-23.9\%)$ \cite{Jing:2020_betaCOVID-19_Houseldo_Sec_atta}. Thus,
\begin{equation}
	\sigma_{\beta} = \widehat{\left[ \frac{1}{d} \left( 1 - SAR \right)^{1/d - 1} \right]^{\frac{1}{2}}}\cdot \sigma_{ \mu } \sim 0.036
\end{equation}

\clearpage
The following table displays the conversion among the recovery rate $\mu$ and the days of recovery, which is the terminology used in medical articles. 
\label{App:muD_table}

\begin{center}
	\begin{tabular}{||c|c||}
		\hline
		\multicolumn{2}{|c|}{Recovery Measures}\\  
		\hline
		\multicolumn{1}{|c|}{$ \mu$ [1/time-step(s)] } & \multicolumn{1}{c|}{days [time-step(s)]}\\
		\hline
		0.071 &  14\\ 
		\hline
		0.111 & 9 \\
		\hline
		0.167 & 6 \\
		\hline
		0.25 & 4 \\
		\hline
		1 & 1 \\
		\hline
	\end{tabular}
\end{center}


\bibliographystyle{plain}
\bibliography{../bib/my_bibliography.bib}
\end{document}	